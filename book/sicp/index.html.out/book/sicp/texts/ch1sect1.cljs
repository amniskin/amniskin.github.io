(ns book.sicp.texts.ch1sect1 (:require [tailrecursion.hoplon.markdown :as md] [book.sicp.book-data :as data] [tailrecursion.hoplon :refer [form audio input hgroup do! timeout $text base h1 embed h3 body keygen on-append! progress main cite on-page-load object i p nav ruby check-val! a menu blockquote img $comment span track seq?* data u dl select html thead del eventsource append-child fieldset aside figure figcaption sentinel q on! bdi video address caption parse-args dd rp hr tbody table acronym frame applet html-var add-initfn! pre ul dir html-time add-attributes! html-map sup dfn sub mark script big button wbr strong li dt frameset td tr section th optgroup iframe legend em kbd spliced article isindex abbr command <!-- source output basefont route-cell header datalist tfoot s ins footer title is-ie8 h5 canvas param font div option summary samp center small style textarea loop-tpl* strike h4 tt head add-children! ol details col vector?* label rt when-dom h6 link page-load colgroup meter html-meta text-val! bdo --> b code node? noframes replace-children! noscript safe-nth h2 area br]] [tailrecursion.javelin :refer [input? cell cell? destroy-cell! ^{:private true} last-rank ^{:deprecated true} lift lens? set-formula! cell-doseq* ^{:dynamic true, :private true} *tx* deref* set-cell! lens formula? alts! dosync* cell-map formula]]) (:require-macros [tailrecursion.hoplon.markdown :refer [md]] [tailrecursion.hoplon :refer [text with-timeout sexp defelem def-values with-page-load with-dom loop-tpl with-interval with-init!]] [tailrecursion.javelin :refer [with-let mx2 dosync cell= set-cell!= prop-cell cell-doseq defc cell-let-1 defc= macroexpand-all mx cell-let]]))

(sexp {} "defelem content [attr kids]" (div {} (data/sect {:title "The Elements of Programming"} (md {} "A powerful programming language is more than just a means \nfor instructing a computer to perform tasks. The language \nalso serves as a framework within which we organize our ideas \nabout processes. Thus, when we describe a language, we should \npay particular attention to the means that the language provides \nfor combining simple ideas to form more complex ideas. Every \npowerful language has three mechanisms for accomplishing this:\n\n- **primitive expressions**, which represent the simplest entities \nthe language is concerned with,\n\n- **means of combination**, by which compound elements are built \nfrom simpler ones, and\n\n- **means of abstraction**, by which compound elements can be \nnamed and manipulated as units.\n\nIn programming, we deal with two kinds of\nelements: procedures and data. (Later we will\ndiscover that they are really not so distinct.)\nInformally, data is ``stuff'' that we want to\nmanipulate, and procedures are descriptions of the\nrules for manipulating the data. Thus, any\npowerful programming language should be able to\ndescribe primitive data and primitive procedures\nand should have methods for combining and\nabstracting procedures and data.\n\nIn this chapter we will deal only with simple\nnumerical data so that we can focus on the rules\nfor building procedures.<<The characterization of numbers as \"simple\ndata\" is a barefaced bluff. In fact, the treatment of numbers is one of\nthe trickiest and most confusing aspects of any programming language.\nSome typical issues involved are these: Some computer systems distinguish\n*integers*, such as 2, from *real numbers*, such as 2.71. Is the real\nnumber 2.00 different from the integer 2? Are the arithmetic operations\nused for integers the same as the operations used for real numbers? Does\n6 divided by 2 produce 3, or 3.0? How large a number can we represent?\nHow many decimal places of accuracy can we represent? Is the range of\nintegers the same as the range of real numbers? Above and beyond these\nquestions, of course, lies a collection of issues concerning roundoff and\ntruncation errors -- the entire science of numerical analysis. Since our\nfocus in this book is on large-scale program design rather than on\nnumerical techniques, we are going to ignore these problems. The\nnumerical examples in this chapter will exhibit the usual roundoff\nbehavior that one observes when using arithmetic operations that preserve\na limited number of decimal places of accuracy in noninteger\noperations.>> In later chapters we will see that these same rules allow\nus to build procedures to manipulate compound data as well.")) "" (data/subsect {:title "Expressions"} (md {} "One easy way to get started at programming is to\nexamine some typical interactions with an\ninterpreter for the Scheme dialect of Lisp.\nImagine that you are sitting at a computer\nterminal. You type an *expression*, and the\ninterpreter responds by displaying the result of\nits evaluating that expression.\n\nOne kind of primitive expression you might type\nis a number. (More precisely, the expression\nthat you type consists of the numerals that\nrepresent the number in base 10.) If you present\nLisp with a number\n\n486\n\nthe interpreter will respond by printing<<Throughout this book, when we\nwish to emphasize the distinction between the input typed by the user and\nthe response printed by the interpreter, we will show the latter in\nslanted characters.>>\n\n*486*\n\nExpressions representing numbers may be combined\nwith an expression representing a primitive\nprocedure (such as + or *) to form a compound\nexpression that represents the application of\nthe procedure to those numbers. For example:\n\n```clj\n(+ 137 349)\n486\n```\n```clj\n(- 1000 334)\n666\n```\n```clj\n(* 5 99)\n495\n```\n```clj\n(/ 10 5)\n2\n```\n```clj\n(+ 2.7 10)\n12.7\n```\n\nExpressions such as these, formed by delimiting\na list of expressions within parentheses in\norder to denote procedure application, are\ncalled *combinations*. The leftmost element in\nthe list is called the *operator*, and the other\nelements are called *operands*. The value of a\ncombination is obtained by applying the\nprocedure specified by the operator to the\n*arguments* that are the values of the operands.\n\nThe convention of placing the operator to the\nleft of the operands is known as *prefix\nnotation*, and it may be somewhat confusing at\nfirst because it departs significantly from the\ncustomary mathematical convention. Prefix\nnotation has several advantages, however. One of\nthem is that it can accommodate procedures that\nmay take an arbitrary number of arguments, as in\nthe following examples:\n\n```clj\n(+ 21 35 12 7)\n75\n```\n```clj\n(* 25 4 12)\n1200\n```\n\nNo ambiguity can arise, because the operator is\nalways the leftmost element and the entire\ncombination is delimited by the parentheses.\n\nA second advantage of prefix notation is that it\nextends in a straightforward way to allow\ncombinations to be *nested*, that is, to have\ncombinations whose elements are themselves\ncombinations:\n\n```clj\n(+ (* 3 5) (- 10 6))\n19\n```\n\nThere is no limit (in principle) to the depth of\nsuch nesting and to the overall complexity of\nthe expressions that the Lisp interpreter can\nevaluate. It is we humans who get confused by\nstill relatively simple expressions such as\n\n```clj\n(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))\n```\n\nwhich the interpreter would readily evaluate to\nbe 57. We can help ourselves by writing such an\nexpression in the form\n\n```clj\n(+ (* 3\n      (+ (* 2 4)\n         (+ 3 5)))\n   (+ (- 10 7)\n      6))\n```\n\nfollowing a formatting convention known as\n*pretty-printing*, in which each long\ncombination is written so that the operands are\naligned vertically. The resulting indentations\ndisplay clearly the structure of the expression.<<Lisp systems typically\nprovide features to aid the user in formatting expressions. Two\nespecially useful features are one that automatically indents to the\nproper pretty-print position whenever a new line is started and one that\nhighlights the matching left parenthesis whenever a right parenthesis is\ntyped.>>\n\nEven with complex expressions, the interpreter\nalways operates in the same basic cycle: It\nreads an expression from the terminal, evaluates\nthe expression, and prints the result. This mode\nof operation is often expressed by saying that\nthe interpreter runs in a *read-eval-print\nloop*. Observe in particular that it is not\nnecessary to explicitly instruct the interpreter\nto print the value of the\nexpression.<<Lisp obeys the convention that every expression has a value.\nThis convention, together with the old reputation of Lisp as an\ninefficient language, is the source of the quip by Alan Perlis\n(paraphrasing Oscar Wilde) that \"Lisp programmers know the value of\neverything but the cost of nothing.\">>")) "" (data/subsect {:title "Naming and the Environment"} (md {} "A critical aspect of a programming language is\nthe means it provides for using names to refer\nto computational objects. We say that the name\nidentifies a *variable* whose *value* is the\nobject.\n\nIn the Scheme dialect of Lisp, we name things with `define`. Typing\n\n```scm\n(define size 2)\n```\n\ncauses the interpreter to associate the value 2\nwith the name size.<<In this book, we do not show the interpreter's\nresponse to evaluating definitions, since this is highly\nimplementation-dependent.>> In Clojure we would use `def` to accomplish\nthe same goal. i.e.\n\n```clj\n(def size 2)\n```\n\nand the interpreter will now associate the value\n2 with the name size. Once the name size has\nbeen associated with the number 2, we can refer\nto the value 2 by name:\n\n```clj\nsize\n2\n```\n\n```clj\n(* 5 size)\n10\n```\n\nHere are further examples of the use of `def`:\n\n```clj\n(def pi 3.14159)\n(def radius 10)\n(* pi (* radius radius))\n314.159\n(def circumference (* 2 pi radius))\ncircumference\n62.8318\n```\n\n`Def` is our language's simplest means of\nabstraction, for it allows us to use simple\nnames to refer to the results of compound\noperations, such as the `circumference` computed\nabove. In general, computational objects may\nhave very complex structures, and it would be\nextremely inconvenient to have to remember and\nrepeat their details each time we want to use\nthem. Indeed, complex programs are constructed\nby building, step by step, computational objects\nof increasing complexity. The interpreter makes\nthis step-by-step program construction\nparticularly convenient because name-object\nassociations can be created incrementally in\nsuccessive interactions. This feature encourages\nthe incremental development and testing of\nprograms and is largely responsible for the fact\nthat a Lisp program usually consists of a large\nnumber of relatively simple procedures.\n\nIt should be clear that the possibility of\nassociating values with symbols and later\nretrieving them means that the interpreter must\nmaintain some sort of memory that keeps track of\nthe name-object pairs. This memory is called the\n*environment* (more precisely the *global\nenvironment*, since we will see later that a\ncomputation may involve a number of different\nenvironments).<<Chapter 3 will show that this notion of environment is\ncrucial, both for understanding how the interpreter works and for\nimplementing interpreters.>>")) " " (data/subsect {:title "Evaluating Combinations"} (md {} "One of our goals in this chapter is to isolate\nissues about thinking procedurally. As a case in\npoint, let us consider that, in evaluating\ncombinations, the interpreter is itself\nfollowing a procedure.\n\n- To evaluate a combination, do the following:\n  \n    1.  Evaluate the subexpressions of the combination.\n    2.  Apply the procedure that is the value of the \n        leftmost subexpression (the operator) to\n        the arguments that are the values of the\n        other subexpressions (the operands).\n\nEven this simple rule illustrates some important\npoints about processes in general. First,\nobserve that the first step dictates that in\norder to accomplish the evaluation process for a\ncombination we must first perform the evaluation\nprocess on each element of the combination.\nThus, the evaluation rule is *recursive* in\nnature; that is, it includes, as one of its\nsteps, the need to invoke the rule itself.<<It may seem strange that the\nevaluation rule says, as part of the first step, that we should evaluate\nthe leftmost element of a combination, since at this point that can only\nbe an operator such as `+` or `*` representing a built-in primitive\nprocedure such as addition or multiplication. We will see later that it\nis useful to be able to work with combinations whose operators are\nthemselves compound expressions.>>\n\nNotice how succinctly the idea of recursion can\nbe used to express what, in the case of a deeply\nnested combination, would otherwise be viewed as\na rather complicated process. For example,\nevaluating\n\n```clj\n(* (+ 2 (* 4 6))\n   (+ 3 5 7))\n```\n\nrequires that the evaluation rule be applied to\nfour different combinations. We can obtain a\npicture of this process by representing the\ncombination in the form of a tree, as shown in\nfigure 1.1. Each combination is represented by a\nnode with branches corresponding to the operator\nand the operands of the combination stemming\nfrom it. The terminal nodes (that is, nodes with\nno branches stemming from them) represent either\noperators or numbers. Viewing evaluation in\nterms of the tree, we can imagine that the\nvalues of the operands percolate upward,\nstarting from the terminal nodes and then\ncombining at higher and higher levels. In\ngeneral, we shall see that recursion is a very\npowerful technique for dealing with\nhierarchical, treelike objects. In fact, the\n``percolate values upward'' form of the\nevaluation rule is an example of a general kind\nof process known as *tree accumulation*.") "" (data/fig {:footer "Tree representation, showing the value of each subcombination."}) (md {} "Next, observe that the repeated application of\nthe first step brings us to the point where we\nneed to evaluate, not combinations, but\nprimitive expressions such as numerals, built-in\noperators, or other names. We take care of the\nprimitive cases by stipulating that\n\n\n- the values of numerals are the numbers that they name,\n- the values of built-in operators are the machine \n  instruction sequences that carry out the corresponding operations, and\n- the values of other names are the objects associated with \n  those names in the environment.\n\nWe may regard the second rule as a special case\nof the third one by stipulating that symbols\nsuch as + and * are also included in the global\nenvironment, and are associated with the\nsequences of machine instructions that are their\n\"values.\" The key point to notice is the role of\nthe environment in determining the meaning of\nthe symbols in expressions. In an interactive\nlanguage such as Lisp, it is meaningless to\nspeak of the value of an expression such as `(+\nx 1)` without specifying any information about\nthe environment that would provide a meaning for\nthe symbol `x` (or even for the symbol `+`). As\nwe shall see in chapter 3, the general notion of\nthe environment as providing a context in which\nevaluation takes place will play an important\nrole in our understanding of program execution.\n\nNotice that the evaluation rule given above does\nnot handle definitions. For instance, evaluating\n`(def x 3)` does not apply `def` to two\narguments, one of which is the value of the\nsymbol `x` and the other of which is 3, since\nthe purpose of the define is precisely to\nassociate `x` with a value. (That is, `(def x\n3)` is not a combination.)\n\nSuch exceptions to the general evaluation rule\nare called *special forms*. `Def` is the only\nexample of a special form that we have seen so\nfar, but we will meet others shortly. Each\nspecial form has its own evaluation rule. The\nvarious kinds of expressions (each with its\nassociated evaluation rule) constitute the\nsyntax of the programming language. In\ncomparison with most other programming\nlanguages, Lisp has a very simple syntax; that is, the evaluation rule\nfor expressions can be described by a simple general rule together with\nspecialized rules for a small number of special forms.<<Special syntactic\nforms that are simply convenient alternative surface structures for\nthings that can be written in more uniform ways are sometimes called\n*syntactic sugar*, to use a phrase coined by Peter Landin. In comparison\nwith users of other languages, Lisp programmers, as a rule, are less\nconcerned with matters of syntax. (By contrast, examine any Pascal manual\nand notice how much of it is devoted to descriptions of syntax.) This\ndisdain for syntax is due partly to the flexibility of Lisp, which makes\nit easy to change surface syntax, and partly to the observation that many\n\"convenient\" syntactic constructs, which make the language less\nuniform, end up causing more trouble than they are worth when programs\nbecome large and complex. In the words of Alan Perlis, \"Syntactic sugar\ncauses cancer of the semicolon.\">>")) "" (data/subsect {:title "Compound Procedures"} (md {} "We have identified in Lisp some of the elements\nthat must appear in any powerful programming\nlanguage:\n\n- Numbers and arithmetic operations are primitive data and procedures.\n\n- Nesting of combinations provides a means of combining operations.\n\n- Definitions that associate names with values provide a \n  limited means of abstraction.\n\nNow we will learn about *procedure definitions*,\na much more powerful abstraction technique by\nwhich a compound operation can be given a name\nand then referred to as a unit.\n\nWe begin by examining how to express the idea of\n\"squaring.\" We might say, \"To square something,\nmultiply it by itself.\" This is expressed in\nscheme as\n\n```scm\n(define (square x) (* x x))\n```\n\nbut in Clojure, we would write that as,\n\n```clj\n(defn square [x] (* x x))\n```\n\nNote that Clojure differentiates between\ndefinining an atom and defining a procedure! We\ncan understand this in the following way:\n\n```clj\n(defn square      [x]      (*      x      x))\n  ↑    ↑          ↑        ↑     ↑      ↑\n to  \"square\" something, multiply it by itself.\n```\n                                       \nWe have here a *compound procedure*, which has been given the name\n`square`. The procedure represents the operation of multiplying\nsomething by itself. The thing to be multiplied is given a local name,\nx, which plays the same role that a pronoun plays in natural language.\nEvaluating the definition creates this compound procedure and\nassociates it with the name square.<<Observe that there are two\ndifferent operations being combined here: we are creating the\nprocedure, and we are giving it the name `square`. It is possible,\nindeed important, to be able to separate these two notions -- to create\nprocedures without naming them, and to give names to procedures that\nhave already been created. We will see how to do this in section\n1.3.2.>>\n\nThe general form of a procedure definition is\n\n```clj\n(defn <name> [<formal parameters>] <body>)\n```\n\nJust in case you end up reading from the original SICP, let's take a\nmoment to note the differences between the Scheme method of defining\ncompound procedures, and the Clojure method. The Scheme method `(define\n(<name> <formal parameters>) <body>)` is very straight forward: it\ndefines the first form to be the second. In this way, we can see\n`define` to be a procedure that takes two arguments. The procedure\n`defn` in Clojure takes three arguments: the first being the name of\nthe intended procedure (in our example \"`square`\"), the second is a\nlist of all the arguments (we'll cover lists later, but in our example\nit was `[x]`), and the third is the intended procedure or the body (in\nour example it was `(* x x)`).\n\nThe <name> is a symbol to be associated with the procedure definition\nin the environment.<<Throughout this book, we will describe the general\nsyntax of expressions by using italic symbols delimited by angle\nbrackets -- e.g., `<name>` -- to denote the \"slots\" in the expression\nto be filled in when such an expression is actually used.>> The <formal\nparameters> are the names used within the body of the procedure to\nrefer to the corresponding arguments of the procedure. The <body> is an\nexpression that will yield the value of the procedure application when\nthe formal parameters are replaced by the actual arguments to which the\nprocedure is applied.<<More generally, the body of the procedure can be\na sequence of expressions. In this case, the interpreter evaluates each\nexpression in the sequence in turn and returns the value of the final\nexpression as the value of the procedure application.>> In Scheme, the\n<name> and the <formal parameters> are grouped within parentheses, just\nas they would be in an actual call to the procedure being defined, but\nin Clojure they are not.\n\nHaving defined square, we can now use it:\n\n```\n(square 21)\n441\n```\n\n```\n(square (+ 2 5))\n49\n```\n\n```\n(square (square 3))\n81\n```\n\nWe can also use square as a building block in\ndefining other procedures. For example, \\\\(x^2 + y^2\\\\) can be\nexpressed as\n\n```\n(+ (square x) (square y))\n```\n\nWe can easily define a procedure sum-of-squares\nthat, given any two numbers as arguments,\nproduces the sum of their squares:\n\n```clj\n(defn sum-of-squares [x y]\n  (+ (square x) (square y)))\n```\n\n```\n(sum-of-squares 3 4)\n25\n```\n\nNow we can use sum-of-squares as a building block in constructing\nfurther procedures:\n\n```clj\n(defn f [a]\n  (sum-of-squares (+ a 1) (* a 2)))\n```\n\n```\n(f 5)\n136\n```\n\nCompound procedures are used in exactly the same way as primitive\nprocedures. Indeed, one could not tell by looking at the definition of\n`sum-of-squares` given above whether `square` was built into the\ninterpreter, like `+` and `*`, or defined as a compound procedure.")) "" (data/subsect {:title "The Substitution Model for Procedure Application"} (md {} "To evaluate a combination whose operator names a compound procedure,\nthe interpreter follows much the same process as for combinations whose\noperators name primitive procedures, which we described in section\n[1.1.3](#section-1.1.3). That is, the interpreter evaluates the\nelements of the combination and applies the procedure (which is the\nvalue of the operator of the combination) to the arguments (which are\nthe values of the operands of the combination).\n\nWe can assume that the mechanism for applying primitive procedures to\narguments is built into the interpreter. For compound procedures, the\napplication process is as follows:\n\n- To apply a compound procedure to arguments, evaluate the body of the\nprocedure with each formal parameter replaced by the corresponding\nargument.\n\nTo illustrate this process, let's evaluate the combination\n\n```\n(f 5)\n```\n\nwhere f is the procedure defined in section [1.1.4](#section-1.1.4). We begin by retrieving the body of f:\n\n```\n(sum-of-squares (+ a 1) (* a 2))\n```\n\nThen we replace the formal parameter a by the argument 5:\n\n```\n(sum-of-squares (+ 5 1) (* 5 2))\n```\n\nThus the problem reduces to the evaluation of a combination with two\noperands and an operator `sum-of-squares`. Evaluating this combination\ninvolves three subproblems. We must evaluate the operator to get the\nprocedure to be applied, and we must evaluate the operands to get the\narguments. Now `(+ 5 1)` produces 6 and `(* 5 2)` produces 10, so we\nmust apply the `sum-of-squares` procedure to 6 and 10. These values are\nsubstituted for the formal parameters `x` and `y` in the body of\n`sum-of-squares`, reducing the expression to\n\n```\n(+ (square 6) (square 10))\n```\n\nIf we use the definition of `square`, this reduces to\n\n```\n(+ (* 6 6) (* 10 10))\n```\n\nwhich reduces by multiplication to\n\n```\n(+ 36 100)\n```\n\nand finally to\n\n```\n136\n```\n\nThe process we have just described is called the *substitution model*\nfor procedure application. It can be taken as a model that determines\nthe \"meaning\" of procedure application, insofar as the procedures in\nthis chapter are concerned. However, there are two points that should\nbe stressed:\n\n- The purpose of the substitution is to help us think about procedure\napplication, not to provide a description of how the interpreter really\nworks. Typical interpreters do not evaluate procedure applications by\nmanipulating the text of a procedure to substitute values for the\nformal parameters. In practice, the \"substitution\" is accomplished by\nusing a local environment for the formal parameters. We will discuss\nthis more fully in chapters 3 and 4 when we examine the implementation\nof an interpreter in detail.\n\n- Over the course of this book, we will present a sequence of\nincreasingly elaborate models of how interpreters work, culminating with\na complete implementation of an interpreter and compiler in chapter 5.\nThe substitution model is only the first of these models -- a way to get\nstarted thinking formally about the evaluation process. In general, when\nmodeling phenomena in science and engineering, we begin with simplified,\nincomplete models. As we examine things in greater detail, these simple\nmodels become inadequate and must be replaced by more refined models. The\nsubstitution model is no exception. In particular, when we address in\nchapter 3 the use of procedures with \"mutable data\", we will see that the\nsubstitution model breaks down and must be replaced by a more complicated\nmodel of procedure application.<<Despite the simplicity of the\nsubstitution idea, it turns out to be surprisingly complicated to give a\nrigorous mathematical definition of the substitution process. The problem\narises from the possibility of confusion between the names used for the\nformal parameters of a procedure and the (possibly identical) names used\nin the expressions to which the procedure may be applied. Indeed, there\nis a long history of erroneous definitions of substitution in the\nliterature of logic and programming semantics. See Stoy 1977 for a\ncareful discussion of substitution.>>")) "" (data/ssub {:title "Applicative Order vs Normal Order"} (md {} "According to the description of evaluation given in section\n[1.1.3](#section-1.1.3), the interpreter first evaluates the operator\nand operands and then applies the resulting procedure to the resulting\narguments. This is not the only way to perform evaluation. An\nalternative evaluation model would not evaluate the operands until\ntheir values were needed. Instead it would first substitute operand\nexpressions for parameters until it obtained an expression involving\nonly primitive operators, and would then perform the evaluation. If we\nused this method, the evaluation of\n\n```\n(f 5)\n```\n\nwould proceed according to the sequence of expansions\n\n```\n(sum-of-squares (+ 5 1) (* 5 2))\n```\n\n```\n(+    (square (+ 5 1))      (square (* 5 2))  )\n```\n\n```\n(+    (* (+ 5 1) (+ 5 1))   (* (* 5 2) (* 5 2)))\n```\n\nfollowed by the reductions\n\n```\n(+ (* 6 6) (* 10 10))\n\n(+    36      100)\n\n136\n```\n\n\nThis gives the same answer as our previous evaluation model, but the\nprocess is different. In particular, the evaluations of `(+ 5 1)` and\n`(* 5 2)` are each performed twice here, corresponding to the reduction\nof the expression\n\n```\n(* x x)\n```\n\nwith `x` replaced respectively by `(+ 5 1)` and `(* 5 2)`.\n\nThis alternative \"fully expand and then reduce\" evaluation method is\nknown as *normal-order evaluation*, in contrast to the \"evaluate the\narguments and then apply\" method that the interpreter actually uses,\nwhich is called *applicative-order evaluation*. It can be shown that,\nfor procedure applications that can be modeled using substitution\n(including all the procedures in the first two chapters of this book)\nand that yield legitimate values, normal-order and applicative-order\nevaluation produce the same value. (See [exercise 1.5](#q1.5) for an\ninstance of an \"illegitimate\" value where normal-order and\napplicative-order evaluation do not give the same result.)\n\nLisp uses applicative-order evaluation, partly because of the additional\nefficiency obtained from avoiding multiple evaluations of expressions\nsuch as those illustrated with `(+ 5 1)` and `(* 5 2)` above and, more\nsignificantly, because normal-order evaluation becomes much more\ncomplicated to deal with when we leave the realm of procedures that can\nbe modeled by substitution. On the other hand, normal-order evaluation\ncan be an extremely valuable tool, and we will investigate some of its\nimplications in chapters 3 and 4.<<In chapter 3 we will introduce *stream\nprocessing*, which is a way of handling apparently \"infinite\" data\nstructures by incorporating a limited form of normal-order evaluation. In\nsection 4.2 we will modify the Scheme interpreter to produce a\nnormal-order variant of Scheme.>>")) "" (data/subsect {:title "Conditional Expressions and Predicates"} (md {} "The expressive power of the class of procedures that we can define at\nthis point is very limited, because we have no way to make tests and to\nperform different operations depending on the result of a test. For\ninstance, we cannot define a procedure that computes the absolute value\nof a number by testing whether the number is positive, negative, or zero\nand taking different actions in the different cases according to the rule\n\n$$| x |= \\begin{cases} x &\\mbox{if } x > 0 \\cr 0 &\\mbox{if } x = 0 \\cr -x\n&\\mbox{if } x < 0 \\end{cases}$$\n\n\nThis construct is called a *case analysis*, and there is a special form\nin Lisp for notating such a case analysis. It is called `cond` (which\nstands for \"conditional\"), and it is used as follows:\n\n```\n(defn abs [x]\n  (cond (> x 0) x\n        (= x 0) 0\n        (< x 0) (- x)))\n```\n\nThe general form of a conditional expression is\n\n```\n(cond <p1> <e1>\n      <p2> <e2>\n       ...                       \n      <pn> <en>)\n```\n\n\nconsisting of the symbol cond followed by pairs of expressions <p> <e>\ncalled *clauses*. The first expression in each pair is a *predicate* --\nthat is, an expression whose value is interpreted as either `true` or\n`false`.<<\"Interpreted as either true or false\" means this: In Scheme,\nthere are two distinguished values that are denoted by the constants\n`true` and `false`. When the interpreter checks a predicate's value, it\ninterprets`false` and `nil` as false. Any other value is treated as true.\n(Thus, providing `true` is logically unnecessary, but it is\nconvenient.)>>\n\nConditional expressions are evaluated as follows. The predicate <p1> is\nevaluated first. If its value is false, then <p2> is evaluated. If <p2>'s\nvalue is also false, then <p3> is evaluated. This process continues until\na predicate is found whose value is true, in which case the interpreter\nreturns the value of the corresponding *consequent expression* <e> of the\nclause as the value of the conditional expression. If none of the <p>'s\nis found to be true, the value of the `cond` is undefined.\n\nThe word *predicate* is used for procedures that return `true` or\n`false`, as well as for expressions that evaluate to `true` or `false`.\nThe absolute-value procedure `abs` makes use of the primitive predicates >,\n<, and =.<<`Abs` also uses the \"minus\" operator `-`, which, when used with\na single operand, as in `(- x)`, indicates negation.>> These take two\nnumbers as arguments and test whether the first number is, respectively,\ngreater than, less than,\nor equal to the second number, returning true or false accordingly.\n\nAnother way to write the absolute-value procedure is\n\n```clj\n(defn abs [x]\n  (cond (< x 0) (- x)\n        :else x))\n```\n\nwhich could be expressed in English as \"If x is less than zero return -\nx; otherwise return x.\" `:else` is a special symbol that can be used in\nplace of the <p> in the final clause of a `cond`. This causes the\n`cond` to return as its value the value of the corresponding <e>\nwhenever all previous clauses have been bypassed. In fact, any\nexpression that always evaluates to a true value could be used as the\n<p> here.\n\nHere is yet another way to write the absolute-value procedure:\n\n```clj\n(defn abs [x]\n  (if (< x 0)\n      (- x)\n      x))\n```\n\nThis uses the special form `if`, a restricted type of conditional that\ncan be used when there are precisely two cases in the case analysis.\nThe general form of an `if` expression is\n\n```clj\n(if <predicate> <consequent> <alternative>)\n```\n\nTo evaluate an `if` expression, the interpreter starts by evaluating the\n<predicate> part of the expression. If the <predicate> evaluates to a\ntrue value, the interpreter then evaluates the <consequent> and returns\nits value. Otherwise it evaluates the <alternative> and returns its\nvalue.<<In Scheme, a minor difference between `if` and `cond` is that the\n`<e>` part of each `cond` clause may be a sequence of expressions. If the\ncorresponding `<p>` is found to be true, the expressions `<e>` are\nevaluated in sequence and the value of the final expression in the\nsequence is returned as the value of the `cond`. In an `if` expression,\nhowever, the `<consequent>` and `<alternative>` must be single\nexpressions. In Clojure, however, these must all be single expressioins.\nTo get a similar functionality one could use `do`.>>\n\nIn addition to primitive predicates such as <, =, and >, there are\nlogical composition operations, which enable us to construct compound\npredicates. The three most frequently used are these:\n\n- \n  ```\n  (and <e1> ... <en>)\n  ```\n    \n  The interpreter evaluates the expressions <e> one at a time, in\n  left-to-right order. If any <e> evaluates to false, the value of the\n  `and` expression is false, and the rest of the <e>'s are not\n  evaluated. If all <e>'s evaluate to true values, the value of the and\n  expression is the value of the last one.\n\n\n- \n  ```\n  (or <e1> ... <en>)\n  ```\n  \n  The interpreter evaluates the expressions <e> one at a time, in\n  left-to-right order. If any <e> evaluates to a true value, that value\n  is returned as the value of the or expression, and the rest of the\n  <e>'s are not evaluated. If all <e>'s evaluate to false, the value of\n  the `or` expression is false.\n\n\n- \n  ```\n  (not <e>)\n  ```\n    \n  The value of a `not` expression is true when the expression <e>\n  evaluates to false, and false otherwise.\n\nNotice that `and` and `or` are special forms, not procedures, because\nthe subexpressions are not necessarily all evaluated. `not` is an\nordinary procedure.\n\nAs an example of how these are used, the condition that a number x be\nin the range \\\\(5 \\lt x \\lt 10\\\\) may be expressed as\n\n```clj\n(and (> x 5) (< x 10))\n```\n\nAs another example, we can define a predicate to test whether one\nnumber is greater than or equal to another as\n\n```clj\n(defn >= [x y] \n  (or (> x y) (= x y)))\n```\n\nor alternatively as\n\n```clj\n(defn >= [x y]\n  (not (< x y)))\n```")) (data/exercises {} (data/exercise {} (md {} "Below is a sequence of expressions. What is the result printed by the\ninterpreter in response to each expression? Assume that the sequence is\nto be evaluated in the order in which it is presented.\n\n```clj\n10\n```") (data/q-a {} (md {} "```\n10\n```")) "" (md {} "```clj\n(+ 5 3 4)\n```") "" (data/q-a {} (md {} "```\n12\n```")) "" (md {} "```clj\n(- 9 1)\n```") "" (data/q-a {} (md {} "```\n8\n```")) "" (md {} "```clj\n(/ 6 2)\n```") "" (data/q-a {} (md {} "```\n3\n```")) "" (md {} "```clj\n(+ (* 2 4) (- 4 6))\n```") "" (data/q-a {} (md {} "```\n6\n```")) "" (md {} "```clj\n(defn a 3)\n```") "" (data/q-a {} (md {} "```\na\n```")) "" (md {} "```clj\n(defn b (+ a 1))\n```") "" (data/q-a {} (md {} "```\nb\n```")) "" (md {} "```clj\n(+ a b (* a b))\n```") "" (data/q-a {} (md {} "```\n19\n```")) "" (md {} "```clj\n(= a b)\n```") "" (data/q-a {} (md {} "```\nfalse\n```")) "" (md {} "```clj\n(if (and (> b a) (< b (* a b)))\n    b\n    a)\n```") "" (data/q-a {} (md {} "```\n4\n```")) "" (md {} "```clj\n(cond (= a 4) 6\n      (= b 4) (+ 6 7 a)\n      :else 25)\n```") "" (data/q-a {} (md {} "```\n16\n```")) "" (md {} "```clj\n(+ 2 (if (> b a) b a))\n```") "" (data/q-a {} (md {} "```\n5\n```")) "" (md {} "```clj\n(* (cond (> a b) a\n         (< a b) b\n         :else -1)\n   (+ a 1))\n```") "" (data/q-a {} (md {} "```\n16\n```"))) "" (data/exercise {} (md {} "Translate the following expression into prefix form\n$$\\frac{5+4+\\left(2-\\left(3-\\left(6+\\frac{4}{5}\\right)\\right)\\right)}{3(6-2)(2-7)}$$") "" (data/q-a {} (md {} "```clj\n(/ (+ 5 4 (- 2 (- 3 (+ 6 (/ 4 5))))) \n   (* 3 (- 6 2) (- 2 7)))\n```"))) "" (data/exercise {} (md {} "Define a procedure that takes three numbers as arguments \nand returns the sum of the squares of the two larger numbers.") "" (data/q-a {} (md {} "```clj\n(defn sum-of-largest-squares [x y z]\n  (cond (and (< x y) (< x z)) (+ (square y) (square z))\n        (and (< y x) (< y z)) (+ (square x) (square z))\n        :else (+ (square x) (square y))))\n```"))) "" (data/exercise {} (md {} "Observe that our model of evaluation allows for combinations \nwhose operators are compound expressions. Use this observation \nto describe the behavior of the following procedure:\n\n```clj\n(defn a-plus-abs-b [a b]\n  ((if (> b 0) + -) a b))\n``` ") (data/q-a {} (md {} "It returns `(+ a (abs b))`. Note: if `(> b 0)`, then\n`(= (abs b) b)`, so `(+ a (abs b))` would be `(+ a b)`,\njust as this function gives us. Alternatively, if\n`(not (> b 0))`, then b is negative and `(= (abs b) (- b))`\nwhich means, `(+ a (abs b))` is `(+ a (- b))` which is\nreally just `(- a b)` as our function above gives us."))) "" (data/exercise {} (md {} "Ben Bitdiddle has invented a test to determine whether \nthe interpreter he is faced with is using applicative-order \nevaluation or normal-order evaluation. He defines the following \ntwo procedures:\n\n```clj\n(defn p [] (p))\n```\n\nand\n\n```clj\n(defn test [x y]\n   (if (= x 0)\n   0\n   y))\n```\n\nThen he evaluates the expression\n\n```clj\n(test 0 (p))\n```\n\nWhat behavior will Ben observe with an interpreter that uses \napplicative-order evaluation? What behavior will he observe \nwith an interpreter that uses normal-order evaluation? Explain \nyour answer. (Assume that the evaluation rule for the special \nform if is the same whether the interpreter is using normal or \napplicative order: The predicate expression is evaluated first, \nand the result determines whether to evaluate the consequent or \nthe alternative expression.)") (data/q-a {} (md {} "- With normal order evaluation it compiles just as one\n  might expect: first the function itself is unraveled,\n  finding that it is an `if` statement, then the `if`\n  statement is evaluated according to its own rules.\n  Finding that the first argument is 0, it returns 0.\n\n- With applicative order evaluation the story is a bit more\n  interesting. Since the arguments to a function are always\n  evaluated first in applicative order evaluation, the\n  compiler would attempt to evaluate both the first and\n  second arguments and hence fall into an infinite loop\n  in the attempt to evaluate the second argument.")))) "" (data/subsect {:title "Example: Square Roots by Newton's Method"} (md {} "Procedures, as introduced above, are much like ordinary mathematical\nfunctions. They specify a value that is determined by one or more\nparameters. But there is an important difference between mathematical\nfunctions and computer procedures. Procedures must be effective. As a\ncase in point, consider the problem of computing square roots. We can\ndefine the square-root function as\n\n$$ \\sqrt x = \\text{ the } y \\text{ such that } y\\geq 0 \\text{ and } y^2 = x $$\n\nThis describes a perfectly legitimate mathematical function. We could\nuse it to recognize whether one number is the square root of another,\nor to derive facts about square roots in general. On the other hand,\nthe definition does not describe a procedure. Indeed, it tells us\nalmost nothing about how to actually find the square root of a given\nnumber. It will not help matters to rephrase this definition in\npseudo-Lisp: \n\n```clj\n(defn sqrt [x] \n  (the y (and (>= y 0) \n              (= (square y) x)))) \n```\n\nThis only begs the question.  The contrast between function and\nprocedure is a reflection of the general distinction between describing\nproperties of things and describing how to do things, or, as it is\nsometimes referred to, the distinction between declarative knowledge\nand imperative knowledge. In mathematics we are usually concerned with\ndeclarative (what is) descriptions, whereas in computer science we are\nusually concerned with imperative (how to) descriptions.<<Declarative\nand imperative descriptions are intimately related, as indeed are\nmathematics and computer science. For instance, to say that the answer\nproduced by a program is \"correct\" is to make a declarative statement\nabout the program. There is a large amount of research aimed at\nestablishing techniques for proving that programs are correct, and much\nof the technical difficulty of this subject has to do with negotiating\nthe transition between imperative statements (from which programs are\nconstructed) and declarative statements (which can be used to deduce\nthings). In a related vein, an important current area in\nprogramming-language design is the exploration of so-called very\nhigh-level languages, in which one actually programs in terms of\ndeclarative statements. The idea is to make interpreters sophisticated\nenough so that, given \"what is\" knowledge specified by the\nprogrammer, they can generate \"how to\" knowledge automatically. This\ncannot be done in general, but there are important areas where progress\nhas been made. We shall revisit this idea in chapter 4.>>\n\nHow does one compute square roots? The most common way is to use\nNewton's method of successive approximations, which says that whenever\nwe have a guess y for the value of the square root of a number x, we\ncan perform a simple manipulation to get a better guess (one closer to\nthe actual square root) by averaging y with x/y.<<This square-root\nalgorithm is actually a special case of Newton's method, which is a\ngeneral technique for finding roots of equations. The square-root\nalgorithm itself was developed by Heron of Alexandria in the first\ncentury A.D. We will see how to express the general Newton's method as\na Lisp procedure in section 1.3.4.>> For example, we can compute the\nsquare root of 2 as follows. Suppose our initial guess is 1:") "" (table {} (tr {} (td {} "Guess ") (td {} "Quotient ") (td {} "Average ")) (tr {} (td {} "1 ") (td {} "(2/1) = 2 ") (td {} "((2+1)/2) = 1.5 ")) (tr {} (td {} "1.5 ") (td {} "(2/1.5) = 1.333...  ") (td {} "((1.333... + 1.5)/2) = 1.4167 ")) (tr {} (td {} "1.4167 ") (td {} "(2/1.4167) = 1.4118 ") (td {} "((1.4167 + 1.4118)/2) = 1.4142 ")) (tr {} (td {} "1.4142...  ") (td {} "...  ") (td {} "..."))) (md {} "Continuing this process, we obtain better and better approximations to the square root. \n\nNow let's formalize the process in terms of procedures. We start with a\nvalue for the radicand (the number whose square root we are trying to\ncompute) and a value for the guess. If the guess is good enough for our\npurposes, we are done; if not, we must repeat the process with an\nimproved guess. We write this basic strategy as a procedure:\n\n```clj\n(defn sqrt-iter [guess x]\n  (if (good-enough? guess x)\n      guess\n      (sqrt-iter (improve guess x)\n                 x)))\n```\n\nA guess is improved by averaging it with the quotient of the radicand and\nthe old guess:\n\n```clj\n(defn improve [guess x]\n  (average guess (/ x guess)))\n```\n\nwhere\n\n```clj\n(defn average [x y]\n  (/ (+ x y) 2))\n```\n\nWe also have to say what we mean by ``good enough.'' The following will\ndo for illustration, but it is not really a very good test. (See exercise\n1.7.) The idea is to improve the answer until it is close enough so that\nits square differs from the radicand by less than a predetermined\ntolerance (here 0.001):<<We will usually give predicates names ending\nwith question marks, to help us remember that they are predicates. This\nis just a stylistic convention. As far as the interpreter is concerned,\nthe question mark is just an ordinary character.>>\n\n```clj\n(defn good-enough? [guess x]\n  (< (abs (- (square guess) x)) 0.001))\n```\n\nFinally, we need a way to get started. For instance, we can always\nguess that the square root of any number is 1:<<Observe that we express\nour initial guess as 1.0 rather than 1. This would not make any\ndifference in many Lisp implementations. MIT Scheme, however,\ndistinguishes between exact integers and decimal values, and dividing\ntwo integers produces a rational number rather than a decimal. For\nexample, dividing 10 by 6 yields 5/3, while dividing 10.0 by 6.0 yields\n1.6666666666666667. (We will learn how to implement arithmetic on\nrational numbers in section 2.1.1.) If we start with an initial guess\nof 1 in our square-root program, and \\\\(x\\\\) is an exact integer, all\nsubsequent values produced in the square-root computation will be\nrational numbers rather than decimals. Mixed operations on rational\nnumbers and decimals always yield decimals, so starting with an initial\nguess of 1.0 forces all subsequent values to be decimals.>>\n\n```clj\n(defn sqrt [x]\n  (sqrt-iter 1.0 x))\n```\n\nIf we type these definitions to the interpreter, we can use sqrt just as we can use any procedure:\n\n```clj\n(sqrt 9)\n3.00009155413138\n(sqrt (+ 100 37))\n11.704699917758145\n(sqrt (+ (sqrt 2) (sqrt 3)))\n1.7739279023207892\n(square (sqrt 1000))\n1000.000369924366\n```\n\nThe sqrt program also illustrates that the simple procedural language\nwe have introduced so far is sufficient for writing any purely\nnumerical program that one could write in, say, C or Pascal. This might\nseem surprising, since we have not included in our language any\niterative (looping) constructs that direct the computer to do something\nover and over again. Sqrt-iter, on the other hand, demonstrates how\niteration can be accomplished using no special construct other than the\nordinary ability to call a procedure.<<Readers who are worried about\nthe efficiency issues involved in using procedure calls to implement\niteration should note the remarks on ``tail recursion'' in section\n1.2.1.>>")) "" (data/exercises {} (data/exercise {} (md {} "Alyssa P. Hacker doesn't see why if needs to be provided as a\nspecial form. \"Why can't I just define it as an ordinary procedure\nin terms of cond?\" she asks. Alyssa's friend Eva Lu Ator claims\nthis can indeed be done, and she defines a new version of if:\n\n```clj\n(defn new-if [predicate then-clause else-clause]\n  (cond predicate then-clause\n        :else else-clause))\n```\n\nEva demonstrates the program for Alyssa:\n\n```clj\n(new-if (= 2 3) 0 5)\n5\n```\n```clj\n(new-if (= 1 1) 0 5)\n0\n```\n\nDelighted, Alyssa now uses `new-if` to rewrite the square-root program:\n\n```clj\n(defn sqrt-iter [guess x]\n  (new-if (good-enough? guess x)\n          guess\n          (sqrt-iter (improve guess x)\n                     x)))\n```\n\nWhat happens when Alyssa attempts to use this to compute square roots? Explain.") "" (data/q-a {} (md {} "Since `new-if` is not a special form, it will be evaluated in\napplicative order. Hence, when `(new-if a b c)` is called, a, b, and\nc are all evaluated before considering how they may or may not be\nused within the function `new-if`.\n\nSo, in this particular case, let us compute the square root of 4 with\nour first guess being 2 (Alyssa would probably think that this would\nterminate immediately, but let's see).  ```clj\n(sqrt-iter 2 4) ==>\n(new-if (good-enough? 2 4) 2 (sqrt-iter (improve 2 4) 4))\n```\n\nYou can see that in this example, since `(improve 2 4) = 2`, `new-if`\nis going to requre us to compute `(sqrt-iter 2 4)` again. Then we'll\nbe computing the `new-if` again, and you can see the cycle that we've\ngotten ourselves in.\n\nLong story short, this would result in an infinite loop."))) "" (data/exercise {} (md {} "The `good-enough?` test used in computing square roots will not be\nvery effective for finding the square roots of very small numbers.\nAlso, in real computers, arithmetic operations are almost always\nperformed with limited precision. This makes our test inadequate\nfor very large numbers. Explain these statements, with examples\nshowing how the test fails for small and large numbers. An\nalternative strategy for implementing `good-enough?` is to watch\nhow `guess` changes from one iteration to the next and to stop when\nthe change is a very small fraction of the guess. Design a\nsquare-root procedure that uses this kind of end test. Does this\nwork better for small and large numbers?") "" (data/q-a {} (md {} "When finding the square root of a very small number (let's use\n0.0000001, whose square root is 0.0001), since the answer we're\nlooking for is smaller than our tollerance, you might get a zero\nor even a negative number as our answer! And on the other end of\nthe spectrum, if our number is too large it would require enough\ncalculations to make the precision larger than our tolerance. In\nthat having a set tolerance is meaningless because our answer\nwill be outside of that range due to the limitations of the\ncomputer!\n\nTo avoid this problem we can set a dynamic tolerance like the\nexercise suggests. Let's say our problem allows for a 10%\nfractional tolerance. Then our `good-enough?` procedure would\nlook like, \n\n```clj\n(defn good-enough? [guess x]\n  (< (abs (/ (- x guess) x)) 0.1))\n```"))) "" (data/exercise {} (md {} "Newton's method for cube roots is based on the fact that if y is an\napproximation to the cube root of x, then a better approximation is\ngiven by the value\n\n$$ \\frac{x/y^2 +2y}{3} $$\n\nUse this formula to implement a cube-root procedure analogous to\nthe square-root procedure. (In section\n[1.3.4](#!/sicp/ch/1/sect/3/sub/4) we will see how to implement\nNewton's method in general as an abstraction of these square-root\nand cube-root procedures.)") "" (data/q-a {} (md {} "```clj\n(defn improve [guess x]\n  (/ (+ (/ x (square guess)) (* 2 guess)) 3))\n```")))) "" (data/subsect {:title "Procedures as Black-Box Abstractions"} (md {} "`Sqrt` is our first example of a process defined by a set of mutually\ndefined procedures. Notice that the definition of `sqrt-iter` is\n*recursive*; that is, the procedure is defined in terms of itself. The\nidea of being able to define a procedure in terms of itself may be\ndisturbing; it may seem unclear how such a \"circular\" definition could\nmake sense at all, much less specify a well-defined process to be\ncarried out by a computer. This will be addressed more carefully in\nsection [1.2](\"#/sicp/ch/1/sect/2/\"). But first let's consider some\nother important points illustrated by the `sqrt` example.\n\nObserve that the problem of computing square roots breaks up naturally\ninto a number of subproblems: how to tell whether a guess is good\nenough, how to improve a guess, and so on. Each of these tasks is\naccomplished by a separate procedure. The entire `sqrt` program can be\nviewed as a cluster of procedures (shown in figure 1.2) that mirrors\nthe decomposition of the problem into subproblems.") (data/fig {:footer "Procedural decomposition of the sqrt program."}) "" (md {} "The importance of this decomposition strategy is not simply that one is\ndividing the program into parts. After all, we could take any large\nprogram and divide it into parts -- the first ten lines, the next ten\nlines, the next ten lines, and so on. Rather, it is crucial that each\nprocedure accomplishes an identifiable task that can be used as a\nmodule in defining other procedures. For example, when we define the\n`good-enough?` procedure in terms of `square`, we are able to regard the\n`square` procedure as a \"black box.\" We are not at that moment\nconcerned with *how* the procedure computes its result, only with the\nfact that it computes the square. The details of how the square is\ncomputed can be suppressed, to be considered at a later time. Indeed,\nas far as the `good-enough?` procedure is concerned, `square` is not quite\na procedure but rather an abstraction of a procedure, a so-called\n*procedural abstraction*. At this level of abstraction, any procedure\nthat computes the square is equally good.\n\nThus, considering only the values they return, the following two\nprocedures for squaring a number should be indistinguishable. Each\ntakes a numerical argument and produces the square of that number as\nthe value.<<It is not even clear which of these procedures is a more\nefficient implementation. This depends upon the hardware available.\nThere are machines for which the \"obvious\" implementation is the\nless efficient one. Consider a machine that has extensive tables of\nlogarithms and antilogarithms stored in a very efficient manner.>>\n\n```clj\n(defn square [x] (* x x))\n```\n\n```\n(defn square [x] \n  (exp (double (log x))))\n```  \n\n```clj\n(defn double [x] (+ x x))\n```\n\nSo a procedure definition should be able to suppress detail. The users\nof the procedure may not have written the procedure themselves, but may\nhave obtained it from another programmer as a black box. A user should\nnot need to know how the procedure is implemented in order to use it.")) "" (data/ssub {:title "Local Names"} (md {} "One detail of a procedure's implementation that should not matter to\nthe user of the procedure is the implementer's choice of names for\nthe procedure's formal parameters. Thus, the following procedures\nshould not be distinguishable:\n\n```clj\n(defn square [x] (* x x))\n```\n\n```clj\n(defn square [y] (* y y))\n```\n\nThis principle -- that the meaning of a procedure should be\nindependent of the parameter names used by its author -- seems on the\nsurface to be self-evident, but its consequences are profound. The\nsimplest consequence is that the parameter names of a procedure must\nbe local to the body of the procedure. For example, we used `square` in\nthe definition of `good-enough?` in our square-root procedure:\n\n```clj\n(defn good-enough? [guess x]\n  (< (abs (- (square guess) x)) 0.001))\n```  \n\nThe intention of the author of `good-enough?` is to determine if the\nsquare of the first argument is within a given tolerance of the\nsecond argument. We see that the author of `good-enough?` used the name\n`guess` to refer to the first argument and `x` to refer to the second\nargument. The argument of `square` is `guess`. If the author of `square`\nused `x` (as above) to refer to that argument, we see that the `x` in\n`good-enough?` must be a different `x` than the one in `square`. Running\nthe procedure `square` must not affect the value of `x` that is used by\n`good-enough?`, because that value of `x` may be needed by `good-enough?`\nafter `square` is done computing.\n\nIf the parameters were not local to the bodies of their respective\nprocedures, then the parameter `x` in `square` could be confused with the\nparameter `x` in `good-enough?`, and the behavior of `good-enough?` would\ndepend upon which version of `square` we used. Thus, `square` would not\nbe the black box we desired.\n\nA formal parameter of a procedure has a very special role in the\nprocedure definition, in that it doesn't matter what name the formal\nparameter has. Such a name is called a *bound variable*, and we say\nthat the procedure definition *binds* its formal parameters. The\nmeaning of a procedure definition is unchanged if a bound variable is\nconsistently renamed throughout the definition.<<The concept of\nconsistent renaming is actually subtle and difficult to define\nformally. Famous logicians have made embarrassing errors here.>> If a\nvariable is not bound, we say that it is *free*. The set of\nexpressions for which a binding defines a name is called the *scope*\nof that name. In a procedure definition, the bound variables declared\nas the formal parameters of the procedure have the body of the\nprocedure as their scope.\n\nIn the definition of `good-enough?` above, `guess` and `x` are bound\nvariables but `<`, `-`, `abs`, and `square` are free. The meaning of\n`good-enough?` should be independent of the names we choose for\n`guess` and `x` so long as they are distinct and different from `<`,\n`-`, `abs`, and `square`. (If we renamed `guess` to `abs` we would\nhave introduced a bug by *capturing* the variable `abs`. It would\nhave changed from free to bound.) The meaning of `good-enough?` is\nnot independent of the names of its free variables, however. It\nsurely depends upon the fact (external to this definition) that the\nsymbol `abs` names a procedure for computing the absolute value of a\nnumber. `Good-enough?` will compute a different function if we\nsubstitute `cos` for `abs` in its definition.")) "" (data/ssub {:title "Internal Definitions and Block Structures"} (md {} "It is instructive to note that the rest of this section does not work\nas well in Clojure. The reason is that `def`, `defn` and all other\ndefining forms define things in the global environment directly (no\nmatter where they are called). If this does not make sense to you\njust yet, don't worry: it should by the end of this section.\n\nWe have one kind of name isolation available to us so far: The formal\nparameters of a procedure are local to the body of the procedure. The\nsquare-root program illustrates another way in which we would like to\ncontrol the use of names. The existing program consists of separate\nprocedures:\n\n```clj\n(defn sqrt [x]\n  (sqrt-iter 1.0 x))\n(defn sqrt-iter [guess x]\n  (if (good-enough? guess x)\n      guess\n      (sqrt-iter (improve guess x) x)))\n(defn good-enough? [guess x]\n  (< (abs (- (square guess) x)) 0.001))\n(defn improve [guess x]\n  (average guess (/ x guess)))\n```\n\nThe problem with this program is that the only procedure that is\nimportant to users of `sqrt` is `sqrt`. The other procedures\n(`sqrt-iter`, `good-enough?`, and `improve`) only clutter up their\nminds. They may not define any other procedure called `good-enough?`\nas part of another program to work together with the square-root\nprogram, because `sqrt` needs it. The problem is especially severe in\nthe construction of large systems by many separate programmers. For\nexample, in the construction of a large library of numerical\nprocedures, many numerical functions are computed as successive\napproximations and thus might have procedures named `good-enough?`\nand `improve` as auxiliary procedures. We would like to localize the\nsubprocedures, hiding them inside `sqrt` so that `sqrt` could coexist\nwith other successive approximations, each having its own private\n`good-enough?` procedure. To make this possible, we allow a procedure\nto have internal definitions that are local to that procedure. For\nexample, in the `square-root` problem we can write\n\n```scm\n(define (sqrt x)\n  (define (good-enough? guess x)\n    (< (abs (- (square guess) x)) 0.001))\n  (define (improve guess x)\n    (average guess (/ x guess)))\n  (define (sqrt-iter guess x)\n    (if (good-enough? guess x)\n        guess\n        (sqrt-iter (improve guess x) x)))\n  (sqrt-iter 1.0 x))\n```\n\nNote: This approach does not solve our problem in Clojure. In\nClojure, whenever `def` or `defn` are used, they add the definitions\nto the global environment. What that means is, every time you run the\n`sqrt` procedure, you would end up redefining `good-enough?` for\nevery program that uses it. Now, if every program that uses\n`good-enough?` redefines `good-enough?`, then you might not run into\nany problems; but either way, there is a better alternative: we could\nuse what's called a `let` binding, but we'll learn about those a\nlittle later.\n\nThe thing to remember is the evaluation model. When the compiler is\ngiven a symbol, it has a set procedure for determining what this\nsymbol means: first it looks to see if the symbol is a special form\n(like `if`), if it's not, then it checks each successive nested local\nenvironment until it reaches the global environment. The point is, in\nScheme, `define` only mutates the local environment, whatever that\nmay be; the same is not true in Clojure. Defining forms mutate the\nglobal environment directly, so using `defn` to change the definition\nof a function in one place changes it in all places.\n\nLuckily, Cloure has a built in pair of functions `loop` and `recur`\nthat do help us a bit. We can replace the `iter` definition with this\n`loop` `recur` business thusly (assuming `good-enough` and `improve` were already defined):\n\n```clj\n(defn sqrt [x]\n  (loop [guess 1.0]\n    (if (good-enough? guess x)\n        guess\n        (recur (improve guess x)))))\n```\n\nThe genearl format for these will be,\n\n```clj\n(defn function [arguments]\n  (loop [thing1 initial-value1\n         thing2 initial-value2\n         ...\n         thingn initial-valuen]\n    (<if or cond can go here> (recur (next thing1) (next thing2)...(next thingn)))))\n```\n\nThis `[thing1 intial-value1]` defines `thing1` to be `value1` for the\nfirst iteration, then when you call `recur`, it goes back to loop\nwith the new values given (in the same order they appear in the\n`loop` bindings).\n\nSuch nesting of definitions, called *block structure*, is basically\nthe right solution to the simplest name-packaging problem. But there\nis a better idea lurking here. In addition to internalizing the\ndefinitions of the auxiliary procedures, we can simplify them. Since\n`x` is bound in the definition of `sqrt`, the procedures\n`good-enough?`, `improve`, and `sqrt-iter`, which are defined\ninternally to `sqrt`, are in the scope of `x`. Thus, it is not\nnecessary to pass `x` explicitly to each of these procedures.\nInstead, we allow `x` to be a free variable in the internal\ndefinitions, as shown below. Then `x` gets its value from the\nargument with which the enclosing procedure `sqrt` is called. This\ndiscipline is called *lexical scoping*.<<Lexical scoping dictates\nthat free variables in a procedure are taken to refer to bindings\nmade by enclosing procedure definitions; that is, they are looked up\nin the environment in which the procedure was defined. We will see\nhow this works in detail in chapter 3 when we study environments and\nthe detailed behavior of the interpreter.>>\n\n> This would still work in Clojure, if one were so inclined, it would\njust define all of these functions globally (as is explained above).\n\n```clj\n(defn sqrt [x]\n  (defn good-enough? [guess]\n    (< (abs (- (square guess) x)) 0.001))\n  (defn improve [guess]\n    (average guess (/ x guess)))\n  (defn sqrt-iter [guess]\n    (if (good-enough? guess)\n        guess\n        (sqrt-iter (improve guess))))\n  (sqrt-iter 1.0))\n```\n\nWe will use block structure extensively to help us break up large\nprograms into tractable pieces.<<Embedded definitions must come\nfirst in a procedure body. The management is not responsible for\nthe consequences of running programs that intertwine definition and\nuse.>> The idea of block structure originated with the programming\nlanguage Algol 60. It appears in most advanced programming\nlanguages and is an important tool for helping to organize the\nconstruction of large programs."))))
