<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="http://jekyllrb.com" version="3.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-06-02T22:31:53-07:00</updated><id>http://localhost:4000/</id><title type="html">Aaron Niskin’s Blog</title><subtitle>Not just another mathy blog! Now with more... Aaron!</subtitle><author><name>amniskin</name></author><entry><title type="html">Prisoners and The Lightblub</title><link href="http://localhost:4000/blog/2018/06/02/prisoner_lightbulb.html" rel="alternate" type="text/html" title="Prisoners and The Lightblub" /><published>2018-06-02T00:00:00-07:00</published><updated>2018-06-02T00:00:00-07:00</updated><id>http://localhost:4000/blog/2018/06/02/prisoner_lightbulb</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/02/prisoner_lightbulb.html">&lt;h2 id=&quot;the-scenario&quot;&gt;The scenario:&lt;/h2&gt;

&lt;p&gt;One day, a drunk warden waltzes into her prison feeling particularly sadistic and decides to put on a little show for herself. She told her guards to gather 100 prisoners into a room so that she could talk to them. When in front of the group of prisoners, she tells them of her plan: All of their prison sentences have been extended indefinitely, but they have a chance to earn their freedom – through her game.&lt;/p&gt;

&lt;p&gt;She explained that she arranged for a room to be secured and left with just a single light bulb inside and that nobody but them would be allowed inside. They would then be brought into the room one prisoner per day and allowed to turn the light on or off. It’s guaranteed that nobody else would be given access to the room other than themselves, and that in no way would anyone mess with the light.&lt;/p&gt;

&lt;p&gt;They were told that at any time, anyone could come forward and say “I believe all prisoners has been in the room” if they believe it, and if it’s true, all the prisoners go free. If the prisoner says the phrase and it’s not true, they all are killed by firing squad.&lt;/p&gt;

&lt;p&gt;Now, you can’t just say the phrase on the 100th day – I mean, you could, but it probably wouldn’t work because the prisoners can be sent in multiple times.&lt;/p&gt;

&lt;p&gt;What you know:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;There are 100 prisoners&lt;/li&gt;
  &lt;li&gt;There is a room with a light bulb that only these prisoners have access to&lt;/li&gt;
  &lt;li&gt;They can really only communicate through this light bulb&lt;/li&gt;
  &lt;li&gt;At any time, any one of them can stop the game, and if all prisoners have been in the room with the light, they go free. If not all prisoners have been in that room, then they all lose the game (or get killed, or the warden steps on their pet bunny or something – something negative happens).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What’s your strategy?&lt;/p&gt;

&lt;h3 id=&quot;hints-click-to-unblur&quot;&gt;Hints (click to unblur)&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;There’s a non-zero probability (assuming the choice of prisoner is random) that it’s 100,000 years before all prisoners go into that room. So don’t try to find a perfect solution. Just any solution will work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;If you haven’t found any solutions, how about putting one prisoner in charge?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;some-solutions&quot;&gt;Some Solutions&lt;/h3&gt;

&lt;h4 id=&quot;solution-1&quot;&gt;Solution 1&lt;/h4&gt;

&lt;div class=&quot;hint&quot;&gt;
  &lt;p&gt;You can put one prisoner in charge and only allow that prisoner to ever turn off the light. Then, whenever anyone else gets in the room, if the light is off and they’ve never turned it on before, turn it on; otherwise, just leave it be. The chosen prisoner ends the game when he or she turns the light off for the 99th time.&lt;/p&gt;

  &lt;p&gt;That solution is okay, but not great. It gets the job done, but it’ll take forever.&lt;/p&gt;
&lt;/div&gt;

&lt;h4 id=&quot;solution-2&quot;&gt;Solution 2&lt;/h4&gt;

&lt;div class=&quot;hint&quot;&gt;
  &lt;p&gt;My favorite solution is kinda complicated, but it’s really cool…&lt;/p&gt;

  &lt;p&gt;So, you pick a number, say, 10. Then, you say make the following rules:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;You assign a notion of “value” to a light-bulb.
      &lt;ul&gt;
        &lt;li&gt;For the first ten days, a light bulb is said to have a value of 1.&lt;/li&gt;
        &lt;li&gt;Then every ten days after that, the value doubles, until it gets to 64&lt;/li&gt;
        &lt;li&gt;After 64, it goes back to 1.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Everybody keeps a record in their own respective cells of the value they currently have.&lt;/li&gt;
    &lt;li&gt;When a prisoner enters the room, if the light is on, the prisoner turns it off and adds the current day’s value to their own.
      &lt;ul&gt;
        &lt;li&gt;Then, the prisoner writes out the value they have in binary.&lt;/li&gt;
        &lt;li&gt;The value of the light bulb progresses to the next day’s value, let’s call it \(\lambda\).&lt;/li&gt;
        &lt;li&gt;If the prisoner has a “1” in the \(\lambda\) place of the binary description of his or her own value, they turn on the light and decrease their own value by \(\lambda\).&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;So, for example, let’s pick 10 as our number of days per value thing. Then if today is the 9th day in the full cycle, then today’s value is 1 (and so is tomorrow’s). So if the light is on when I get in, I turn it off and increment my value. Let’s assume the light is on and I have a value of 20 (or 0010100, in our description). Then I turn off the light and find that I have a value of 21. Since tomorrow’s value is 1, and my binary description is 0010101, I return that point and turn on the light bulb, leaving me with 0010100. If on the other hand, it had been the tenth day and tomorrow’s value were 2, since I’d have a 0 in the 2’s place, I’d keep the point.&lt;/p&gt;

  &lt;p&gt;The reason I find this solution so interesting is, it really gets to the core of money and value. In this case, the light is only twice as valuable on day 11 as it is on day 10 because we agree to artificially make it so, but as long as we’re doing that, the results are astounding and very real.&lt;/p&gt;

  &lt;p&gt;Also, this is a completely decentralized solution! Come on, that’s amazing!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Aaron Niskin</name></author><category term="Riddles" /><category term="puzzles" /><category term="riddles" /><category term="fun&amp;games" /><category term="pokeaneyeout" /><summary type="html">A group of prisoners encounter an evil warden and his sadistic lightbulb. Who will win?</summary></entry><entry><title type="html">The blue-eyed reconing!</title><link href="http://localhost:4000/blog/2018/06/02/blue_eyed_people.html" rel="alternate" type="text/html" title="The blue-eyed reconing!" /><published>2018-06-02T00:00:00-07:00</published><updated>2018-06-02T00:00:00-07:00</updated><id>http://localhost:4000/blog/2018/06/02/blue_eyed_people</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/02/blue_eyed_people.html">&lt;h2 id=&quot;the-scenario&quot;&gt;The scenario:&lt;/h2&gt;

&lt;p&gt;There’s an island far away from anything we would call recognizable with a particularly strange custom: in this town, any person who discovers his or her own eye color is compelled to go to the town square at 9:00AM the following morning and kill him or her self publicly, so it goes. It’s a part of their lives and they all obey this custom diligently.&lt;/p&gt;

&lt;p&gt;This island is so secluded that the inhabitants had not seen an outsider until the one fateful day Pat stopped by. On that day, they were so excited to see an outsider that they asked Pat to give a speech in front of the whole town. Not knowing the town’s customs, in Pat’s opening remarks, Pat mentioned, “it’s nice to see other blue eyed people out here”. The question is: what happens?&lt;/p&gt;

&lt;p&gt;What you know:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The town is very secluded and hasn’t seen any outsiders before&lt;/li&gt;
  &lt;li&gt;The town has the custom that they kill themselves when they find out their own eye color, so it goes.&lt;/li&gt;
  &lt;li&gt;A newcomer casually mentions in front of the whole town “it’s nice to see other blue eyed people here”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What happens?&lt;/p&gt;

&lt;h3 id=&quot;hints-click-to-unblur&quot;&gt;Hints (click to unblur)&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;Think inductively&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;This is kinda a repeat (sorry for that) but start with the case where there’s only 1 blue eyed person, then go from there.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;a-solution&quot;&gt;A solution&lt;/h2&gt;

&lt;h3 id=&quot;the-solution&quot;&gt;The Solution&lt;/h3&gt;
&lt;p class=&quot;hint&quot;&gt;If there are \(n\) many blue eyed people in the town (assuming blue eyed people are the minority), then on the \(n^\text{th}\) days, all the blue eyed people kill themselves, so it goes.&lt;/p&gt;

&lt;h3 id=&quot;the-explanation&quot;&gt;The Explanation&lt;/h3&gt;
&lt;div class=&quot;hint&quot;&gt;
&lt;div&gt;
    &lt;p&gt;If there is only 1 blue eyed person, then (s)he looks around after the speaker leaves and says, “there are no blue eyed people here!”, then quickly realizes that (s)he must be the only blue eyed person and (s)he goes to the town square the next day and commits suicide, so it goes.&lt;/p&gt;

    &lt;p&gt;If there are \(n+1\) many blue eyed people, then each looks around and sees only \(n\) and therefore concludes that \(n\) days from now all of those poor bastards are going to kill themselves, so it goes. But then the \(n^\text{th}\) day comes and none of them commit suicide (because they each think they’re not blue eyed, but the other \(n\) are). Then they each come to the conclusion that there must be another blue-eyed person around, and since they don’t see one, they each conclude that it’s themself. So on the \(n+1^\text{th}\) day, they all go to the town square, so it goes.&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;</content><author><name>Aaron Niskin</name></author><category term="Riddles" /><category term="puzzles" /><category term="riddles" /><category term="fun&amp;games" /><category term="pokeaneyeout" /><summary type="html">In a world of blue eyed and brown eyed people, it's dangerous to know your own eye color.</summary></entry><entry><title type="html">The 7 person game-show riddle</title><link href="http://localhost:4000/blog/2018/06/02/7_friends.html" rel="alternate" type="text/html" title="The 7 person game-show riddle" /><published>2018-06-02T00:00:00-07:00</published><updated>2018-06-02T00:00:00-07:00</updated><id>http://localhost:4000/blog/2018/06/02/7_friends</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/02/7_friends.html">&lt;h2 id=&quot;the-scenario&quot;&gt;The scenario:&lt;/h2&gt;

&lt;p&gt;You and six of your friends are going on a game show. When you get there, you’ll be placed in a green room and told the rules of the game so that you all can strategize. Once you all agree on a strategy, you’ll be taken on stage where you’ll each be put in your own respective isolation chambers. Once your whole team is in their respective chambers, you will each be assigned a number between 1 and 7 (inclusive and possibly repeating). You’ll all be shown everyone else’s numbers, but not your own. Your whole team wins if any one member can guess his or her own number correctly.&lt;/p&gt;

&lt;p&gt;What you know:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Each member of your team is assigned a number between 1 and 7 inclusive and possibly repeating.&lt;/li&gt;
  &lt;li&gt;Each member gets only one guess.&lt;/li&gt;
  &lt;li&gt;There’s no penalty for wrong guesses.&lt;/li&gt;
  &lt;li&gt;There’s absolutely no communication between members while the game is on.&lt;/li&gt;
  &lt;li&gt;You all win if at least one person from your team guesses correctly.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Can you come up with a winning strategy?&lt;/p&gt;

&lt;h3 id=&quot;hints-click-to-unblur&quot;&gt;Hints (click to unblur)&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;Start with a simpler case (like only 2 players, then 3 players, etc.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;Consider what is conserved.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;Consider modular arithmetic&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;a-solution&quot;&gt;A solution&lt;/h2&gt;

&lt;h3 id=&quot;a-description&quot;&gt;A description&lt;/h3&gt;
&lt;p class=&quot;hint&quot;&gt;Regardless of who’s looking at the numbers, the sum of all the numbers (including your own) must be the same. The problem is that you don’t know what the missing number is (your own). But, if we make an assumption as to what the sum is, we could then solve for our own. But that leaves too many options (we could assume that the sum would be 7 or 49 or anything between). Luckily we don’t need all of that information. We really only need to assume something about what the sum is mod 7. For instance, if you knew that the sum of all the numbers was \(3 \pmod 7\), and you see the numbers 1, 2, 3, 4, 5, 6, (the sum of which is \(21 \equiv 0 \pmod 7\)), you would know that your number is 3. But that assumes that you know what the sum is (mod 7). Luckily you have a total of 7 people on your team!&lt;/p&gt;

&lt;h3 id=&quot;the-strategy&quot;&gt;The strategy&lt;/h3&gt;
&lt;p class=&quot;hint&quot;&gt;In the green room you assign a number from 1 to 7 (inclusive and not repeating) to each person in your team. So each person has a number and all numbers from 1 to 7 are represented. Then you all go into your respective isolation chambers and get your numbers and solve for your own assuming the sum mod 7 is whatever number you were assigned. Since the sum must be something from 1 to 7 mod 7, we know one person had the correct assumption, and since given the assumption, the solution is unique, we know one person will guess his or her own number correctly. And we’re done!&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Riddles" /><category term="puzzles" /><category term="riddles" /><category term="fun&amp;games" /><category term="pokeaneyeout" /><summary type="html">You and 7 friends are assigned numbers from 1-7 and you have to guess your own</summary></entry><entry><title type="html">2 ropes and a matchbook</title><link href="http://localhost:4000/blog/2018/06/02/2_ropes_60_min.html" rel="alternate" type="text/html" title="2 ropes and a matchbook" /><published>2018-06-02T00:00:00-07:00</published><updated>2018-06-02T00:00:00-07:00</updated><id>http://localhost:4000/blog/2018/06/02/2_ropes_60_min</id><content type="html" xml:base="http://localhost:4000/blog/2018/06/02/2_ropes_60_min.html">&lt;h2 id=&quot;the-scenario&quot;&gt;The scenario:&lt;/h2&gt;

&lt;p&gt;You’re given 2 ropes and a matchbook. You know a priori that these two ropes each take an hour to burn, but they don’t burn at an even rate. For instance, the first rope might take 1 minute to burn through the first half and 59 minutes to burn the second, and the other rope might be completely different.&lt;/p&gt;

&lt;p&gt;Can you measure 45 minutes using only these two ropes and the matchbook?&lt;/p&gt;

&lt;p&gt;What you know:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You have two ropes and a matchbook.&lt;/li&gt;
  &lt;li&gt;The ropes take an hour to burn completely.&lt;/li&gt;
  &lt;li&gt;The rate of burn is inconsistent.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;hints-click-to-unblur&quot;&gt;Hints (click to unblur)&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;Can you measure 30 minutes?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p class=&quot;hint&quot;&gt;You may have to do two things at once&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;a-solution&quot;&gt;A solution&lt;/h2&gt;

&lt;h3 id=&quot;a-description-and-strategy&quot;&gt;A description (and strategy)&lt;/h3&gt;
&lt;p class=&quot;hint&quot;&gt;You can measure 60 minutes easily by just burning a rope. You can measure 30 minutes by burning both ends of a rope. So you can measure 45 minutes by lighting two ends of one rope and one end of the other, then when the first rope burns out, light the other end of the second rope. It’ll be 45 minutes because the first rope takes 30 minutes to burn, so there will be 30 minutes left on the second rope when you light the second end, thereby turning the 30 minutes of rope into 15 minutes.&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Riddles" /><category term="puzzles" /><category term="riddles" /><category term="fun&amp;games" /><category term="pokeaneyeout" /><summary type="html">You're given two ropes that take 60 minutes to burn and a matchbook, and you need to measure 45 minutes.</summary></entry><entry><title type="html">Let’s Cover Homology (pt 1)</title><link href="http://localhost:4000/blog/2018/04/12/homology.html" rel="alternate" type="text/html" title="Let's Cover Homology (pt 1)" /><published>2018-04-12T00:00:00-07:00</published><updated>2018-04-12T00:00:00-07:00</updated><id>http://localhost:4000/blog/2018/04/12/homology</id><content type="html" xml:base="http://localhost:4000/blog/2018/04/12/homology.html">&lt;h1 id=&quot;topology&quot;&gt;Topology&lt;/h1&gt;

&lt;h2 id=&quot;what-is-it&quot;&gt;What is it?&lt;/h2&gt;

&lt;p&gt;Topology is essentially the study of proximity, which is a close analogue for shape. The specifics of how that’s done are not really the point of this post. That’s all for this section.&lt;/p&gt;

&lt;h2 id=&quot;how-is-it-related-to-analyzing-data&quot;&gt;How is it related to analyzing data?&lt;/h2&gt;

&lt;p&gt;Most data analysis techniques are already about quantifying some geometric attributes. For instance, when you fit a linear model, you’re really just imposing an affine model on the data, and computing the appropriate parameters (slope and intercept). But these sorts of things work best if you have an idea for what an appropriate shape would be. That’s one area where topology might be able to help. But to hear more about that, you’ll have to wait for my next post.&lt;/p&gt;

&lt;p&gt;There is a notion of equivalence (called isomorphism) of topological spaces (bi-continuous bijections). Basically, we consider two topological spaces to be equivalent if one can be continuously transformed into the other and back. That’s actually a very powerful description that captures a lot of non-linearities and things like that. For instance, an egg shape, a sphere, a pyramid, and a tetrahedron are all isomorphic topological spaces, but not a doughnut (torus). And those kinda make sense. But there are some counter-intuitive examples. For instance, if you were to take one of those long clown balloons and tie it up into a poodle, it would also be isomorphic to the bunch above. And, as the joke goes, donuts are isomorphic to coffee cups. I know what you’re thinking. This topology stuff sounds super cool.&lt;/p&gt;

&lt;p&gt;So topology would make a wonderful (admittedly incomplete) description of data. But there are some problems: mainly that this whole story breaks down in higher dimensions. Luckily, there is an analogue that can be computed.&lt;/p&gt;

&lt;h1 id=&quot;homology&quot;&gt;Homology&lt;/h1&gt;

&lt;h2 id=&quot;what-is-it-1&quot;&gt;What is it?&lt;/h2&gt;

&lt;p&gt;Homology is (in an overly-simplified sentence), counting the number of holes. That’s actually a lot more information than you might initially think. It’s actually sufficient to completely classify the space in lower dimensions, and a good approximation in higher ones. Either way, if we knew that info about our data, we’d capture a lot of the non-linear relationships. Either way, it’ll be fun, so let’s get into it.&lt;/p&gt;

&lt;h1 id=&quot;how-to-computes&quot;&gt;How to computes…&lt;/h1&gt;

&lt;h2 id=&quot;triangulation&quot;&gt;Triangulation&lt;/h2&gt;

&lt;h3 id=&quot;simplices&quot;&gt;Simplices&lt;/h3&gt;

&lt;p&gt;A &lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex&quot;&gt;simplex&lt;/a&gt; is a collection of $n$ points with the property that no one point lies in the subspace defined by the other $n-1$ points. The idea is that it’s the minimal number of points with an $n-1$ dimensional convex hull – or, said differently, the minimal number of points to make an $n-1$ dimensional shape. For instance, if we consider $\mathbb{R}^2$ as our ambient space, then the only simplices that exist are 0, 1, or 2 simplices: the 0 simplices being points, 1 simplices being lines and 2 simplices being tetrahedra. If we look at these simplices like building blocks, we can now make something isomorphic to any shape just by glueing a bunch of these simplices together. But we’ll get to that in a bit.&lt;/p&gt;

&lt;p&gt;Let $\{v_0,v_1,v_2\}$ be a simplex. Firstly, since it’s a simplex with 3 points, it must be a 2-simplex. And since it’s a simplex, we know that $v_0-v_1\notin span(\{v_1-v_2,v_1+v_2\})$ and the same relationship holds for all the rest of the points. This simplex is supposed to represent any 2 dimensional contiguous ball-like thing. For instance, since a filled-in circle can be continuously transformed into a filled-in triangle (which is, in essence what a 2-simplex is), our simplex becomes a proxy for such circles, and squares, and rhombi, and octagons, but not the Apple logo. But if you take that stem thing and throw it away so you’re only left with the main apple part of the logo, then yeah, that too.&lt;/p&gt;

&lt;p&gt;So now if we have any single contiguous $N$-D object without any holes, we can represent it topologically by a triangle. So simplices make the building blocks for general shapes, as we’ll see in a bit.&lt;/p&gt;

&lt;h3 id=&quot;simplicial-complexes&quot;&gt;Simplicial Complexes&lt;/h3&gt;

&lt;p&gt;So let’s build a simplicial complex! But wait! I haven’t even defined what that is yet! Meh, let’s just roll with it. So given a bunch of things we can represent by simplices (like the full apple logo, for instance), we can construct a simplicial complex to represent it. Some more examples would be: an air-filled balloon (which we’ll consider to be hollow) on a string, a filled water balloon (which we’ll not consider to be hollow) on a string, or a doughnut. The list goes on, obviously, but I think you get the point. We can represent pretty much anything this way.&lt;/p&gt;

&lt;p&gt;The specifics really only come in when we try to construct the simplicial complex itself. In order to make the thing have the nice characteristics we’ll use later on, we’ll need to make sure our complexes have some properties. But first, we need to know what the face of a simplex is:&lt;/p&gt;

&lt;p&gt;Given a simplex $\{v_0,v_1,…,v_n\}$, a face is the simplex defined by a subset (e.g. $\{v_1,v_2,…,v_n\}$ is a face, and so is the original simplex). If you think of a tetrahedron, for instance, the faces are the four triangular faces we’re used to calling faces as well as the six lines on the edges, and the four individual points. So the faces are kinda similar to our intuitive notion of a face. Now we can define a simplicial complex. A simplicial complex $K$ is a collection of simplices with the following properties (see &lt;a href=&quot;http://mathworld.wolfram.com/SimplicialComplex.html&quot;&gt;mathworld&lt;/a&gt;):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Each face of a simplex in $K$ is itself a simplex in $K$&lt;/li&gt;
  &lt;li&gt;The intersection of two simplices in $K$ is itself a simplex (hence in $K$)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It’s the second rule that’s really the crux of everything, as we’ll see. But let’s go through some examples…&lt;/p&gt;

&lt;p&gt;The Apple logo can be triangulated by two disjoint 2-simplices (along with all the appropriate faces of the two). So we basically forced the first property to hold, and since the two simplices are disjoint the second property trivially holds.&lt;/p&gt;

&lt;p&gt;The filled water-balloon on a string can be triangulated by a 3-simplex attached to a 1-simplex along with all the appropriate faces. The filled water-balloon part is clearly the 3-simplex, and the string is the 1-simplex. So let’s prove that the two properties hold. The first one holds trivially, since we defined it as the union of all the faces. The second property holds because if you take any two simplices in this complex, either they intersect at the point on top (a 0-simplex) or they don’t intersect at all! (Pardon the hand waving proof there).&lt;/p&gt;

&lt;p&gt;The (hollow) air-filled balloon, on the other hand, is a bit harder to triangulate, but we’ll barrel through it. We can glue four 2-simplices together to be like a hollowed out 3-simplex, then attach a 1-simplex as the string to one of the vertices of the hollow tetrahedron, and we’ll be done. All that’s left is to show the two properties hold. That’s left as an exercise to the reader (ah, the good life).&lt;/p&gt;

&lt;p&gt;The doughnut, on the other hand, is a lot more complicated to triangulate. To do that we’d have to specify if we’re talking about the shell of a doughnut or a filled in one. Although this is a fun exercise, the traditional way to triangulate the torus doesn’t have much to do with what we’re going to be using this stuff for, so I’ll take a more data-science type approach to this. If we have a bunch of data arranged in the shape of a torus, we can just take the union of the simplices defined by taking a point and the 3 nearest points to it, and creating the convex hull of those points (or considering them as a 3-simplex).&lt;/p&gt;

&lt;h3 id=&quot;associations&quot;&gt;Associations&lt;/h3&gt;

&lt;p&gt;But it would be useful to triangulate the torus using the more traditional approach. To get you started on the right track, you’ll need another tool: association. An association is basically a way of considering things to be equal. It’s kinda like defining specific teleportation or something. I think it’s best to just work out an example. So let’s triangulate some things (like a sphere – the air-filled balloon, for example) but without using the fact that we’re in 3-D space and using associations instead. Let’s start with two 2-simplices joined at one edge (to make something that looks like a square).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_triangulate_base.png&quot; alt=&quot;sphere&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We then make the following association: we say anything along the line $(\langle1\rangle,\langle2\rangle)$ is associated with things on the line $(\langle4\rangle,\langle3\rangle)$ – where order is important. If we want to make it more formal, we could parameterize the line connecting $\langle1\rangle$ to $\langle2\rangle$ by a parameter $t$ such that $f_0(0) = \langle1\rangle$ and $f_0(1) = \langle2\rangle$. We describe this visually like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_tube.png&quot; alt=&quot;tube&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We’re considering all the points on the top line to be associated with (or equal to) their corresponding points on the bottom line. You can imagine this to be kinda like pacman: when you go off the top edge, you come back from the bottom edge in the same direction (because of the association that we’ve made). So, we might as well fold the paper over and tape the two sides together so as to better visualize the association we’ve made. But when we do that, we notice we have a tube!&lt;/p&gt;

&lt;p&gt;So the association shown above can be described as a tube. Unfortunately, it’s not a simplicial complex though. This can be seen because if we call the top-left triangle $A$, and the bottom-right one $B$, the intersection of $A$ and $B$ is the diagonal line $(\langle1\rangle,\langle3\rangle)$ and the associated line (it’s only one because the two are associated – hence the same line) $(\langle1\rangle,\langle2\rangle) = (\langle4\rangle,\langle3\rangle)$. So the intersection is two lines, which is a simplicial complex, but not a simplex! So this triangulation doesn’t have the second property that we require all simplicial complexes to have.&lt;/p&gt;

&lt;p&gt;We could make it a simplicial complex by dividing the thing into a 9 square grid (so 18 triangles) and then doing the same thing again with the top being associated with the bottom, but it’s a lot to write out. Try it out though. See if you can make it a simplicial complex. If you run into any issues, feel free to email me.&lt;/p&gt;

&lt;p&gt;Moving on… Now if we just flipped the association, we get a möbius strip!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_mobius.png&quot; alt=&quot;m&amp;ouml;bius&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It might be useful to actually break out a piece of paper and do this if you’ve never done it before.&lt;/p&gt;

&lt;p&gt;If we take the tube and add this one association it becomes a torus (a hollow doughnut)!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_torus.png&quot; alt=&quot;torus&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice that we identify which sides are connected by the fact that they share the same symbol (the double arrow is connected to the other double arrow, and the single arrow does likewise).&lt;/p&gt;

&lt;p&gt;If you’re trying it out on paper, make sure you label the points so you can see them! If you reverse the direction one side of the second association, you get something very different – a Klein bottle!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_klein.png&quot; alt=&quot;klein bottle&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I feel like it’s probably a bit cruel of me to have put this after the picture, in case you’ve been trying to make the last one with your paper… It turns out, you can’t make the last one in 3D space. You need to either use an extra dimension or tear the paper, unfortunately. But, it’s interesting to see that flipping the association completely changes the thing – kinda like chirality in chemistry.&lt;/p&gt;

&lt;p&gt;Like if we take the möbius strip and make the following additional association, you get something called the Projective Plane (\(\mathbb{P}^2\) – also not embeddable in 3D space).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_projective.png&quot; alt=&quot;projective plane&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And finally, the following association leads us to a sphere, or, more precisely, the surface of a sphere.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2018/04/12_sphere.png&quot; alt=&quot;sphere&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then, since all the points on the top line (and the bottom, left, and right lines) are all associated, imagine contracting them while keeping the inside of the bag relatively unchanged (as far as area is concerned). So necessarily the bag will puff up like a bubble as the sides squish down to a smaller and smaller hole. Eventually, the edge becomes just a point, and what do we have? Yup, we’ve got a sphere. So that’s one way we can triangulate a sphere.&lt;/p&gt;

&lt;p&gt;The problem is that none of these are simplicial complexes. Why not? Can you fix these so that they become simplicial complexes?&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;So we’ve triangulated some things, defined what simplices and simplicial complexes are, but we haven’t yet found their utility. For that, just stay tuned! In the next episode we’ll go over Betti Numbers and how to compute them using these simplicial complexes!&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Mathematics" /><category term="Data Visualization" /><category term="Statistics" /><category term="Mathematics" /><category term="Topology" /><category term="Algebra" /><category term="Theory" /><summary type="html">What does topology have to do with data?! And what is this topology thing anyway?</summary></entry><entry><title type="html">Decomposition of Autoregressive Models</title><link href="http://localhost:4000/blog/2017/10/25/Autoregression.html" rel="alternate" type="text/html" title="Decomposition of Autoregressive Models" /><published>2017-10-25T13:52:39-07:00</published><updated>2017-10-25T13:52:39-07:00</updated><id>http://localhost:4000/blog/2017/10/25/Autoregression</id><content type="html" xml:base="http://localhost:4000/blog/2017/10/25/Autoregression.html">&lt;h1 id=&quot;autoregression&quot;&gt;Autoregression&lt;/h1&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;This post will be a formal introduction into some of the theory of Autoregressive models. Specifically, we’ll tackle how to decompose an AR(p) model into a bunch of AR(1) models. We’ll discuss the interpretability of these models and howto therein. This post will develop the subject using what seems to be an atypical approach, but one that I find to be very elegant.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1 id=&quot;the-traditional-way&quot;&gt;The traditional way&lt;/h1&gt;

&lt;p&gt;Let $x_t$ be an AR(p) process. So $x_t = \sum\limits_{i=1}^pa_ix_{t-i} + w_t$. We can express $x_t$ thusly:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
x_t =&amp; \sum\limits_{i=1}^pa_ix_{t-i} + w_t \\
x_t - \sum\limits_{i=1}^pa_ix_{t-i} =&amp; w_t \\
\left(1 - \sum\limits_{i=1}^pa_iL^i\right)x_t =&amp; w_t
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Where $L$ is the &lt;strong&gt;lag operator&lt;/strong&gt;. We define the AR polynomial $\Phi$ as $\Phi(L) := \left(1 - \sum\limits_{i=1}^pa_iL^i\right)$. Then as long as we’re considering this polynomial to be over an algebraically closed field (like $\mathbb{C}$), we can factor this polynomial. So&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(L) = c\prod\limits_{i=1}^p(L-\varphi_i)&lt;/script&gt;

&lt;p&gt;Where $\varphi_i$ are the roots of $\Phi$. This polynomial will be the star of our show today. In fact, if we want to understand $\Phi$ (the AR process we’re considering), we need only understand each $x_t = \varphi_ix_{t-1} + w_t$ model. We’ll actually prove this later.&lt;/p&gt;

&lt;p&gt;We’ll be investigating several of its properties but first (just for fun) let’s investigate the conditions under which it’s invertible.&lt;/p&gt;

&lt;p&gt;We can reduce the problem of determining whether or not the AR polynomial is invertible to the problem of inverting each factor. After all, the polynomial is invertible if and only if each factor is. So let’s restrict our considerations to just a single factor for the time being. When will $x-\lambda$ be invertible?&lt;/p&gt;

&lt;p&gt;Now, we recall the Taylor Series Expansion formula from our trusty calculus class.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = \sum\limits_{i=0}^\infty \frac{f^{(i)}(a)}{i!}(x-a)^i&lt;/script&gt;

&lt;p&gt;In general, we tend to use $a=0$ as a good arbitrary choice (the Maclaurin Series), resulting in:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = \sum\limits_{i=0}^\infty \frac{f^{(i)}(0)}{i!}x^i&lt;/script&gt;

&lt;p&gt;Well, if we consider the Taylor expansion of $\frac{1}{x-\lambda}$, we find&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{1}{x-\lambda} =&amp; \frac{-1}{\lambda}(x) + (-1)^1\frac{-1}{\lambda^2}x^2 + (-1)^2\frac{-1}{\lambda^3}x^3 + ... \\
=&amp; \sum\limits_{i=0}^\infty (-1)^{i+1}\frac{1}{\lambda^{i+1}}x^{i+1} \\
=&amp; \sum\limits_{i=1}^\infty (-1)^{i}\frac{1}{\lambda^{i}}x^{i}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Which is square summable if and only if $|\lambda| &amp;gt; 1$. So we see that if the AR roots are all outside the unit circle, then the AR polynomial will be invertible (in such a case, the AR process is called &lt;strong&gt;causal&lt;/strong&gt;).&lt;/p&gt;

&lt;h1 id=&quot;the-new-approach&quot;&gt;The new(?) approach&lt;/h1&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;Let $X_t\in \mathbb{R}^n, A_i\in\mathbb{R}^{n\times n}, B\in\mathbb{R}^{k_0\times n}$, and $p\in\mathbb{N}_{&amp;gt;0}$. Also let, $W_t$ be $k_0$ dimensional white noise. Then, $X_t$ is called a VAR(p) process if,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t = \sum\limits_{i=1}^p A_iX_{t-i} + BW_t&lt;/script&gt;

&lt;p&gt;Basically a VAR(p) model is an analogue of AR(p) models where the scalars are matrices and the variable itself is a vector. The noise in such a model need not be independent per coordinate, nor restricted to only one. In fact, we can have any number of driving noise processes that get mixed together linearly into $X_t$. Hence cometh $B$ – the linear transformation from the driving noise space into the $X_t$ space.&lt;/p&gt;

&lt;p&gt;Furthermore, let’s say that we don’t directly observe $X_t$ directly, but rather we observe some $Y_t$ that’s a linear function of $X_t$ (plus some noise). Formally, we observe $Y_t$ s.t.:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_t = C X_t + D U_t&lt;/script&gt;

&lt;p&gt;Where $Y_t \in\mathbb{R}^m, C\in\mathbb{R}^{m\times n}, D\in \mathbb{R}^{k_1\times m}$. And again, $U_t$ is $k_1$ dimensional white noise.&lt;/p&gt;

&lt;p&gt;Here $D$ serves the same purpose as $B$ did above, but for the observations themselves.&lt;/p&gt;

&lt;p&gt;This is called a “State Space” model.&lt;/p&gt;

&lt;h2 id=&quot;examplificate&quot;&gt;Examplificate&lt;/h2&gt;

&lt;p&gt;How does this relate to our star (the AR polynomial $\Phi$)? Let’s try to express an AR(p) process as a VAR(1) process…&lt;/p&gt;

&lt;p&gt;Let $x_t$ be an AR(p) process. That is to say, $x_t = \sum\limits_{i=1}^p a_ix_{t-i} + w_t$ where $w_t$ is some white noise process.&lt;/p&gt;

&lt;p&gt;Let $W_t$ be a 1 dimensional white-noise processes such that $W_t = w_t$. We define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t := \left[\begin{matrix} x_t \\ x_{t-1} \\ \vdots \\ x_{t-(p-1)} \end{matrix}\right]&lt;/script&gt;

&lt;p&gt;Then, we can see that the first coordinate of $X_t$ is always $x_t$. Our notation for this will be $X_t[0] = x_t$.&lt;/p&gt;

&lt;p&gt;Furthermore, let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A = \left[\begin{matrix}
a_1 &amp; a_2 &amp; \dots &amp; a_{p-1} &amp; a_p \\
1 &amp; 0 &amp; \dots &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; \dots &amp; 0 &amp; 0 \\
 &amp;  &amp; \ddots &amp; &amp; \\
0 &amp; \dots &amp; 0 &amp; 1 &amp; 0 \\
\end{matrix} \right] %]]&gt;&lt;/script&gt;

&lt;p&gt;We can see that for $0 &amp;lt; i &amp;lt; p$, we have $(AX_{t-1})[i] = x_{t-i}$, and $(AX_{t-1})[0] = \sum\limits_{i=1}^p a_i x_{t-i} = x_t - w_t$. As it stands, $AX_{t-1}$ is almost $X_t$, just without the added noise in the first coordinate. So let’s add noise to only the first coordinate. To this end, let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;B := \left[\begin{matrix} 1 \\ 0 \\ \vdots \\ 0 \end{matrix}\right]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t = AX_{t-1} + BW_t&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall t \in \mathbb{N}_{&gt;p} (X_t[0] = x_t)&lt;/script&gt;

&lt;p&gt;Now we want $Y_t = x_t$. So we set&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
C = \left[\begin{matrix}1 &amp; 0 &amp; 0 &amp; \dots &amp; 0\end{matrix}\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;That way, $Y_t = CX_t = x_t$ and all is right with the world.&lt;/p&gt;

&lt;p&gt;So yay! We’ve expressed this AR(p) process as a $p$ dimensional $VAR(1)$ process! So… Why?&lt;/p&gt;

&lt;h2 id=&quot;why-do&quot;&gt;Why do?&lt;/h2&gt;

&lt;p&gt;Well, one natural question to ask at this point is, what are the eigenvalues of $A$?&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
0 =&amp; \det(A - \lambda I) \\
=&amp; \left\|\begin{matrix}
a_1 - \lambda &amp; a_2 &amp; \dots &amp; a_{p-1} &amp; a_p \\
1 &amp; -\lambda &amp; \dots &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; \dots &amp; 0 &amp; 0 \\
 &amp;  &amp; \ddots &amp; &amp; \\
0 &amp; \dots &amp; 0 &amp; 1 &amp; -\lambda \\
\end{matrix} \right\| \\
=&amp; (-\lambda)^p + a_1(-\lambda)^{p-1} - a_2(-\lambda)^{p-2} + \dots + (-1)^{p-1}a_p
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;This polynomial is the characteristic polynomial of $A$, so the roots of this polynomial are the eigenvalues of $A$. Let’s see how this relates to $\Phi$…&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
0 =&amp; (-\lambda)^p + a_1(-\lambda)^{p-1} - a_2(-\lambda)^{p-2} + \dots + (-1)^{p-1}a_p \\
(-\lambda)^{-p}(0) =&amp; 1 - a_1\lambda^{-1} - a_2\lambda^{-2} - \dots - a_p\lambda^{-p} \\
\text{Define } L :=&amp; \lambda^{-1} \\
0 =&amp; 1 - a_1L - a_2L^2 - \dots - a_pL^p \\
=&amp; 1 - \sum\limits_{i=1}^pa_iL^i \\
=&amp; \Phi(L)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So the characteristic polynomial is really just $\Phi(L)$ revisited! Furthermore, check this sweetness out…&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\Phi(L) =&amp; c\prod\limits_{i=1}^p\left(L-\varphi_i\right) \\
=&amp; c\prod\limits_{i=1}^p\left(\lambda^{-1}-\varphi_i\right) \Rightarrow \\
\lambda_i =&amp; \frac{1}{\varphi_i}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So we can see that the eigenvalues are actually intimately related with the roots (in fact they’re inverses of each other)! With that in mind, let’s see what happens when we try to diagonalize this matrix $A$. Firstly, let’s assume that $A$ matrix is diagonalizable. I.e., let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\bar H^{-1}AH =&amp; A \Leftrightarrow \\
\bar A =&amp; HAH^{-1}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $H$ is a coordinate transformation (an invertible map) and $\bar A$ is diagonal.&lt;/p&gt;

&lt;p&gt;Then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
X_t =&amp; H^{-1}\bar AH X_{t-1} + BW_t \\
=&amp; H^{-1}\left(\bar AHX_{t-1} + HBW_t\right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So if we let $\tilde X_t = HX_t$, we get&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\tilde X_t =&amp; HX_t \\
=&amp; HH^{-1}\left(\bar AHX_{t-1} + HBW_t\right) \\
=&amp; \bar AHX_{t-1} + HBW_t \\
=&amp; \bar A\tilde X_{t-1} + HBW_t
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So $\tilde X_t$ is a bunch of AR(1) processes (because the matrix $\bar A$ is diagonal), and,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
Y_t =&amp; CX_t \text{ because $U_t=0$ for our scenario}\\
=&amp; CH^{-1}\tilde X_t \\
=&amp; \left(CH^{-1}\right)\tilde X_t
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Which is to say that $Y_t$ is a linear combination of AR(1) processes! So we started out with a general AR(p) process, and found that expressing it as a VAR(1) model allows us to see that this is just a linear combination of AR(1) processes. I think that’s pretty cool. But let’s investigate this a bit further…&lt;/p&gt;

&lt;h1 id=&quot;what-more&quot;&gt;What more?!&lt;/h1&gt;

&lt;p&gt;As per our previous section, we have that $Y_t$, which was really just $x_t$ – our original AR(p) variable, is a linear combination of AR(1) models. More specifically, if we let $F := CH^{-1}$, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
x_t =&amp; Y_t \\
=&amp; F\tilde X_t
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So indeed, $x_t$ is a linear combination of $p$ many AR(1) processes. In fact, since $\tilde X_t = \bar A \tilde X_{t-1} + \left(HB\right)W_t$, we know the AR(1) models explicitly:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\tilde x_{t,i} =&amp; \lambda_i\tilde x_{t-1,i} + w_t \\
\tilde x_{t,i} - \lambda_i\tilde x_{t-1,i} =&amp; w_{t,i} \\
\left(1-\lambda_iL\right)\tilde x_{t,i} =&amp; w_{t,i} \\
\frac{-1}{\lambda_i}\left(L-\lambda_i\right)\tilde x_{t,i} =&amp; w_{t,i} \\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Where $\lambda_i$ is the $i$th eigenvalue of $A$ (hence the $(i,i)$th element of $\bar A$). So we see that the AR(1) processes each have their respective roots from the roots of the original AR polynomial $\Phi$. Pretty cool, right?&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;So we can express any AR(p) model as a linear combination of AR(1) processes (albeit with correlated noise terms), where each AR(1) process is determined by the roots of the AR polynomial (or the characteristic polynomial).&lt;/p&gt;

&lt;p&gt;We’ve essentially reduced the problem of studying AR(p) models to studying their eigenvalues (or AR roots).&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Time Series" /><category term="Statistics" /><category term="Stochastic" /><category term="Autoregression" /><category term="Autoregressive" /><category term="Theory" /><summary type="html">We discuss the decomposition of AR models into components, and how eigenvalues are involved (because they always are).</summary></entry><entry><title type="html">Markov Chain Monte Carlo</title><link href="http://localhost:4000/blog/2017/04/19/MCMC.html" rel="alternate" type="text/html" title="Markov Chain Monte Carlo" /><published>2017-04-19T13:52:39-07:00</published><updated>2017-04-19T13:52:39-07:00</updated><id>http://localhost:4000/blog/2017/04/19/MCMC</id><content type="html" xml:base="http://localhost:4000/blog/2017/04/19/MCMC.html">&lt;h1 id=&quot;text--mc2&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{???} = (MC)^2&lt;/script&gt;&lt;/h1&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;What if we know the relative likelihood, but want the probability distribution?&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{P}(X=x) = \frac{f(x)}{\int_{-\infty}^\infty f(x)dx}&lt;/script&gt;

&lt;p&gt;But what if \( \int f(x)dx \) is hard, or you can’t sample from \( f \) directly?&lt;/p&gt;

&lt;p&gt;This is the problem we will be trying to solve.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;first-approach&quot;&gt;First approach&lt;/h2&gt;
&lt;p&gt;If space if bounded (integral is between \( a,b \)) we can use Monte Carlo to estimate \( \int\limits_a^b f(x)dx \)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pick \( \alpha \in (a,b) \)&lt;/li&gt;
  &lt;li&gt;Compute \( f(\alpha)/(b-a) \)&lt;/li&gt;
  &lt;li&gt;Repeat as necessary&lt;/li&gt;
  &lt;li&gt;Compute the expected value of the computed values&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;what-if-its-a-big-ol-bag-of-nope&quot;&gt;What if it’s a big ol’ bag of nope?&lt;/h2&gt;

&lt;p&gt;What if we can’t sample from \( f(x) \) but can only determine likelihood ratios?&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{f(x)}{f(y)}&lt;/script&gt;

&lt;p&gt;Enter Markov Chain Monte Carlo&lt;/p&gt;

&lt;h1 id=&quot;the-obligatory-basics&quot;&gt;The obligatory basics&lt;/h1&gt;

&lt;p&gt;A &lt;strong&gt;Markov Chain&lt;/strong&gt; is a stochastic process (a collection of indexed random variables) such that \( \mathbb{P}(X_n=x|X_0,X_1,…,X_{n-1}) = \mathbb{P}(X_n=x|X_{n-1}) \).&lt;/p&gt;

&lt;p&gt;In other words, the conditional probabilities only depend on the last state, not on any deeper history.&lt;/p&gt;

&lt;p&gt;We call the set of all possible values of \( X_i \) the &lt;strong&gt;state space&lt;/strong&gt; and denote it by, \( \chi \).&lt;/p&gt;

&lt;h3 id=&quot;transition-matrix&quot;&gt;Transition Matrix&lt;/h3&gt;
&lt;p&gt;Let \( p_{ij} = \mathbb{P}(X_1 = j | X_0 = i) \). We call the matrix \( (p_{ij}) \) the &lt;strong&gt;Transition Matrix&lt;/strong&gt; of \( X \) and denote it \( P \).&lt;/p&gt;

&lt;p&gt;Let \( \mu_n = \left(\mathbb{P}(X_n=0), \mathbb{P}(X_n=1),…, \mathbb{P}(X_n=l)\right) \) be the row vector corresponding to the “probabilities” of being at each state at the \( n \)th point in time (iteration).&lt;/p&gt;

&lt;p&gt;Claim: \( \mu_{i+1} = \mu_0P^{i+1} \)&lt;/p&gt;

&lt;p&gt;Proof:&lt;/p&gt;

&lt;p&gt;if \( i = 0 \):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
(\mu_0 P)_j =&amp; \sum\limits_{i=1}^l\mu_0(i)p_{ij}\\
=&amp;\sum\limits_{i=1}^l\mathbb{P}(X_0=i)\mathbb{P}(X_1=j | X_0=i)\\
=&amp;\mathbb{P}(X_1 = j)\\
=&amp;\mu_1(j)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So: \( \mu_1 = \mu_0P \)&lt;/p&gt;

&lt;p&gt;if \( i &amp;gt; 0 \):&lt;/p&gt;

&lt;p&gt;Then, \( \mu_{i+1} = \mu_iP = (\mu_0P^i)P = \mu_0P^{i+1} \)&lt;/p&gt;

&lt;h3 id=&quot;stationary-distributions&quot;&gt;Stationary Distributions&lt;/h3&gt;
&lt;p&gt;We say that a distribution \( \pi \) is &lt;strong&gt;stationary&lt;/strong&gt; if&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{gather*}\pi P = \pi\end{gather*}&lt;/script&gt;

&lt;h3 id=&quot;main-theorem&quot;&gt;Main Theorem:&lt;/h3&gt;
&lt;p&gt;An irreducible, ergotic Markov Chain \( {X_n} \) has a unique stationary distribution, \( \pi \). The limiting distribution exists and is equal to \( \pi \). And furthermore, if \( g \) is any bounded function, then with probability 1:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim\limits_{N\to\infty}\frac{1}{N}\sum\limits_{n=1}^Ng(X_n) \rightarrow E_\pi(g)&lt;/script&gt;

&lt;p&gt;This really just means that if our Markov Chain has certain properties (basically just that any state can be gotten to from any other state at any time), then we can sample from this Markov Chain, and it’ll have the same distribution as a generic sample from our desired distribution.&lt;/p&gt;

&lt;h2 id=&quot;random-walk-metropolis---hastings&quot;&gt;Random-Walk-Metropolis - Hastings:&lt;/h2&gt;
&lt;p&gt;Let \( f(x) \) be the relative likelihood function of our desired distribution.&lt;/p&gt;

&lt;p&gt;And \( q(y|x_i) \) the known distribution easily sampled from (generally taken to be \( N(x_i,b^2) \) )&lt;/p&gt;

&lt;p&gt;1) Given \( X_0,X_1,…,X_i \), pick \( Y \sim q(y|X_i) \)&lt;/p&gt;

&lt;p&gt;2) Compute \( r(X_i,Y) = \min\left(\frac{f(Y)q(X_i|Y)}{f(X_i)q(Y|X_i)}, 1\right) \)&lt;/p&gt;

&lt;p&gt;3) Pick \( a \sim U(0,1) \)&lt;/p&gt;

&lt;p&gt;4) Set&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X_{i+1} = \begin{cases} Y &amp; \text{if } a &lt; r \\ X_i &amp; \text{otherwise}\end{cases} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;the-confidence-builder&quot;&gt;The Confidence Builder:&lt;/h2&gt;
&lt;p&gt;We would like to sample from and obtain a histogram of the Cauchy distribution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = \frac{1}{\pi}\frac{1}{1+x^2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
q_{01} \sim&amp; N(x,0.1)\\
q_1 \sim&amp; N(x,1)\\
q_{10} \sim&amp; N(x,10)\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Note: Since \( q \) is symmetric, \( q(x|y) = q(y|x) \).&lt;/p&gt;

&lt;h2 id=&quot;pseudocode&quot;&gt;Pseudocode:&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;X_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;MC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;estimation&quot;&gt;Estimation:&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(y\|x) \sim N(x,b^2)&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/04/18-MCMC-Cauchy-Estimation.png&quot; alt=&quot;The many distributions&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/04/18-MCMC-Cauchy-Estimation_TS.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So you can clearly see that the different values of \( b \) lead to wildly different distributions, and therefore wildly different approximations of the end distribution. For example, if the standard deviation on our sampling distribution is very small, our prospective transitions won’t venture out very far, and hence the tails of our distribution will be woefully underrepresented. If, on the other hand, the standard deviation is too large, we will often venture our much further than we should, and the we’ll end up with something like a multi-modal distribution. Basically, the prospective transition states will often be too far out to accept, in which case the current state persists, or it will be just close enough to be accepted. What you end up with is far too many samples from the tails and not enough samples from the beafier parts of the distribution.&lt;/p&gt;

&lt;p&gt;Choosing the “best” value of \( b \) is more of an art than a science, really. This issue will poke its ugly head a little later. But even with that issue, we see clearly that something amazing is happening here.&lt;/p&gt;

&lt;h2 id=&quot;how-is-this-happening&quot;&gt;How is this happening?&lt;/h2&gt;

&lt;p&gt;A property called &lt;strong&gt;detailed balance&lt;/strong&gt;, which means,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi_ip_{ij} = p_{ji}\pi_j&lt;/script&gt;

&lt;p&gt;or in the continuous case:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)P_{xy} = f(y)P_{yx}&lt;/script&gt;

&lt;h3 id=&quot;the-intuition&quot;&gt;The intuition&lt;/h3&gt;

&lt;p&gt;Since what we’re really after is the distribution of the samples and not the order in which they were picked, it’s reasonable to require a notion of (what I’m going to call) equal hopportunity:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)p(y|x) = f(y)p(x|y)&lt;/script&gt;

&lt;p&gt;In other words, the probability of “hopping” from \( x \) to \( y \) should be the same as the reverse, because at the end of the day, both of these two scenarios only mean that \( x \) and \( y \) are in our sample.&lt;/p&gt;

&lt;p&gt;If you work out the math therein (as we will do below), you find that this ratio guarantees equal hopportunity.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x,y) = \min\left(\frac{f(y)q(x|y)}{f(x)q(y|x)},1\right)&lt;/script&gt;

&lt;h3 id=&quot;lets-prove-it&quot;&gt;Let’s prove it!&lt;/h3&gt;

&lt;p&gt;To reiterate, the claim was that this detailed balance property ( \( f(x)P_{xy} = P_{yx}f(y) \) ) guarantees that our likelihood function \( f \) is the stable distribution for our Markov Chain.&lt;/p&gt;

&lt;p&gt;Let \( f \) be the desired distribution (in our example, it was the Cauchy Distribution), and let \( q(y|x) \) be the distribution we draw from.&lt;/p&gt;

&lt;p&gt;First we’ll show that detailed balance implies \( \pi \) (or \( f \) if the distribution is continuous) is the stable distribution!&lt;/p&gt;

&lt;p&gt;Let \( \pi_ip_{ij} = \pi_jp_{ji} \) for discrete or for continuous \( f(i)P_{ij}=P_{ji}f(j) \)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
(\pi P)_i =&amp; \sum\limits_j\pi_jP_{ji} &amp; (fP)(x)=&amp;\int f(y)p(x|y)dy\\
=&amp;\sum\limits_j\pi_iP_{ij} &amp; =&amp; \int f(x)p(y|x)dy\\
=&amp;\pi_i\sum\limits_jP_{ij} &amp; =&amp; f(x)\int p(y|x)dy\\
=&amp;\pi_i &amp; =&amp; f(x)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now we’ll show that the Markov Chain defined by the Metropolis-Hastings algorithm has the detailed balance property (and hence \( f \) is the stable distribution).&lt;/p&gt;

&lt;p&gt;Without any loss of generality, we’ll assume \( f(x)q(y|x) &amp;gt; f(y)q(x|y) \) (if this is not the case, the proof will follow the same with just symbolic changes).&lt;/p&gt;

&lt;p&gt;Note: Since \( f(x)q(y|x) &amp;gt; f(y)q(x|y) \), we know, \( r(x,y) = \frac{f(y)q(x|y)}{f(x)q(y|x)} \), and \( r(y,x) = 1 \).&lt;/p&gt;

&lt;p&gt;Then,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\pi_xp_{xy} =&amp; f(x)\mathbb{P}(X_1=y|X_0=x) &amp; \pi_yp_{yx} =&amp; f(y)\mathbb{P}(X_1=x|X_0=y)\\
=&amp; f(x)\left[q(y|x)\cdot r(x,y)\right] &amp; =&amp;f(y)\left[q(x|y)\cdot r(y,x)\right]\\
=&amp; f(x)\left[q(y|x)\cdot \frac{f(y)q(x|y)}{f(x)q(y|x)}\right] &amp; =&amp;f(y)\left[q(x|y)\cdot 1\right]\\
=&amp; f(y)q(x|y) &amp; =&amp;f(y)q(x|y)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;modeling-change-point-models-in-astrostatistics&quot;&gt;Modeling Change Point Models in Astrostatistics.&lt;/h2&gt;

&lt;p&gt;This was taken from a Penn State statistics summer program website located at &lt;a href=&quot;http://sites.stat.psu.edu/~mharan/MCMCtut/COUP551_rates.dat&quot;&gt;stat.psu.edu&lt;/a&gt;. A detailed walk-through of the process PSU took with this project can be found at that site. The data is a time series of light emission recorded and aggregated over periods of 10000 seconds (just under 3 hours). A plot of the time series can be seen below for your convenience.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/04/18_psu_ts.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea (with this data) is that the emissions can be modeled by two Poisson distributions and a change point. The data will be modeled by the first Poisson until the change point, and then it switches to the second Poisson.&lt;/p&gt;

&lt;p&gt;So we start out with a multi-parameter model, and through some Bayesian inference you arrive at a pretty nasty looking posterior distribution. You’d like to sample this distribution to obtain, say, the mean \( k \) (change point) value along with a 95% confidence interval. Since you need that confidence interval, standard optimization methods won’t suffice: we’d need the distribution of \( k \)s. For this, we can use MCMC!&lt;/p&gt;

&lt;p&gt;The posterior distribution we would like to sample from is this:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
f(k,\theta,\lambda,b_1,b_2 | Y) \alpha&amp; \prod\limits_{i=1}^k\frac{\theta^{Y_i}e^{-\theta}}{Y_i!} \prod\limits_{i=k+1}^n\frac{\lambda^{Y_i}e^{-\lambda}}{Y_i!} \\
&amp;\times\frac{1}{\Gamma(0.5)b_1^{0.5}}\theta^{-0.5}e^{-\theta/b_1} \times\frac{1}{\Gamma(0.5)b_2^{0.5}}\theta^{-0.5}e^{-\theta/b_2}\\
&amp;\times\frac{e^{-1/b_1}}{b_1}\frac{e^{-1/b_2}}{b_2}\times \frac{1}{n}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;This distribution is pretty gnarly and since I don’t really know how to sample from this (beyond a blind search), we would like to use MCMC. Metropolis-Hastings (at least how we’ve discussed it) clearly doesn’t work here because this is multidimensional. For that we introduce another MCMC algorithm: &lt;strong&gt;Gibbs Sampling&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;gibbs-sampling&quot;&gt;Gibbs Sampling&lt;/h3&gt;

&lt;p&gt;The basic pseudocode is this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_X&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_Y&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_Z&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;We&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;turn&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can combine Gibbs with Metropolis quite easily:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_X&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_Y&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_Z&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;prospect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prospect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prospect&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;We&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;turn&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So, basically, you update one at a time.&lt;/p&gt;

&lt;p&gt;Using this algorithm, we can analyze the data from the PSU website we mentioned above. In fact we did that very thing. Below you’ll find some graphs depicting the distribution of \( k \) values.&lt;/p&gt;

&lt;!--
```python
def psu_mcmc(X, q, numIters=10000):
    theta, lambd, k, b1, b2 = 1, 1, 20, 1, 1
    thetas, lambds, ks, b1s, b2s = [], [], [], [], []
    n = len(X)
    def f_k(theta, lambd, k, b1, b2):
        if 0 &lt;= k and k &lt;= n:
            return theta**sum(X[:k])*lambd**sum(X[k:])*np.exp(-k*theta-(n-k)*lambd)
        elif k &lt; 0:
            return lambd**sum(X)*np.exp(-n*lambd)
        elif k &gt; n:
            return theta**sum(X)*np.exp(-n*theta)
    def f_t(theta, k, b1):
        return theta**(sum(X[:k])+0.5)*np.exp(-theta*(k+1.0)/b1)
    def f_l(lambd, k, b2):
        return lambd**(sum(X[k:])+0.5)*np.exp(-lambd*((n-k)+1.0)/b2)
    def f_b(b, par):
        return np.exp(-(1 + par) / b) / (b*np.sqrt(b))
    for i in range(numIters):
        tmp = q(theta)
        if tmp &lt; np.infty:
            r = min(1, f_t(tmp,k,b1)/f_t(theta,k,b1))
            if np.random.uniform(0,1) &lt; r:
                theta = tmp
        tmp = q(lambd)
        if tmp &lt; np.infty:
            r = min(1, f_l(tmp,k,b2)/f_l(lambd,k,b2))
            if np.random.uniform(0,1) &lt; r:
                lambd = tmp
        tmp = q(b1)
        if tmp &lt; np.infty:
            r = min(1, f_b(tmp, theta)/f_b(b1, theta))
            if np.random.uniform(0,1) &lt; r:
                b1 = tmp
        tmp = q(b2)
        if tmp &lt; np.infty:
            r = min(1, f_b(tmp, lambd)/f_b(b2, lambd))
            if np.random.uniform(0,1) &lt; r:
                b2 = tmp
        tmp = q(k)
        if tmp &lt; np.infty:
            r = min(1, f_k(theta, lambd, tmp, b1, b2) /
                    f_k(theta, lambd, k, b1,b2))
            if np.random.uniform(0,1) &lt; r:
                k = tmp
        thetas.append(theta)
        lambds.append(lambd)
        b1s.append(b1)
        b2s.append(b2)
        ks.append(k)
    return np.array([thetas,lambds,ks,b1s,b2s])
```


```python
%%bash
if [ ! -f tmp/psu_data.tsv ]
then
wget http://sites.stat.psu.edu/~mharan/MCMCtut/COUP551_rates.dat -O tmp/psu_data.tsv
fi
```


```python
psu_data = []
with open(&quot;tmp/psu_data.tsv&quot;, &quot;r&quot;) as f:
    title = f.readline()
    for line in f:
        tmpArr = [x.strip() for x in line.split(&quot; &quot;)]
        psu_data.append([int(x) for x in tmpArr if x != &quot;&quot;][1])
psu_data = np.array(psu_data)
psu_data
```




    array([11,  3,  5,  9,  3,  4,  5,  5,  5,  5, 13, 18, 27,  8,  4, 10,  8,
            3, 12, 10, 10,  3,  9,  8,  5,  9,  4,  6,  1,  5, 14,  7,  9, 10,
            8, 13,  8, 11, 11, 10, 11, 13, 10,  3,  8,  5])




```python
mcmc2 = psu_mcmc(psu_data, q(1), 1000)

fig = plt.figure()
fig.suptitle(&quot;MCMC values for Change Point&quot;)
plt.subplot(2,1,1)
plt.hist(mcmc2[2] % len(psu_data), normed=True)
plt.subplot(2,1,2)
plt.plot(mcmc2[2])
plb.savefig(&quot;tmp/psu_graphs1.png&quot;)
plt.show()
```
--&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/04/18_psu_graphs1.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;!--
```python
plt.plot(psu_data)
plt.title(&quot;PSU Data&quot;)
plb.savefig(&quot;tmp/psu_ts.png&quot;)
plt.show()
```
--&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Random-Walk-Metropolis-Hastings
    &lt;ul&gt;
      &lt;li&gt;Can be used to sample difficult univariate distributions relatively easily
        &lt;ul&gt;
          &lt;li&gt;Have to tune the sampling parameter&lt;/li&gt;
          &lt;li&gt;Curse of dimensionality in tuning parameters&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Requires \( f \) to be defined on all of \( \mathbb{R} \)
        &lt;ul&gt;
          &lt;li&gt;Transform as needed&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gibbs Sampling
    &lt;ul&gt;
      &lt;li&gt;Turn high dimensional sampling into iterative one-dimensional sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gibbs with Metropolis-Hastings
    &lt;ul&gt;
      &lt;li&gt;Lovely&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bibliography&quot;&gt;Bibliography&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://sites.stat.psu.edu/~mharan/MCMCtut/MCMC.html&quot;&gt;Summer School in Astrostatistics&lt;/a&gt;&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Sampling" /><category term="Statistics" /><category term="Stochastic" /><category term="Monte Carlo" /><category term="Markov Chain" /><category term="MCMC" /><summary type="html">Markov Chain Monte Carlo is a tool for sampling otherwise intractible distributions. In this post, we'll go through some descriptions, reasoning, and examples therein.</summary></entry><entry><title type="html">Linear Regression – The Basics</title><link href="http://localhost:4000/blog/2017/02/21/What-Is-Linear-Regression.html" rel="alternate" type="text/html" title="Linear Regression -- The Basics" /><published>2017-02-20T23:24:43-08:00</published><updated>2017-02-20T23:24:43-08:00</updated><id>http://localhost:4000/blog/2017/02/21/What-Is-Linear-Regression</id><content type="html" xml:base="http://localhost:4000/blog/2017/02/21/What-Is-Linear-Regression.html">&lt;h3 id=&quot;the-basics&quot;&gt;The basics&lt;/h3&gt;

&lt;p&gt;Yeah. It’s not a good sign if I’m starting out already repeating myself. But
that’s how things seem to be with linear regression, so I guess it’s fitting.
It seems like every day one of my professors will talk about linear regression,
and it’s not due to laziness or lack of coordination. Indeed, it’s an
intentional part of the curriculum here at New College of Florida because of
how ubiquitous linear regression is. Not only is it an extremely simple yet
expressive formulation, it’s also the theoretical basis of a whole slew of
other tactics. Let’s just get right into it, shall we?&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3 id=&quot;linear-regression&quot;&gt;Linear Regression:&lt;/h3&gt;

&lt;p&gt;Let’s say you have some data from the real world (and hence riddled with
real-world error). A basic example for us to start with is this one:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/02/21-linear-regression_scatterPoints.png&quot; alt=&quot;Data suitable for Linear Regression&quot; title=&quot;Some Example Data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There’s clearly a linear trend there, but how do we pick which linear trend would be the best? Well, one thing we could do is pick the line that has the least amount of error from the prediction to the actual data-point. To do that, we have to say what we mean by “least amount of error”. For this post, we’ll calculate that error by squaring the difference between the predicted value and the actual value for every point in our data set, then averaging those values. This standard is called the Mean-Squared-Error (MSE). We can write the MSE as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{N}\sum\limits_{i=1}^N\left(\hat Y_i - Y_i\right)^2&lt;/script&gt;

&lt;p&gt;where \( \hat Y_i\) is our predicted value of \(Y_i\) for a give \(X_i\). Being as how we want a linear model (for simplicity and extensibility), we can write the above equation as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^N\left(\alpha + \beta X_i - Y_i\right)^2&lt;/script&gt;

&lt;p&gt;for some \( \alpha, \beta \) that we don’t yet know. But since we want to minimize that error, we can take some derivatives and solve for \( \alpha, \beta \)! Let’s go ahead and do that! We want to minimize&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^N\left(\alpha + \beta X_i - Y_i\right)^2&lt;/script&gt;

&lt;p&gt;We can start by finding the \( \hat\alpha \) such that, \( \frac{d}{d\alpha}\sum\limits_{i=1}^N\left(\alpha + \beta X_i - Y_i\right)^2 = 0 \). And as long as we don’t forget the chain rule, we’ll be alright…&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum\limits_{i=1}^N2\left(\alpha + \beta X_i - Y_i\right) =&amp; 0\Longrightarrow\\
\sum\limits_{i=1}^N\left(\alpha + \beta X_i - Y_i\right) =&amp; 0 \Longrightarrow\\
N\alpha + N\beta\bar X - N\bar Y =&amp; 0\Longrightarrow\\
\alpha =&amp; \bar Y - \beta\bar X \end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;and we’ll find the \( \beta \) such that \( \frac{d}{d\beta}\sum\limits_{i=1}^N\left(\alpha + \beta X_i - Y_i\right)^2 = 0 \)&lt;/p&gt;

&lt;p&gt;And following a similar pattern we find (sorry for the editing… Wordpress.com isn’t the greatest therein):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum\limits_{i=1}^N2X_i\left(\alpha + \beta X_i - Y_i\right) =&amp; 0\Longrightarrow\\
\alpha\sum\limits_{i=1}^NX_i + \beta\sum\limits_{i=1}^N X_i^2 - \sum\limits_{i=1}^NY_iX_i =&amp; 0\Longrightarrow\\
(\bar Y -\beta\bar X)N\bar X + \beta\sum\limits_{i=1}^NX_i^2 - \sum\limits_{i=1}^NY_iX_i =&amp; 0\\
N\bar Y\bar X -N\beta(\bar X)^2 + \beta\sum\limits_{i=1}^NX_i^2 - \sum\limits_{i=1}^NY_iX_i =&amp; 0\\
\beta\left(\sum\limits_{i=1}^NX_i^2 - N(\bar X)^2\right) =&amp; \sum\limits_{i=1}^NY_iX_i - N\bar Y\bar X\\
\beta =&amp; \frac{\sum\limits_{i=1}^NY_iX_i - N\bar Y\bar X}{\sum\limits_{i=1}^NX_i^2 - N(\bar X)^2}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;But note:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{VAR}(X) = \frac{1}{N}\sum\limits_{i=1}^NX_i^2 - (\bar X)^2&lt;/script&gt;

&lt;p&gt;So,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;N\cdot\text{VAR}(X) = \sum\limits_{i=1}^NX_i^2 - N(\bar X)^2&lt;/script&gt;

&lt;p&gt;And:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum\limits_{i=1}^NY_iX_i - N\bar Y\bar X =&amp; \sum\limits_{i=1}^NY_iX_i - N(\frac{1}{N}\sum\limits_{i=1}^NY_i)\bar X \\
=&amp; \sum\limits_{i=1}^NY_iX_i - \sum\limits_{i=1}^N(Y_i\bar X)\\
=&amp; \sum\limits_{i=1}^NY_i\left(X_i - \bar X\right) \\
=&amp; \sum\limits_{i=1}^NY_i\left(X_i - \bar X\right) - \sum\limits_{i=1}^N\bar Y\left(X_i - \bar X\right) + \sum\limits_{i=1}^N\bar Y\left(X_i - \bar X\right)\\
=&amp; \sum\limits_{i=1}^N\left(Y_i-\bar Y\right)\left(X_i - \bar X\right) + \bar Y\sum\limits_{i=1}^N\left(X_i - \bar X\right)\\
=&amp; \sum\limits_{i=1}^N\left(Y_i-\bar Y\right)\left(X_i - \bar X\right) = N\cdot \text{COV}(X, Y) \end{align*} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;So,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta = \frac{\text{COV}(X,Y)}{\text{VAR}(X)}&lt;/script&gt;

&lt;p&gt;And then we can find \( \alpha \) by substituting in our approximation of \( \beta \). Using those coefficients, we can plot the line below, and as you can see, it really is a good approximation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/02/21-linear-regression_scatterPoints_withLine.png&quot; alt=&quot;Data With Linear Regression Line&quot; title=&quot;Some Example Data With Regression Line&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;now-we-have-it&quot;&gt;Now we have it&lt;/h3&gt;

&lt;p&gt;Okay, so now we have our line of “best fit”, but what does it mean? Well, it
means that this line predicts the data we gave it with the least error. That’s
really all it means. And sometimes, as we’ll see later, reading too much into
that can really get you into trouble.&lt;/p&gt;

&lt;p&gt;But using this model we can now predict other data outside the model.  So, for
instance, in the model pictured above, if we were to try and predict \( Y \)
when \( X=2 \), we wouldn’t do so bad by picking something around 10 for \(
Y \).&lt;/p&gt;

&lt;h3 id=&quot;an-example-perhaps&quot;&gt;An example, perhaps?&lt;/h3&gt;

&lt;p&gt;So I feel at this point, it’s probably best to give an example. Let’s say we’re
trying to predict stock price given the total market price. Well, in practice
this model is used to assess volatility, but that’s neither here nor there.
Right now, we’re really only interested in the model itself. But without
further ado, I present you with, the CAPM (Capital Asset Pricing Model):&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;r = \alpha + \beta r_m + \epsilon&lt;/script&gt; (where \( \epsilon \) is the error in
our predictions).&lt;/p&gt;

&lt;p&gt;And you can fit this using historical data or what-have-you. There are a bunch
of downsides to fitting it with historical data though, like the fact that data
from 3 days ago really doesn’t have much to say about the future anymore. There
are plenty of cool things you can do therein, but sadly, those are out of the
scope of this post.&lt;/p&gt;

&lt;p&gt;For now, we move on to&lt;/p&gt;

&lt;h2 id=&quot;multiple-regression&quot;&gt;Multiple Regression&lt;/h2&gt;

&lt;h3 id=&quot;what-is-this-anyway&quot;&gt;What is this anyway?&lt;/h3&gt;

&lt;p&gt;Well, multiple regression is really just a new name for the same thing: how do
we fit a linear model to our data given some set of predictors and a single
response variable? The only difference is that this time our linear model
doesn’t have to be one dimensional. Let’s get right into it, shall we?&lt;/p&gt;

&lt;p&gt;So let’s say you have \( k \) many predictors arranged in a vector (in other
words, our predictor is a vector in \( \mathbb{R}^n \)). Well, I wonder if a
similar formula would work… Let’s figure it out…&lt;/p&gt;

&lt;p&gt;Firstly, we need to know what a derivative is in \( \mathbb{R}^n \). Well, if
\( f:\mathbb{R}^n\to\mathbb{R}^m \) is a differentiable function, then for
any \( x \) in the domain, \( f’(x) \) is the linear map \(
A:\mathbb{R}^n\to\mathbb{R}^m \) such that \( \text{lim}_{h\to 0}\frac{||f(x+h) - f(x) - Ah||}{||h||} = 0 \). Basically, \( f’(x) \) is the tangent plane.&lt;/p&gt;

&lt;p&gt;So, now that we got that out of the way, let’s use it! We want to find the
linear function that minimizes the Euclidean norm of the error terms (just like
before). But note: the error term is \( \epsilon = Y - \hat Y = Y - \alpha
-\beta X \), for some vector \( \alpha \) and some matrix \( \beta \).
Now, since it’s easier and it’ll give us the same answer, we’re going to
minimize the squared error term instead of just the error term (like we did in
the one dimensional version). We’re also going to make one more simplification:
That \( \alpha=0 \). We can do this safely by simply appending (or
prepending) a 1 to the rows of our data (thereby creating a constant term). So
for the following, assume we’ve done that.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}\langle\epsilon, \epsilon\rangle =&amp; (Y - X\beta)^T(Y - X\beta) \\
 \langle\epsilon, \epsilon\rangle =&amp; (Y^T - \beta^TX^T)(Y - X\beta) \\
 \langle\epsilon, \epsilon\rangle =&amp; Y^TY - 2Y^TX\beta + \beta^TX^TX\beta \end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, let’s find the \( \beta \) that minimizes that.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
0=&amp;\lim\limits_{h\to0}\frac{||(Y^TY - 2Y^TX(\beta+h) + (\beta+h)^TX^TX(\beta+h)) - (Y^TY - 2Y^TX\beta + \beta^TX^TX\beta) - Ah||}{||h||} \\
0=&amp;\lim\limits_{h\to0}\frac{||- 2Y^TXh + 2\beta^TX^TXh + h^TX^TXh - Ah||}{||h||}\\
0=&amp;\lim\limits_{h\to0}||- 2Y^TX + 2\beta^TX^TX + h^TX^TX - A||\frac{||h||}{||h||}\\
0=&amp;\lim\limits_{h\to0}||- 2Y^TX + 2\beta^TX^TX - A|| \end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, now we see that the derivative is \( -2Y^TX + 2\beta^TX^TX \) and we want to find where our error is minimized, so we want to set that derivative to zero:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
	0=&amp;- 2Y^TX + 2\beta^TX^TX \\
	X^TX\beta =&amp; X^TY \\
	\beta =&amp; (X^TX)^{-1}X^TY \end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;And there we have it. That’s called the &lt;strong&gt;normal equation&lt;/strong&gt; for linear regression.&lt;/p&gt;

&lt;p&gt;Maybe next time I’ll post about how we can find these coefficients given some data using gradient descent, or some modification thereof.&lt;/p&gt;

&lt;p&gt;Till next time, I hope you enjoyed this post. Please, let me know if something could be clearer or if you have any requests.&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="Statistics" /><category term="Prediction" /><category term="Regression" /><summary type="html">Linear Regression is the bedrock of Machine Learning. We cover the basics therein, some theory involved, and give some relevant examples.</summary></entry><entry><title type="html">Probability – A Measure Theoretic Approach</title><link href="http://localhost:4000/blog/2017/02/18/probability-a-measure-theoretic-approach.html" rel="alternate" type="text/html" title="Probability -- A Measure Theoretic Approach" /><published>2017-02-18T06:42:55-08:00</published><updated>2017-02-18T06:42:55-08:00</updated><id>http://localhost:4000/blog/2017/02/18/probability-a-measure-theoretic-approach</id><content type="html" xml:base="http://localhost:4000/blog/2017/02/18/probability-a-measure-theoretic-approach.html">&lt;h2 id=&quot;probability-using-measure-theory&quot;&gt;Probability using Measure Theory&lt;/h2&gt;

&lt;p&gt;A mathematically rigorous definition of probability, and some examples therein.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3 id=&quot;the-traditional-definition&quot;&gt;The Traditional Definition:&lt;/h3&gt;

&lt;p&gt;Consider a set \(  \Omega \) (called the &lt;strong&gt;sample space&lt;/strong&gt;
), and a function \(  X:\Omega\rightarrow\mathbb{R} \) (called a &lt;strong&gt;random variable&lt;/strong&gt;
.&lt;/p&gt;

&lt;p&gt;If \(  \Omega \) is countable (or finite), a function \(  \mathbb{P}:\Omega\rightarrow\mathbb{R} \) is called a &lt;strong&gt;probability distribution&lt;/strong&gt;
 if it satisfies the following 2 conditions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For each \(  x \in \Omega \), \(  \mathbb{P}(x) \geq 0 \)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If \(  A_i\cap A_j = \emptyset \), then \(  \mathbb{P}(\bigcup\limits_0^\infty A_i) = \sum\limits_0^\infty\mathbb{P}(A_i) \)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And if \(  \Omega \) is uncountable, a function \(  F:\mathbb{R}\rightarrow\mathbb{R} \) is called a &lt;strong&gt;probability distribution&lt;/strong&gt;
 or a &lt;strong&gt;cumulative distribution function&lt;/strong&gt;
 if it satisfies the following 3 conditions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For each \(  a,b\in\mathbb{R} \), \(  a &amp;lt; b \rightarrow F(a)\leq F(b) \)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(  \lim\limits_{x\to -\infty}F(x) = 0 \)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(  \lim\limits_{x\to\infty}F(x) = 1 \)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-intuition&quot;&gt;The Intuition:&lt;/h3&gt;

&lt;p&gt;What idea are we even trying to capture with these seemingly disparate definitions for the same thing? Well, with the two cases taken separately it's somewhat obvious, but they don't seem to marry very well. The discrete case is giving us a pointwise estimation of something akin to the proportion of observations that should correspond to a value (in a perfect world). The continuous case is the same thing, but instead of corresponding to that particular value (which doesn't really even make sense in this case), the proportion corresponds to the point in question and everything less than it. The shaded region in the top picture below and the curve in the picture directly below it denote the cumulative density function of a standard normal distribution (don't worry too much about what that means for this post, but if you're doing anything with statistics, you should probably know a bit about that).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pics/2017/02/18-probability-a-measure-theoretic-approach_pdf-cdf1.png&quot; alt=&quot;pdf vs cdf for Normal distribution&quot; title=&quot;PDF vs CDF for Normal Distribution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another way to define a continuous probability distribution is through something called a probability density function, which is closer to the discrete case definition of a probability distribution (or &lt;strong&gt;probability mass function&lt;/strong&gt;
). A &lt;strong&gt;probability density function&lt;/strong&gt;
 is a function \(  f:\mathbb{R}\rightarrow\mathbb{R}&lt;em&gt;+ \) such that \(  \int&lt;/em&gt;{-\infty}^xf(t)dt = F(x) \). In other words, \(  \frac{dF}{dX} = f \). This new function has some properties of our discrete case probability function, but lacks some others. On the one hand, they’re both defined pointwise, but on the other, this one can be greater than one in some places – meaning the value of the probability density function isn’t really the probability of an event, but rather (as the name “suggests”) the density therein.&lt;/p&gt;

&lt;h3 id=&quot;does-it-measure-up&quot;&gt;Does it measure up?&lt;/h3&gt;

&lt;p&gt;Now let’s check out the measure theoretic approach…&lt;/p&gt;

&lt;p&gt;Let \(  \Omega \) be our sample space, \(  S \) be the \(  \sigma \)-algebra on \(  \Omega \) (so \(  S \) is the collection of measurable subsets of \(  \Omega \)), and \(  \mu:S\to\mathbb{R} \) a measure on that measure space. Let \(  X:\Omega\rightarrow\mathbb{E} \) be a random variable (\(  \mathbb{E} \) is generally taken to be \(  \mathbb{R} \) or \(  \mathbb{R}^n \)). We define the function \(  \mathbb{P}:\mathcal{P}(\mathbb{E})\rightarrow\mathbb{R} \) (where \(  \mathcal{P}(\mathbb{E}) \) is the powerset of \(  \mathbb{E} \) – the set of all subsets) such that if \(  A\subseteq\mathbb{E} \), we have \(  \mathbb{P}(A)=\mu(X^{-1}(A)) \). We call \(  \mathbb{P} \) a &lt;strong&gt;probability distribution&lt;/strong&gt;
 if the following conditions hold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(  \mu(\Omega) = 1 \)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;for each \(  A\subseteq\mathbb{E} \) we have \(  X^{-1}(A)\in S \).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-do-this&quot;&gt;Why do this?&lt;/h3&gt;

&lt;p&gt;Well, right off the bat we have a serious benefit: we no longer have two disparate definitions of our probability distributions. Furthermore, there is the added benefit of having a natural separation of concerns: the measure \(  \mu \) determines the what we might intuitively consider to be the probability distribution while the random variable is used to encode the aspects of the events that we care about.&lt;/p&gt;

&lt;p&gt;To further illustrate this&lt;/p&gt;

&lt;h3 id=&quot;the-examples&quot;&gt;The Examples&lt;/h3&gt;

&lt;h4 id=&quot;a-fair-die&quot;&gt;A fair die&lt;/h4&gt;

&lt;h5 id=&quot;all-even&quot;&gt;All even&lt;/h5&gt;

&lt;p&gt;Let’s consider a fair die. Our sample space will be \(  {1,2,3,4,5,6} \). Since our die is fair, we’ll define our measure fairly: for any \(  x \) in our sample space, \(  \mu({x}) = \frac{1}{6} \). If we want to know, for instance, what the probability of getting each number is, we could use a very intuitive random variable \(  X(a) = a \) (so \(  X(1)=1 \), etc.). Then we see that \(  \mathbb{P}({1}) = \mu({1}) = \frac{1}{6} \), and the rest are found similarly.&lt;/p&gt;

&lt;h5 id=&quot;odds-and-evens&quot;&gt;Odds and Evens?&lt;/h5&gt;

&lt;p&gt;What if we want to consider the fair die of yester-paragraph, but we only care if the face of the die shows an odd or an even number? Well, since the actual distribution of the die hasn’t changed, we won’t have to change our measure. Instead we’ll change our random variable to capture just those aspects we care about. In particular, \(  X(a) = 0 \) if \(  a \) is even, and \(  X(a) = 1 \) if \(  a \) is odd. We then see \(  \mathbb{P}(1) = \mu({1,3,5}) = \frac{1}{2} \) and \(  \mathbb{P}(0) = \mu({2,4,6}) = \frac{1}{2} \)&lt;/p&gt;

&lt;h4 id=&quot;getting-loaded&quot;&gt;Getting loaded&lt;/h4&gt;

&lt;h5 id=&quot;all-even-1&quot;&gt;All even&lt;/h5&gt;

&lt;p&gt;Now let’s consider the same scenario of wanting to know the probability of getting each number, but now our die is loaded. Being as how we’re changing the distribution itself and not just the aspects we’re choosing to care about, we’re going to want to change the measure this time. For simplicity, let’s consider a kind of degenerate case scenario. Let our measure be: \(  \mu(A) = 1 \) if \(  1\in A \) and \(  \mu(A)=0 \) if \(  1\notin A \). Basically, we’re defining our probability to be such that the only possible outcome is a roll of 1. So since we are concerned with the same things we were concerned with last time, we can take that same random variable. We note \(  \mathbb{P}(1) = 1 \) and \(  \mathbb{P}(a) = 0 \) for any \(  a \neq 1 \).&lt;/p&gt;

&lt;h5 id=&quot;odds-or-evens&quot;&gt;Odds or evens&lt;/h5&gt;

&lt;p&gt;Try to do this one yourself. I’m going to go get some sleep now. Please feel free to contact me with any questions. I love doing this stuff, so don’t be shy!&lt;/p&gt;</content><author><name>Aaron Niskin</name></author><category term="math" /><category term="measure theory" /><category term="Probability" /><category term="statistics" /><summary type="html">We cover probability from a measure theoretic approach</summary></entry><entry><title type="html">A dirty little ditty on Finite Automata</title><link href="http://localhost:4000/blog/2015/12/03/a-dirty-little-ditty-on-finite-automata.html" rel="alternate" type="text/html" title="A dirty little ditty on Finite Automata" /><published>2015-12-03T00:00:00-08:00</published><updated>2015-12-03T00:00:00-08:00</updated><id>http://localhost:4000/blog/2015/12/03/a-dirty-little-ditty-on-finite-automata</id><content type="html" xml:base="http://localhost:4000/blog/2015/12/03/a-dirty-little-ditty-on-finite-automata.html">&lt;p&gt;This post builds on the previous post about &lt;a href=&quot;/mathematics/2015/11/30/whats-in-a-language/&quot;&gt;Formal Languages&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;some-formal-definitions&quot;&gt;Some Formal Definitions&lt;/h3&gt;

&lt;h4 id=&quot;a-deterministic-finite-automata-dfa-is&quot;&gt;A Deterministic Finite Automata (DFA) is&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A set \(  \mathcal{Q} \) called “states”&lt;/li&gt;
  &lt;li&gt;A set \(  \Sigma \) called “symbols” or “alphabet”&lt;/li&gt;
  &lt;li&gt;A function \(  \delta_F:\mathcal{Q}\times\Sigma \to \mathcal{Q} \)&lt;/li&gt;
  &lt;li&gt;A designated state \(  q_0\in\mathcal{Q} \) called the start point&lt;/li&gt;
  &lt;li&gt;A subset \(  F\subseteq\mathcal{Q} \) called the “accepting states”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The DFA is then often referred to as the ordered quintuple \(  A=(\mathcal{Q},\Sigma,\delta_F,q_0,F) \).&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h4 id=&quot;defining-how-strings-act-on-dfas&quot;&gt;Defining how strings act on DFAs.&lt;/h4&gt;

&lt;p&gt;Given a DFA, \(  A=(\mathcal{Q}, \Sigma, \delta, q_0, F) \), a state \(  q_i\in\mathcal{Q} \), and a string \(  w\in\Sigma^* \), we can define \(  \delta(q_i,w) \) like so:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If \(  w \) only has one symbol, we can consider \(  w \) to be the symbol and define \(  \delta(q_i,w) \) to be the same as if we considered \(  w \) as the symbol&lt;/li&gt;
  &lt;li&gt;If \(  w=xv \), where \(  x\in\Sigma \) and \(  v\in\Sigma^* \), then \(  \delta(q_i, w)=\delta(\delta(q_i,x),v) \)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And in this way, we have defined how DFAs can interpret strings of symbols rather than just single symbols.&lt;/p&gt;

&lt;h4 id=&quot;the-language-of-a-dfa&quot;&gt;The language of a DFA&lt;/h4&gt;

&lt;p&gt;Given a DFA, \(  A=(\mathcal{Q}, \Sigma, \delta, q_0, F) \), we can define “the language of \(  A \)”, denoted \(  L(A) \), as \(  {w\in\Sigma^*|\delta(q_0,w)\in F} \).&lt;/p&gt;

&lt;h3 id=&quot;some-examples-maybe&quot;&gt;Some Examples, Maybe?&lt;/h3&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example 1:&lt;/h4&gt;

&lt;p&gt;Let’s construct a  DFA that accepts only strings beginning with a 1 that, when interpreted as binary numbers, are multiples of 5. So some examples of strings that would be in \(  L(A) \) are 101, 1010, 1111&lt;/p&gt;

&lt;h3 id=&quot;some-more-formal-definitions&quot;&gt;Some More Formal Definitions&lt;/h3&gt;

&lt;h4 id=&quot;a-nondeterministic-finite-automata-nfa-is&quot;&gt;A Nondeterministic Finite Automata (NFA) is&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A set \(  \mathcal{Q} \) called “states”&lt;/li&gt;
  &lt;li&gt;A set \(  \Sigma \) called “symbols”&lt;/li&gt;
  &lt;li&gt;A function \(  \delta_N:\mathcal{Q}\times\Sigma \to \mathcal{P}\left(\mathcal{Q}\right) \)&lt;/li&gt;
  &lt;li&gt;A designated state \(  q_0\in\mathcal{Q} \) called the start point&lt;/li&gt;
  &lt;li&gt;A subset \(  F\subseteq\mathcal{Q} \) called the “accepting states”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The NFA is then often referred to as the ordered quintuple \(  A=(\mathcal{Q},\Sigma,\delta_N,q_0,F) \).&lt;/p&gt;

&lt;h4 id=&quot;defining-how-strings-act-on-nfas&quot;&gt;Defining how strings act on NFAs.&lt;/h4&gt;

&lt;p&gt;Given an NFA, \(  N=(\mathcal{Q}, \Sigma, \delta, q_0, F) \), a collection of states \(  \mathcal{S}\subseteq\mathcal{Q} \), and a string \(  w\in\Sigma^* \), we can define \(  \delta(\mathcal{S},w) \) like so:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If \(  w \) only has one symbol, then we can consider \(  w \) to be the symbol and define \(  \delta(\mathcal{S},w):=\bigcup\limits_{s\in\mathcal{S}}\delta(s,w) \)&lt;/li&gt;
  &lt;li&gt;If \(  w=xv \), where \(  x\in\Sigma \) and \(  v\in\Sigma^* \), then \(  \delta(\mathcal{S}, w)=\bigcup\limits_{s\in\mathcal{S}}\delta(\delta(s,x),v) \)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And in this way, we have defined how NFAs can interpret strings of symbols rather than just single symbols.&lt;/p&gt;

&lt;h3 id=&quot;maybe-in-another-post-well-get-past-the-definitions--&quot;&gt;Maybe in another post, we’ll get past the definitions! :-/&lt;/h3&gt;</content><author><name>Aaron Niskin</name></author><category term="Mathematics" /><category term="dfa" /><category term="dfa nfa equivalence" /><category term="finite automata" /><category term="formal languages" /><category term="math" /><category term="mathematics" /><category term="maths" /><category term="nfa" /><category term="intro" /><summary type="html">A basic yet formal introduction to Finite Automata and how strings act on them.</summary></entry></feed>