(ns content.sicp.texts.ch1sect3 (:require [tailrecursion.hoplon.markdown :as md] [content.sicp.book-data :as data] [tailrecursion.hoplon :refer [form audio input hgroup do! timeout $text base h1 embed h3 body keygen on-append! progress main cite on-page-load object i p nav ruby check-val! a menu blockquote img $comment span track seq?* data u dl select html thead del eventsource append-child fieldset aside figure figcaption sentinel q on! bdi video address caption parse-args dd rp hr tbody table acronym frame applet html-var add-initfn! pre ul dir html-time add-attributes! html-map sup dfn sub mark script big button wbr strong li dt frameset td tr section th optgroup iframe legend em kbd spliced article isindex abbr command <!-- source output basefont route-cell header datalist tfoot s ins footer title is-ie8 h5 canvas param font div option summary samp center small style textarea loop-tpl* strike h4 tt head add-children! ol details col vector?* label rt when-dom h6 link page-load colgroup meter html-meta text-val! bdo --> b code node? noframes replace-children! noscript safe-nth h2 area br]] [tailrecursion.javelin :refer [input? cell cell? destroy-cell! ^{:private true} last-rank ^{:deprecated true} lift lens? set-formula! cell-doseq* ^{:dynamic true, :private true} *tx* deref* set-cell! lens formula? alts! dosync* cell-map formula]]) (:require-macros [tailrecursion.hoplon.markdown :refer [md]] [tailrecursion.hoplon :refer [text with-timeout sexp defelem def-values with-page-load with-dom loop-tpl with-interval with-init!]] [tailrecursion.javelin :refer [with-let mx2 dosync cell= set-cell!= prop-cell cell-doseq defc cell-let-1 defc= macroexpand-all mx cell-let]]))

(sexp {} "defelem content [_ _]" (div {} (data/sect {:title "Formulating Abstractions with Higher-Order Procedures"} (md {} "We have seen that procedures are, in effect, abstractions that describe\ncompound operations on numbers independent of the particular numbers.\nFor example, when we\n\n```clj\n(defn cube [x] (* x x x))\n```\n\nWe are not talking about the cube of a particular number, but rather\nabout a method for obtaining the cube of any number. Of course we could\nget along without ever defining this procedure, by always writing\nexpressions such as\n\n```clj\n(* 3 3 3)\n(* x x x)\n(* y y y)\n```\n\nand never mentioning `cube` explicitly. This would place us at a\nserious disadvantage, forcing us to work always at the level of the\nparticular operations that happen to be primitives in the language\n(multiplication, in this case) rather than in terms of higher-level\noperations. Our programs would be able to compute cubes, but our\nlanguage would lack the ability to express the concept of cubing. One\nof the things we should demand from a powerful programming language is\nthe ability to build abstractions by assigning names to common patterns\nand then to work in terms of the abstractions directly. Procedures\nprovide this ability. This is why all but the most primitive\nprogramming languages include mechanisms for defining procedures.\n\nYet even in numerical processing we will be severely limited in our\nability to create abstractions if we are restricted to procedures whose\nparameters must be numbers. Often the same programming pattern will be\nused with a number of different procedures. To express such patterns as\nconcepts, we will need to construct procedures that can accept\nprocedures as arguments or return procedures as values. Procedures that\nmanipulate procedures are called *higher-order procedures*. This\nsection shows how higher-order procedures can serve as powerful\nabstraction mechanisms, vastly increasing the expressive power of our\nlanguage.")) "" (data/subsect {:title "Procedures as Arguments"} (md {} "Consider the following three procedures. The first computes the sum of\nthe integers from `a` through `b`:\n\n```clj\n(defn sum-integers [a b]\n  (if (> a b)\n      0\n      (+ a (sum-integers (inc a) b))))\n```\n\nThe second computes the sum of the cubes of the integers in the given\nrange:\n\n```clj\n(defn sum-cubes [a b]\n  (if (> a b)\n      0\n      (+ (cube a) (sum-cubes (inc a) b))))\n```\n\nThe third computes the sum of a sequence of terms in the series\n\n$$ \\frac{1}{1\\cdot3}+\\frac{1}{5\\cdot7}+\\frac{1}{9\\cdot11}+...$$\n\nwhich converges to \\\\(\\pi/8\\\\) (very slowly):<<This series, usually\nwritten in the equivalent form \\\\((\\pi/4)=1-(1/3)+(1/5)-(1/7)+...\\\\),\nis due to Leibniz. We'll see how to use this as the basis for some\nfancy numerical tricks in [section 3.5.3](#!/sicp/ch/3/sect/5/sub/3/)>>\n\n```clj\n(defn pi-sum [a b]\n  (if (> a b)\n      0\n      (+ (/ 1.0 (* a (+ a 2))) (pi-sum (+ a 4) b))))\n```\n\nThese three procedures clearly share a common underlying pattern. They\nare for the most part identical, differing only in the name of the\nprocedure, the function of a used to compute the term to be added, and\nthe function that provides the next value of `a`. We could generate\neach of the procedures by filling in slots in the same template:\n\n```clj\n(defn <name> [a b]\n  (if (> a b)\n      0\n      (+ (<term> a)\n         (<name> (<next> a) b))))\n```\n\nThe presence of such a common pattern is strong evidence that there is\na useful abstraction waiting to be brought to the surface. Indeed,\nmathematicians long ago identified the abstraction of *summation of a\nseries* and invented \"sigma notation,\" for example\n\n$$\\sum_{n=a}^bf(n)=f(a)+...+f(b)$$\n\nto express this concept. The power of sigma notation is that it allows\nmathematicians to deal with the concept of summation itself rather than\nonly with particular sums -- for example, to formulate general results\nabout sums that are independent of the particular series being summed.\n\nSimilarly, as program designers, we would like our language to be\npowerful enough so that we can write a procedure that expresses the\nconcept of summation itself rather than only procedures that compute\nparticular sums. We can do so readily in our procedural language by\ntaking the common template shown above and transforming the \"slots\"\ninto formal parameters:\n\n```clj\n(defn sum [term a next b]\n  (if (> a b)\n      0\n      (+ (term a)\n         (sum term (next a) next b))))\n```\n\nNotice that `sum` takes as its arguments the lower and upper bounds `a`\nand `b` together with the procedures `term` and `next`. We can use\n`sum` just as we would any procedure. For example, we can use it (along\nwith a procedure `inc` that increments its argument by 1) to define\n`sum-cubes`:\n\n```clj\n(defn inc [n] (+ n 1))\n(defn sum-cubes [a b]\n  (sum cube a inc b))\n```\n\nUsing this, we can compute the sum of the cubes of the integers from 1\nto 10:\n\n```clj\n(sum-cubes 1 10)\n3025\n```\n\nWith the aid of an identity procedure to compute the term, we can\ndefine `sum-integers` in terms of `sum`:\n\n```clj\n(defn identity [x] x)\n(defn sum-integers [a b]\n  (sum identity a inc b))\n```\n\nThe we can add up the integers from 1 to 10:\n\n```clj\n(sum-integers 1 10)\n55\n```\n\nWe can also define `pi-sum` in the same way:<<Notice that we have used\nblock structure (section 1.1.8) to embed the definitions of `pi-next`\nand `pi-term` within `pi-sum`, since these procedures are unlikely to\nbe useful for any other purpose and in Scheme (the language that SICP\nwas written for), procedures written in this way are defined only in\nthe local environment; the same is not true in Clojure. We will see how\nto get rid of them altogether (and hence how one would approach this\nproblem) in section 1.3.2.>>\n\n```clj\n(defn pi-sum [a b]\n  (defn pi-term [x]\n    (/ 1.0 (* x (+ x 2))))\n  (defn pi-next [x]\n    (+ x 4))\n  (sum pi-term a pi-next b))\n```\n\nUsing these procedures, we can compute an approximation to \\\\(\\pi\\\\):\n\n```clj\n(* 8 (pi-sum 1 1000))\n3.139592655589783\n```\n\nOnce we have `sum`, we can use it as a building block in formulating\nfurther concepts. For instance, the definite integral of a function\n\\\\(f\\\\) between the limits \\\\(a\\\\) and \\\\(b\\\\) can be approximated\nnumerically using the formula\n\n$$\\int_a^bf(x)dx=\\left[f\\left(a+\\frac{dx}{2}\\right)+f\\left(a+dx+\\frac{dx}{2}\\right)+\nf\\left(a+2dx+\\frac{dx}{2}\\right)\\right]dx$$\n\nfor small values of \\\\(dx\\\\). We can express this directly as a procedure:\n\n```clj\n(defn integral [f a b dx]\n  (defn add-dx [x] (+ x dx))\n  (* (sum f (+ a (/ dx 2.0)) add-dx b)\n     dx))\n(inegral cube 0 1 0.01)\n.24998750000000042\n(integral cube 0 1 0.001)\n.249999875000001\n```\n\n(The exact value of the integral of `cube` between 0 and 1 is 1/4.)")) "" (data/exercises {:title "29-33"} (data/exercise {} (md {} "Simpson's Rule is a more accurate method of numberical integration\nthan the method illustrated above. Using Simpson's Rule, the integral\nof a function \\\\(f\\\\) between \\\\(a\\\\) and \\\\(b\\\\) is approximated as\n\n$$\\frac{h}{3}[y_0+4y_1+2y_2+4y_3+2y_4+...+2y_{n-2}+4y_{n-1}+y_n]$$\n\nwhere \\\\(h=(b-a)/n\\\\), for some even integer \\\\(n\\\\), and\n\\\\(y_k=f(a+kh)\\\\). (Increasing \\\\(n\\\\) increases the accuracy of the\napproximation.) Define a procedure that takes as arguments\n\\\\(f\\\\),\\\\(a\\\\),\\\\(b\\\\), and \\\\(n\\\\) and returns the value of the\nintegral, computed using Simpson's Rule. Use your procedure to\nintegrate the `fifth-power` function shown below between 0 and 1\n(with \\\\(n=100\\\\) and \\\\(n=1000\\\\)), and compare the results to those\nof the `integral` procedure shown above.\n\n```clj\n(defn fifth-power [x]\n  (* x x x x x))\n```\n\nThe value of the integral is actually \\\\(\\frac{1}{6}\\\\) or\n\\\\(0.1\\bar6\\\\), where the bar over the 6 means that it repeats\nforever.") "" (data/q-a {} (md {} "```clj\n(defn simpsons-rule [f a b n]\n  (def even-n (if (= (mod n 2) 0)\n                  n\n                  (inc n)))\n  (def h (/ (- b a) even-n))\n  (defn term [i]\n    (cond (or (= i 0) (= i even-n))\n          (f (+ a (* i h)))\n          (odd? i) (* 4 (f (+ a (* i h))))\n          :else (* 2 (f (+ a (* i h))))))\n  (* (/ h 3.0) (sum term 0 inc even-n)))\n```\n\nOr, if we wanted to save some computation and clean it up a bit,\n\n```clj\n(defn simpsons-rule [f a b n]\n  (def even-n (+ n (mod n 2)))\n  (def h (/ (- b a) even-n))\n  (def upper-limit (dec even-n))\n  (defn y [k] (f (+ a (* k h))))\n  (defn term [k]\n    (if (odd? k) (* 4 (y k))\n        (* 2 (y k))))\n  (* (/ h 3) (+ (y 0) (sum term 1 inc upper-limit) (y even-n))))\n```\n\nThis replaces the three-pronged `cond` with a simple if where we\nanticipate needing both equally (roughly)."))) "" (data/exercise {} (md {} "a.  The `sum` procedure above generates a linear recursion. The\nprocedure can be written so that the sum is performed iteratively.\nShow how to do this by filling in the missing expressions in the\nfollowing definition:\n\n```clj\n(defn sum [term a next b]\n  (defn iter [a result]\n    (if <??>\n        <??>\n        (iter <??> <??>)))\n  (iter <??> <??>))\n```\n\nb.  Do the same with the `loop` construct below (and notice the similarities).\n\n```clj\n(defn sum [term a next b]\n  (loop [number <??>\n         result <??>]\n    (if <??>\n        <??>\n        (recur <??> <??>))))\n```") "" (data/q-a {} (md {} "```clj\n(defn sum [term a next b]\n  (defn iter [a result]\n    (if (= a b)\n        result\n        (iter (next a) (+ (term a) result))))\n  (iter a 0))\n```\n\nFor part b.\n\n```clj\n(defn sum [term a next b]\n  (loop [this a\n         result 0]\n    (if (= this b)\n        result\n        (recur (next this) (+ (term this) result)))))\n```"))) "" (data/exercise {} (md {} "a.  The `sum` procedure is only the simplest of a vast number of\nsimilar abstractions that can be captured as higher-order\nprocedures.<<The intent of exercises 1.31-1.33 is to demonstrate the\nexpressive power that is attained by using an appropriate abstraction\nto consolidate many seemingly disparate operations. However, though\naccumulation and filtering are elegant ideas, our hands are somewhat\ntied in using them at this point since we do not yet have data\nstructures to provide suitable means of combination for these\nabstractions. We will return to these ideas in section 2.2.3 when we\nshow how to use sequences as interfaces for combining filters and\naccumulators to build even more powerful abstractions. We will see\nthere how these methods really come into their own as a powerful and\nelegant approach to designing programs.>> Write an analogous\nprocedure called `product` that returns the product of the values of\na function at points over a given range. Show how to define\n`factorial` in terms of `product`. Also use `product` to compute\napproximations to \\\\(\\pi\\\\) using the formula<<This formula was\ndiscovered by the seventeenth-century English mathematician John\nWallis.>>\n\n$$\\frac{\\pi}{4}=\\frac{2\\cdot4\\cdot4\\cdot6\\cdot6\\cdot8\\cdot\\cdot\\cdot}{3\\cdot3\\cdot5\\cdot5\\cdot7\\cdot7\\cdot\\cdot\\cdot}$$\n\nb.  If your `product` procedure generates a recursive process, write\none that generates an iterative process. If it generates an iterative\nprocess, write one that generates a recursive process.") "" (data/q-a {} (md {} "First, iteratively:\n\n```clj\n(defn product [term a next b]\n  (loop [number a\n         result 1]\n    (if (> number b)\n        result\n        (recur (next number) (* (term number) result)))))\n```\n\nNext, recursively:\n\n```clj\n(defn product [term a next b]\n  (if (> a b)\n      0\n      (* (term a) (product term (next a) next b))))\n```\n\n```clj\n(defn factorial [n]\n  (product identity 1 inc n))\n```\n\n```clj\n(defn pi-approximation [n]\n  (defn term-denominator [k] (square (+ 1 (* 2 k))))\n  (defn term-numerator [k] (* 2\n                              k \n                              (+ (* 2 k) 2)))\n  (defn term (/ term-numerator term-denominator))\n  (* 4 (product term 1 inc n)))\n```"))) "" (data/exercise {} (md {} "a. Show that `sum` and `product` (exercise 1.31) are both special\ncases of a still more general notion called `accumulate` that\ncombines a collection of terms, using some general accumulation\nfunction:\n\n```clj\n(accumulate combiner null-value term a next b)\n```\n\n`Accumulate` takes as arguments the same term and range\nspecifications as `sum` and `product`, together with a `combiner`\nprocedure (of two arguments) that specifies how the current term is\nto be combined with the accumulation of the preceding terms and a\n`null-value` that specifies what base value to use when the terms run\nout. Write `accumulate` and show how `sum` and `product` can both be\ndefined as simple calls to `accumulate`.\n\nb. If your `accumulate` procedure generates a recursive process,\nwrite one that generates an iterative process. If it generates an\niterative process, write one that generates a recursive process.") "" (data/q-a {} (md {} "```clj\n(defn accumulate [combiner null-value term a next b]\n  (loop [result null-value\n         number a]\n    (if (> a b)\n        result\n        (recur (next number) (combiner (term number) result)))))\n```\n\n```clj\n(defn accumulate [combiner null-value term a next b]\n  (if (> a b)\n      null-value\n      (combiner (term a) \n                (accumulate combiner \n                            null-value \n                            term \n                            (next a) \n                            next \n                            b))))\n```\n\n```clj\n(defn sum [term a next b]\n  (accumulate + 0 term a next b))\n(defn product [term a next b]\n  (accumulate * 1 term a next b))\n```"))) "" (data/exercise {} (md {} "You can obtain an even more general version of `accumulate` (exercise\n1.32) by introducing the notion of a *filter* on the terms to be\ncombined. That is, combine only those terms derived from values in\nthe range that satisfy a specified condition. The resulting\n`filtered-accumulate` abstraction takes the same arguments as\n`accumulate`, together with an additional predicate of one argument\nthat specifies the filter. Write `filtered-accumulate` as a\nprocedure. Show how to express the following using\n`filtered-accumulate`:\n\na. the sum of the squares of the prime numbers in the interval\n\\\\(a\\\\) to \\\\(b\\\\) (assuming that you have a `prime?` predicate\nalready written)\n\nb. the product of all the positive integers less than \\\\(n\\\\) that\nare relatively prime to \\\\(n\\\\) (i.e., all positive integers \\\\(i <\nn\\\\) such that \\\\(GCD(i,n) = 1\\\\)).") "" (data/q-a {} (md {} "```clj\n(defn filtered-accumulate [combiner null-value term a next b filter]\n  (loop [number a\n         result null-value]\n    (cond (> a b) result\n          (filter? number) (recur (next number)\n                                  (combiner (term number)\n                                            result))\n          :else (recur (next number) result))))\n```\n\n```clj\n(defn sum-prime-squares [a b]\n  (filtered-accumulate + 0 square a inc b prime?))\n```\n\n```clj\n(defn relatively-prime-factorial [n]\n  (defn gcd-filter [x] (= (gcd n x) 1))\n  (filtered-accumulate * 1 identity 1 inc b gcd-filter))\n```")))) "" (data/subsect {:title "Constructing Procedures using fn"} (md {} "It might be useful to note that in Scheme this function is named\n`lambda` (after the lambda calculus).\n\nIn using `sum` as in section 1.3.1, it seems terribly awkward to have\nto define trivial procedures such as `pi-term` and `pi-next` just so we\ncan use them as arguments to our higher-order procedure. Rather than\ndefine `pi-next` and `pi-term`, it would be more convenient to have a\nway to directly specify \"the procedure that returns its input\nincremented by 4\" and \"the procedure that returns the reciprocal of its\ninput times its input plus 2.\" We can do this by introducing the\nspecial form `fn`, which creates procedures. Using `fn` we can describe\nwhat we want as\n\n```clj\n(fn [x] (+ x 4))\n```\n\nand \n\n```clj\n(fn [x] (/ 1.0 (* x (+ x 2))))\n```\n\nThe our `pi-sum` procedure can be expressed without defining any\nauxiliary procedures as\n\n```clj\n(defn pi-sum [a b]\n  (sum (fn [x] (/ 1.0 (* x (+ x 2))))\n       a\n       (fn [x] (+ x 4))\n       b))\n```\n\nAgain using `fn`, we can write the `integral` procedure without having\nto define the auxiliary procedure `add-dx`:\n\n```clj\n(defn integral [f a b dx]\n  (* (sum f\n          (+ a (/ dx 2.0))\n          (fn [x] (+ x dx))\n          b)\n     dx))\n```\n\nIn general, `fn` is used to create procedures in the same way as\n`defn`, except that no name is specified for the procedure:\n\n```clj\n(fn [<formal-parameters>] <body>)\n```\n\nClojure also has an alternate shorter syntax for using `fn`: `#(+ 5 %)`\nis the same thing as `(fn [x] (+ 5 x))`. If there are multiple\narguments, we just enumerate them like so: `#(* %1 %2)`, which would be\nsyntactic sugar for, `(fn [x1 x2] (* x1 x2))`.\n\nThe resulting procedure is just as much a procedure as one that is\ncreated using `defn`. The only difference is that it has not been\nassociated with any name in the environment. In fact,\n\n```clj\n(defn plus4 [x] (+ x 4))\n```\n\nis equivalent to\n\n```clj\n(def plus4 (fn [x] (+ x 4)))\n```\n\nWe can read a `fn` expression as follows:\n\n```clj\n(fn [x] (+ x 4))\n```\n\nthe procedure of an argument x that adds x and 4\n\nLike any expression that has a procedure as its value, a `fn`\nexpression can be used as the operator in a combination such as\n\n```clj\n((fn [x y z] (+ x y (square z))) 1 2 3)\n12\n```\n\nor, more generally, in any context where we would normally use a\nprocedure name.<<It would be clearer and less intimidating to people\nlearning Lisp if a name more obvious than `lambda`, such as\n`make-procedure` (or `fn` in Clojure), were used. But the convention is\nfirmly entrenched. The notation is adopted from the \\\\(\\lambda\\\\)\ncalculus, a mathematical formalism introduced by the mathematical\nlogician Alonzo Church (1941). Church developed the \\\\(\\lambda\\\\)\ncalculus to provide a rigorous foundation for studying the notions of\nfunction and function application. The \\\\(\\lambda\\\\) calculus has\nbecome a basic tool for mathematical investigations of the semantics of\nprogramming languages.>>")) "" (data/ssub {:title "Using let to Create Local Variables"} (md {} "Another use of `fn` is in creating local variables. We often need local\nvariables in our procedures other than those that have been bound as\nformal parameters. For example, suppose we wish to compute the function\n\n$$f(x,y)=x(1+xy)^2 + y(1-y) + (1+xy)(1-y)$$\n\nwhich we could alsp express as\n\n$$\\begin{align*} a=&1+xy \\\\\\\\\n  b=& 1-y \\\\\\\\\n  f(x,y)=& xa^2+yb+ab\\end{align*}$$\n\nIn writing a procedure to compute \\\\(f\\\\), we would like to include as\nlocal variables not only \\\\(x\\\\) and \\\\(y\\\\) but also the names of\nintermediate quantities like \\\\(a\\\\) and \\\\(b\\\\). One way to accomplish\nthis is to use an auxiliary procedure to bind the local variables:\n\n```clj\n(defn f [x y]\n  (defn f-helper [a b]\n    (+ (* x (square a))\n       (* y b)\n       (* a b)))\n  (f-helper (+ 1 (* x y))\n    (- 1 y)))\n```\n\nOf course, we could use a `fn` expression to specify an anonymous\nprocedure for binding our local variables. The body of \\\\(f\\\\) then\nbecomes a single call to that procedure:\n\n```clj\n(defn f [x y]\n  (let [a (+ 1 (* x y))\n        b (- 1 y)]\n    (+ (* x (square a))\n       (* y b)\n       (* a b))))\n```\n\nThis is the way we can define things to the local environment in\nClojure. The general form of a `let` expression is\n\n```clj\n(let [<var1> <exp1>\n      <var2> <exp2>\n      ⋮\n      <varn> <expn>]\n  <body>)\n```\n\nwhich can be though of as saying\n\nlet `<var1>` have the value `<exp1>` and `<var2>` have the value\n`<exp2>` and ... `<varn>` have the value `<expn>` in `<body>`.\n\nThe first part of the `let` expression is a vector of name-expression\npairs. When the `let` is evaluated, each name is associated with the\nvalue of the corresponding expression. The body of the `let` is\nevaluated with these names bound as local variables. The way this\nhappens is that the `let` expression is interpreted as an alternate\nsyntax for\n\n```clj\n((fn [<var1> ... <varn>] <body>) (<exp1> ... <expn>))\n```\n\nNo new mechanism is required in the interpreter in order to provide\nlocal variables. A `let` expression is simply syntactic sugar for the\nunderlying `fn` application.\n\nWe can see from this equivalence that the scope of a variable specified\nby a `let` expression is the body of the `let`. This implies that:") "" (ul {} (li {} (md {} "`let` allows one to bind variables as locally as possible to where\nthey are to be used. For example, if the value of x is 5, the value\nof the expression\n\n```clj\n(+ (let [x 3]\n     (+ x (* x 10)))\n   x)\n```\n\nis 38. Here, the x in the body of the `let` is 3, so the value of the\n`let` expression is 33. On the other hand, the x that is the second\nargument to the outermost + is still 5.")) "" (li {} (md {} "In Scheme, the variables' values are computed outside the `let`\nwhich matters when the expressions that provide the values for the\nlocal variables depend upon variables having the same names as the\nlocal variables themselves. In Clojure, however, the values are\ncomputed sequentially with each new assigned value creating a\nnested environment. For example, if the value of x is 2, the\nexpression\n\n```scm\n(let ((x 3)\n      (y (+ x 2)))\n  (* x y))\n```\n\nwould evaluate to 12 in Scheme because the values are computed from\noutside the `let` binding, but the same thing (in Clojurian syntax)\n\n```clj\n(let [x 3\n      y (+ x 2)]\n  (* x y)\n```\n\nwould evaluate to 15 in Clojure because the values are set in\norder. So when the y is being set to `(+ x 2)`, the x is already\nset to 3.\n\n`let` in Clojure is actually based off of a function called `let*`\nin Scheme which is equivalent to nested `let` procedures. Strangely\nenough `let*` in Clojure acts the same as `let` in Scheme. So in\nsummation, our previous function is actually the same\nas:<<Understanding internal definitions well enough to be sure a\nprogram means what we intend it to mean requires a more elaborate\nmodel of the evaluation process than we have presented in this\nchapter. We will return to this issue in section 4.1.6, after we\nlearn more about evaluation.>>\n\n```clj\n(let [x 3]\n  (let [y (+ x 2)]\n    (* x y)))\n```")))) "" (data/exercises {:title 34} (data/exercise {} (md {} "Suppose we define the procedure\n\n```clj\n(defn f [g]\n  (g 2))\n```\n\nThen we have\n\n```clj\n(f square)\n4\n```\n\n```clj\n(f (fn [z] (* z (+ z 1))))\n6\n```\n\nWhat happens if we (perversely) as the interpreter to evaluate the combination `(f f)`? Explain.") "" (data/q-a {} (md {} "```clj\n((fn [g] (g 2)) f)\n(f 2)\n(2 2)\n```\n\nwhich is not defined because 2 is not a function.")))) "" (data/subsect {:title "Procedure as General Methods"} (md {} "We introduced compound procedures in [section\n1.1.4](#!/sicp/ch/1/sect/1/sub/4/) as a mechanism for abstracting\npatterns of numerical operations so as to make them independent of the\nparticular numbers involved. With higher-order procedures, such as the\n`integral` procedure of [section 1.3.1](#!/sicp/ch/1/sect/3/sub/1/), we\nbegan to see a more powerful kind of abstraction: procedures used to\nexpress general methods of computation, independent of the particular\nfunctions involved. In this section we discuss two more elaborate\nexamples -- general methods for finding zeros and fixed points of\nfunctions -- and show how these methods can be expressed directly as\nprocedures.")) "" (data/ssub {:title "Finding Roots of Equations by the Half-Interval Method"} (md {} "The *half-interval method* is a simple but powerful technique for\nfinding roots of an equation \\\\(f(x) = 0\\\\), where \\\\(f\\\\) is a\ncontinuous function. The idea is that, if we are given points \\\\(a\\\\)\nand \\\\(b\\\\) such that \\\\(f(a) < 0 < f(b)\\\\), then \\\\(f\\\\) must have at\nleast one zero between \\\\(a\\\\) and \\\\(b\\\\). To locate a zero, let\n\\\\(x\\\\) be the average of \\\\(a\\\\) and \\\\(b\\\\) and compute \\\\(f(x)\\\\).\nIf \\\\(f(x) > 0\\\\), then \\\\(f\\\\) must have a zero between \\\\(a\\\\) and\n\\\\(x\\\\). If \\\\(f(x) < 0\\\\), then \\\\(f\\\\) must have a zero between\n\\\\(x\\\\) and \\\\(b\\\\). Continuing in this way, we can identify smaller\nand smaller intervals on which \\\\(f\\\\) must have a zero. When we reach\na point where the interval is small enough, the process stops. Since\nthe interval of uncertainty is reduced by half at each step of the\nprocess, the number of steps required grows as \\\\(\\Theta(\\log(L/T))\\\\),\nwhere \\\\(L\\\\) is the length of the original interval and \\\\(T\\\\) is the\nerror tolerance (that is, the size of the interval we will consider\n\"small enough\"). Here is a procedure that implements this strategy:\n\n```clj\n(defn search [f neg-point pos-point]\n  (let [midpoint (average neg-point pos-point)]\n    (if (close-enough? neg-point pos-point)\n        midpoint\n        (let [test-value (f midpoint)]\n          (cond (positive? test-value) (search f neg-point midpoint)\n                (negative? test-value) (search f midpoint pos-point)\n                :else midpoint)))))\n```\n\n```clj\n(defn search [f neg-point pos-point]\n  (loop [negative neg-point\n         positive pos-point]\n    (let [midpoint (average negative positive)]\n      (if (close-enough? negative positive)\n          midpoint\n          (let [test-value (f midpoint)]\n            (cond (positive? test-value) (recur negative midpoint)\n                  (negative? test-value) (recur midpoint positive)\n                  :else midpoint))))))\n```\n\nWe assume that we are initially given the function \\\\(f\\\\) together\nwith points at which its values are negative and positive. We first\ncompute the midpoint of the two given points. Next we check to see if\nthe given interval is small enough, and if so we simply return the\nmidpoint as our answer. Otherwise, we compute as a test value the value\nof \\\\(f\\\\) at the midpoint. If the test value is positive, then we\ncontinue the process with a new interval running from the original\nnegative point to the midpoint. If the test value is negative, we\ncontinue with the interval from the midpoint to the positive point.\nFinally, there is the possibility that the test value is 0, in which\ncase the midpoint is itself the root we are searching for.\n\nTo test whether the endpoints are \"close enough\" we can use a procedure\nsimilar to the one used in [section 1.1.7](#!/sicp/ch/1/sect/1/sub/7/)\nfor computing square roots:<<We have used 0.001 as a representative\n\"small\" number to indicate a tolerance for the acceptable error in a\ncalculation. The appropriate tolerance for a real calculation depends\nupon the problem to be solved and the limitations of the computer and\nthe algorithm. This is often a very subtle consideration, requiring\nhelp from a numerical analyst or some other kind of magician.>>\n\n```clj\n(defn close-enough? [x y]\n  (< (abs (- x y)) 0.001))\n```\n\n`search` is awkward to use directly, because we can accidentally give\nit points at which \\\\(f\\\\)s values do not have the required sign, in\nwhich case we get a wrong answer. Instead we will use `search` via the\nfollowing procedure, which checks to see which of the endpoints has a\nnegative function value and which has a positive value, and calls the\n`search` procedure accordingly. If the function has the same sign at\nthe two given points, the half-interval method cannot be used, in which\ncase the procedure signals an error.<<This can be accomplished using\n`throw`, which takes as arguments a java \"throwable\" like `Exception.`\nand a string to be printed as an error message.>>\n\n```clj\n(defn half-interval-method [f a b]\n  (let [a-value (f a)\n        b-value (f b)]\n    (cond (and (negative? a-value) (positive? b-value))\n          (search f a b)\n          (and (positive? a-value) (negative? b-value))\n          (search f b a)\n          :else (throw (Exception. \"Values are not of opposite sign\")\n```\n\nThe following example uses the half-interval method to approximate\n\\\\(\\pi\\\\) as the root between 2 and 4 of \\\\(\\sin x=0\\\\):\n\n```clj\n(defn sin [x] (Math/sin x))\n(half-interval-method sin 2.0 4.0)\n3.14111328125\n```\n\nHere is another example, using the half-interval method to search for a\nroot of the equation \\\\(x^3-2x-3=0\\\\) between 1 and 2:\n\n```clj\n(half-interval-method (fn [x] (- (* x x x) (* 2 x) 3))\n                      1.0\n                      2.0)\n1.89306640625\n```")) "" (data/ssub {:title "Finding Fixed Points of Functions"} (md {} "A number \\\\(x\\\\) is called a *fixed point* of a function \\\\(f\\\\) if\n\\\\(x\\\\) satisfies the equation \\\\(f(x)=x\\\\). For some functions \\\\(f\\\\)\nwe can locate a fixed point by beginning with an initial guess and\napplying \\\\(f\\\\) repeatedly,\n\n$$f(x),f(f(x)),f(f(f(x))),...$$\n\nuntil the value does not change very much. Using this idea, we can\ndevise a procedure `fixed-point` that takes as inputs a function and an\ninitial guess and produces an approximation to a fixed point of the\nfunction. We apply the function repeatedly until we find two successive\nvalues whose difference is less than some prescribed tolerance:\n\n```clj\n(def tolerance 0.00001)\n(defn fixed-point [f first-guess]\n  (let [close-enough? (fn [v1 v2]\n                        (< (abs (- v1 v2)) tolerance))]\n    (loop [guess first-guess]\n      (let [next (f guess)]\n        (if (close-enough? guess next)\n            next\n            (recur next))))))\n```\n\nFor example, we can use this method to approximate the fixed point of\nthe cosine function, starting with 1 as an initial approximation.<<Try\nthis during a boring lecture: Set your calculator to radians mode and\nthen repeatedly press the `cos` button until you obtain the fixed\npoint.>>\n\n```clj\n(defn cos [x] (Math/cos x))\n(fixed-point cos 1.0)\n.7390822985224023\n```\n\nSimilarly, we can find a solution to the equation \\\\(y= \\sin y+\\cos y\\\\):\n\n```clj\n(fixed-point (fn [y] (+ (sin y) (cos y)))\n             1.0)\n1.2587315962971173\n```\n\nThe fixed-point process is reminiscent of the process we used for\nfinding square roots in [section 1.1.7](#!/sicp/ch/1/sect/1/sub/7/).\nBoth are based on the idea of repeatedly improving a guess until the\nresult satisfies some criterion. In fact, we can readily formulate the\nsquare-root computation as a fixed-point search. Computing the square\nroot of some number \\\\(x\\\\) requires finding a \\\\(y\\\\) such that\n\\\\(y^2=x\\\\). Putting this equation into the equivalent form\n\\\\(y=x/y\\\\), we recognize that we are looking for a fixed point of the\nfunction<<\\\\(\\to\\\\) (pronounced \"maps to\") is the mathematician way\nof writing `lambda` (or `fn`). \\\\(y\\to x/y\\\\) means `(fn [y] (/ x y))`,\nthat is, the function whose value at \\\\(y\\\\) is \\\\(x/y\\\\).>> \\\\(y\\to\nx/y\\\\), and we can therefore try to compute square roots as\n\n```clj\n(defn sqrt [x]\n  (fixed-point (fn [y] (/ x y))\n               1.0))\n```\n\nUnfortunately, this fixed-point search does not converge. Consider an\ninitial guess \\\\(y_1\\\\). The next guess is \\\\(y_2= x/y_1\\\\) and the\nnext guess is \\\\(y_3 = x/y_2 = x/(x/y_1) = y_1\\\\). This results in an\ninfinite loop in which the two guesses \\\\(y_1\\\\) and \\\\(y_2\\\\) repeat\nover and over, oscillating about the answer.\n\nOne way to control such oscillations is to prevent the guesses from\nchanging so much. Since the answer is always between our guess \\\\(y\\\\)\nand \\\\(x/y\\\\), we can make a new guess that is not as far from \\\\(y\\\\)\nas \\\\(x/y\\\\) by averaging \\\\(y\\\\) with \\\\(x/y\\\\), so that the next\nguess after \\\\(y\\\\) is \\\\((1/2)(y + x/y)\\\\) instead of \\\\(x/y\\\\). The\nprocess of making such a sequence of guesses is simply the process of\nlooking for a fixed point of \\\\(y\\to (1/2)(y + x/y)\\\\):\n\n```clj\n(defn sqrt [x]\n  (fixed-point (fn [y] (average y (/ x y)))\n               1.0))\n```\n\n(Note that \\\\(y = (1/2)(y + x/y)\\\\) is a simple transformation of the\nequation \\\\(y = x/y\\\\); to derive it, add \\\\(y\\\\) to both sides of the\nequation and divide by 2.)\n\nWith this modification, the square-root procedure works. In fact, if we\nunravel the definitions, we can see that the sequence of approximations\nto the square root generated here is precisely the same as the one\ngenerated by our original square-root procedure of [section\n1.1.7](#!/sicp/ch/1/sect/1/sub/7/). This approach of averaging\nsuccessive approximations to a solution, a technique we that we call\n*average damping*, often aids the convergence of fixed-point searches.")) "" (data/exercises {} (data/exercise {} (md {} "Show that the golden ratio \\\\(\\phi\\\\) [section\n1.2.2](#!/sicp/ch/1/sect/2/sub/2/) is a fixed point of the\ntransformation \\\\(x\\to 1+1/x\\\\), and use this fact to compute\n\\\\(\\phi\\\\) by means of the `fixed-point` procedure.") "" (data/q-a {} (md {} "If we define \\\\(f(x)=1+1/x\\\\), then a fixed point of \\\\(f\\\\) would\nbe one where \\\\(x=1+1/x\\\\). But then\n\n$$\\begin{align*}\n  x=&1+1/x \\\\\\\\\n  x^2=&x+1 \\end{align*} $$\n\n  Note: the golden ratio \\\\(\\phi\\\\), is\n  \\\\(\\lim_{x\\to\\infty}\\frac{Fib(x+1)}{Fib(x)}\\\\), which can also be\n  seen as a fixed point of the transformation,\n  \\\\(\\frac{a}{b}\\to\\frac{a+b}{a}\\\\). So, setting\n\n$$\\begin{align*}\\frac{a}{b}=&\\frac{a+b}{a}\n\\\\\\\\\\frac{a}{b}=&\\frac{a}{a}+\\frac{b}{a}\n\\\\\\\\\\phi=&1+1/\\phi\\end{align*}$$\n\nSince that is the same equation we started out with, we're done.\n\nNow to compute it using the `fixed-point` procedure.\n\n```clj\n(fixed-point (fn [x] (+ 1 (/ 1 x))) 1.0)\n```\n\nOr, using Clojure's shorter syntax,\n\n```clj\n(fixed-point #(+ 1 (/ 1 %)) 1.0)\n```"))) (data/exercise {} (md {} "Modify `fixed-point` so that it prints the sequence of approximations\nit generates, using the `println` primitive that prints its argument\nfollowed by a line break shown in [exercise\n1.22](#!/sicp/ch/1/ex/22/). Then find a solution to \\\\(x^x = 1000\\\\)\nby finding a fixed point of \\\\(x\\to\\log(1000)/\\log(x)\\\\). (Use\nClojure's primitive `Math/log` procedure to get \\\\(\\ln(x)\\\\), which\ncomputes natural logarithms.) Compare the number of steps this takes\nwith and without average damping. (Note that you cannot start\n`fixed-point` with a guess of 1, as this would cause division by\n\\\\(\\log(1) = 0\\\\).)") "" (data/q-a {} (md {} "```clj\n(defn print-fixed-point [f first-guess]\n  (let [tolerance 0.00001\n        close-enough? #(> tolerance (abs (- %1 %2)))]\n    (loop [guess first-guess]\n      (let [next (f guess)]\n        (if (close-enough? guess next)\n            next\n            (do (println guess) (recur next)))))))\n```\n\n```clj\n(defn log [x] (Math/log x))\n(print-fixed-point #(/ (log 1000) (log %)) 2.0)\n```"))) "" (data/exercise {} (md {} "a. An infinite *continued fraction* is an expression of the form\n\n$$f=\\frac{N_1}{D_1+\\frac{N_2}{D_2+\\frac{N_3}{D_3+...}}}$$\n\nAs an example, one can show that the infinite continued fraction\nexpansion with the \\\\(N_i\\\\) and \\\\(D_i\\\\) all equal to 1 produces\n\\\\(1/\\phi\\\\), where \\\\(\\phi\\\\) is the golden ratio (described in\n[section 1.2.2](#!/sicp/ch/1/sect/2/sub/2/). One way to approximate\nan infinite continued fraction is to truncate the expansion after a\ngiven number of terms. Such a truncation -- a so-called *k-term\nfinite continued fraction* -- has the form\n\n$$\\frac{N_1}{D_1+\\frac{N_2}{...+\\frac{N_k}{D_k}}}$$\n\nSuppose that \\\\(n\\\\) and \\\\(d\\\\) are procedures of one argument (the\nterm index \\\\(i\\\\)) that return the \\\\(N_i\\\\) and \\\\(D_i\\\\) of the\nterms of the continued fraction. Define a procedure `cont-frac` such\nthat evaluating `(cont-frac n d k)` computes the value of the\n\\\\(k\\\\)-term finite continued fraction. Check your procedure by\napproximating \\\\(1/\\phi\\\\) using\n\n```clj\n(cont-frac #(1.0)\n           #(1.0)\n           k)\n```\n\nfor successive values of \\\\(k\\\\). How large must you make \\\\(k\\\\) in\norder to get an approximation that is accurate to 4 decimal places?\n\nb. If your `cont-frac` procedure generates a recursive process, write\none that generates an iterative process. If it generates an iterative\nprocess, write one that generates a recursive process.") "" (data/q-a {} (md {} "```clj\n(defn cont-frac [n d k]\n  (loop [index k\n         accu  0]\n    (if (= index 0)\n        accu\n        (recur (dec index) (/ (n index) (+ (d index) accu))))))\n```\n\n```clj\n(defn cont-frac [n d k]\n  (if (= k 0)\n      0\n      (/ (n k) (+ (d k) (cont-frac n d (dec k))))))\n```"))) "" (data/exercise {} (md {} "In 1737, the Swiss mathematician Leonhard Euler published a memoir\n*De Fractionibus Continuls*, which included a continued fraction\nexpansion for \\\\(e-2\\\\), where \\\\(e\\\\) is the base of the natural\nlogarithms. In this fraction the \\\\(N_i\\\\) are all 1, and the\n\\\\(D_i\\\\) are successively 1,2,1,1,4,1,1,6,1,1,8,... Write a program\nthat uses your `cont-frac` procedure from\n[exercise1.37](#!/sicp/ch/1/ex/37/) to approximate \\\\(e\\\\), based on\nEuler's expansion.") "" (data/q-a {} (md {} "```clj\n(defn e-approximation [k]\n  (let [n #(1)\n        d #(if (= (mod % 3) 2)\n               (* 2 (/ (+ % 1) 3))\n               1)]\n    (+ 2 (cont-frac n d k))))\n```"))) "" (data/exercise {} (md {} "A continued fraction representation of the tangent function was\npublished in 1770 by the German mathematician J.H. Lambert:\n\n$$ \\tan x = \\frac{x}{1-\\frac{x^2}{3-\\frac{x^3}{5-...}}}$$\n\nwhere \\\\(x\\\\) is in radians. Define a procedure `(tan-cf x k)` that\ncomputes an approximation to the tangent function based on Lambert's\nformula. `k` specifies the number of terms to compute, as in\n[exercise 1.37](#!/sicp/ch/1/ex/37/).") "" (data/q-a {} (md {} "```clj\n(defn tan-cf [x k]\n  (let [n #(- (exp x %))\n        d #(- (* 2 %) 1)]\n    (- (cont-frac n d k))))\n```")))) "" (data/subsect {:title "Procedures as Returned Values"} (md {} "The above examples demonstrate how the ability to pass procedures as\narguments significantly enhances the expressive power of our\nprogramming language. We can achieve even more expressive power by\ncreating procedures whose returned values are themselves procedures.\n\nWe can illustrate this idea by looking again at the `fixed-point`\nexample described at the end of [section\n1.3.3](#!/sicp/ch/1/sect/3/sub/3/). We formulated a new version of the\nsquare-root procedure as a fixed-point search, starting with the\nobservation that \\\\(\\sqrt x\\\\) is a fixed-point of the function \\\\(y\\to\nx/y\\\\). Then we used average damping to make the approximations\nconverge. Average damping is a useful general technique in itself.\nNamely, given a function \\\\(f\\\\), we consider the function whose value\nat \\\\(x\\\\) is equal to the average of \\\\(x\\\\) and \\\\(f(x)\\\\).\n\nWe can express the idea of average damping by means of the following\nprocedure:\n\n```clj\n(defn average-damp [f]\n  (fn [x] (average x (f x))))\n```\n\n`average-damp` is a procedure that takes as arguments a procedure `f`\nand returns as its value a procedure (produced by the `fn`) that, when\napplied to a number `x`, produces the average of `x` and `(f x)`. For\nexample, apply `average-damp` to the `square` procedure produces a\nprocedure whose value at some number \\\\(x\\\\) is the average of \\\\(x\\\\)\nand \\\\(x^2\\\\). Applying this resulting procedure to 10 returns the\naverage of 10 and 100, or 55.<<Observe that this is a combination whose\noperator is itself a combination. [Exercise 1.4](#!/sicp/ch/1/ex/4/)\nalready demonstrated the ability to form such combinations, but that\nwas only a toy example.  Here we begin to see the real need for such\ncombinations -- when applying a procedure that is obtained as the value\nreturned by a higher-order procedure.>>\n\n```clj\n((average-damp square) 10)\n55\n```\n\nUsing `average-damp`, we can reformulate the square-root procedure as\nfollows:\n\n```clj\n(defn sqrt [x]\n  (fixed-point (average-damp #(/ x %))\n               1.0))\n```\n\nNotice how this formulation makes explicit the three ideas in the\nmethod: fixed-point search, average damping, and the function \\\\(y\\to\nx/y\\\\). It is instructive to compare this formulation of the\nsquare-root method with the original version given in [section\n1.1.7](#!/sicp/ch/1/sect/1/sub/7/). Bear in mind that these procedures\nexpress the same process, and notice how much clearer the idea becomes\nwhen we express the process in terms of these abstractions. In general,\nthere are many ways to formulate a process as a procedure. Experienced\nprogrammers know how to choose procedural formulations that are\nparticularly perspicuous, and where useful elements of the process are\nexposed as separate entities that can be reused in other applications.\nAs a simple example of reuse, notice that the cube root of \\\\(x\\\\) is a\nfixed point of the function \\\\(y\\to x/y^2\\\\), so we can immediately\ngeneralize our square-root procedure to one that extracts cube\nroots:<<See [exercise 1.45](#!/sicp/ch/1/ex/45/) for a further\ngeneralization.>>\n\n```clj\n(defn cube-root [x]\n  (fixed-point (average-damp #(/ x (square %)))\n               1.0))\n```")) "" (data/ssub {:title "Newton's Method"} (md {} "When we first introduced the square-root procedure, in [section\n1.1.7](#!/sicp/ch/1/sect/1/sub/7/), we mentioned that this was a\nspecial case of *Newton's method*. If \\\\(x\\to g(x)\\\\) is a\ndifferentiable function, then a solution of the equation \\\\(g(x) = 0\\\\)\nis a fixed point of the function \\\\(x\\to f(x)\\\\) where\n\n$$f(x)=x-\\frac{g(x)}{Dg(x)}$$\n\nand \\\\(Dg(x)\\\\) is the derivative of \\\\(g\\\\) evaluated at \\\\(x\\\\).\nNewton's method is the use of the tixed-point method we saw above to\napproximate a solute of the equation by finding a fixed point of the\nfunction \\\\(f\\\\).<<Elementary calculus books usually describe\nNewton&#39;s method in terms of the sequence of approximations\n\\\\(x_{n+1} = x_n - g(x_n)/Dg(x_n)\\\\). Having language for talking about\nprocesses and using the idea of fixed points simplifies the description\nof the method.>> For many functions \\\\(g\\\\) and for sufficiently good\ninitial guesses for \\\\(x\\\\), Newton's method converges very rapidly to\na solution of \\\\(g(x)=0\\\\)<<Newton&#39;s method does not always\nconverge to an answer, but it can be shown that in favorable cases each\niteration doubles the number-of-digits accuracy of the approximation to\nthe solution. In such cases, Newton&#39;s method will converge much\nmore rapidly than the half-interval method.>>\n\nIn order to implement Newton's method as a procedure, we must first\nexpress the idea of derivative. Note that \"derivative,\" like average\ndamping, is something that transforms a function into another function.\nFor instance, the derivative of the function \\\\(x\\to x^3\\\\) is the\nfunction \\\\(x\\to 3x^2\\\\). In general, if \\\\(g\\\\) is a function and\n\\\\(dx\\\\) is a small number, then the derivative \\\\(Dg\\\\) of \\\\(g\\\\) is\nthe function whose value at any number \\\\(x\\\\) is given (in the limit\nof small \\\\(dx\\\\)) by\n\n$$Dg(x)=\\frac{g(x+dx)-g(x)}{dx}$$\n\nThus, we can express the idea of derivative (taking \\\\(dx\\\\) to be,\nsay, 0.00001) as the procedure\n\n```clj\n(defn deriv [g]\n  (fn [x] (/ (- (g (+ x dx)) (g x)) dx)))\n```\n\nalong with the definition\n\n```clj\n(def dx 0.00001)\n```\n\nLike `average-damp`, `deriv` is a procedure that takes a procedure as\nargument and returns a procedure as value. For example, to approximate\nthe derivative of \\\\(x\\to x^3\\\\) at 5 (whose exact value is 75) we can\nevaluate\n\n```clj\n(defn cube [x] (* x x x))\n((deriv cube) 5)\n75.00014999664018\n```\n\nWith the aid of `deriv`, we can express Newton's method as a\nfixed-point process:\n\n```clj\n(defn newton-transform [g]\n  (fn [x] (- x (/ (g x) ((deriv g) x)))))\n(defn newtons-method [g guess]\n  (fixed-point (newton-transform g) guess))\n```\n\nThe `newton-transform` procedure expresses the formula at the beginning\nof this section, and `newtons-method` is readily defined in terms of\nthis. It takes as arguments a procedure that computes the function for\nwhich we want to find a zero, together with an initial guess. For\ninstance, to find the square root of \\\\(x\\\\), we can use Newton's\nmethod to find a zero of the function \\\\(y\\to y^2 - x\\\\) starting with\nan initial guess of 1.<<For finding square roots, Newton&#39;s method\nconverges rapidly to the correct solution from any starting point.>>\nThis provides yet another form of the square-root procedure:\n\n```clj\n(defn sqrt [x]\n  (newtons-method #(- (square %) x)\n                  1.0))\n```")) "" (data/ssub {:title "Abstractions and First-class Procedures"} (md {} "We've seen two ways to express the square-root computation as an\ninstance of a more general method, once as a fixed-point search and\nonce using Newton's method. Since Newton's method was itself expressed\nas a fixed-point process, we actually saw two ways to compute square\nroots as fixed points. Each method begins with a function and finds a\nfixed point of some transformation of the function. We can express this\ngeneral idea itself as a procedure:\n\n```clj\n(defn fixed-point-of-transform [g transform guess]\n  (fixed-point (transform g) guess))\n```\n\nThis very general procedure takes as its arguments a procedure `g` that\ncomputes some function, a procedure that transforms `g`, and an initial\nguess. The returned result is a fixed point of the transformed\nfunction.\n\nUsing this abstraction, we can recast the first square-root computation\nfrom this section (where we look for a fixed point of the\naverage-damped version of \\\\(y\\to x/y\\\\)) as an instance of this\ngeneral method:\n\n```clj\n(defn sqrt [x]\n  (fixed-point-of-transform #(/ x y)\n                            average-damp\n                            1.0))\n```\n\nSimilarly, we can express the second square-root computation from this\nsection (an instance of Newton's method that finds a fixed point of the\nNewton transform of \\\\(y\\to y^2 - x\\\\)) as\n\n```clj\n(defn sqrt [x]\n  (fixed-point-of-transform #(- (square %) x)\n                            newton-transform\n                            1.0))\n```\n\nWe began [section 1.3](#!/sicp/ch/1/sect/3/) with the observation that\ncompound procedures are a crucial abstraction mechanism, because they\npermit us to express general methods of computing as explicit elements\nin our programming language. Now we've seen how higher-order procedures\npermit us to manipulate these general methods to create further\nabstractions.\n\nAs programmers, we should be alert to opportunities to identify the\nunderlying abstractions in our programs and to build upon them and\ngeneralize them to create more powerful abstractions. This is not to\nsay that one should always write programs in the most abstract way\npossible; expert programmers know how to choose the level of\nabstraction appropriate to their task. But it is important to be able\nto think in terms of these abstractions, so that we can be ready to\napply them in new contexts. The significance of higher-order procedures\nis that they enable us to represent these abstractions explicitly as\nelements in our programming language, so that they can be handled just\nlike other computational elements.\n\nIn general, programming languages impose restrictions on the ways in\nwhich computational elements can be manipulated. Elements with the\nfewest restrictions are said to have *first-class* status. Some of the\n\"rights and privileges\" of first-class elements are:<<The notion of\nfirst-class status of programming-language elements is due to the\nBritish computer scientist Christopher Strachey (1916-1975).>>\n\n- They may be named by variables.\n\n- They may be passed as arguments to procedures.\n\n- They may be returned as the results of procedures.\n\n- They may be included in data structures.<<We&#39;ll see examples of\nthis after we introduce data structures in chapter 2.>>\n\nLisp, unlike other common programming languages, awards procedures full\nfirst-class status. This poses challenges for efficient implementation,\nbut the resulting gain in expressive power is enormous.<<The major\nimplementation cost of first-class procedures is that allowing\nprocedures to be returned as values requires reserving storage for a\nprocedure's free variables even while the procedure is not executing.\nIn the Scheme implementation we will study in section 4.1, these\nvariables are stored in the procedure's environment.>>")) "" (data/exercises {} (data/exercise {} (md {} "Define a procedure `cubic` that can be used together with the\n`newtons-method` procedure in expressions of the form\n\n```clj\n(newtons-method (cubic a b c) 1)\n```\n\nto approximate zeros of the cubic \\\\(x^3+ax^2+bx+c\\\\). Use it to\napproximate the zeros of several cubic functions and check your\nanswers on [Wolfram Alpha](http://www.wolframalpha.com).") "" (data/q-a {} (md {} "```clj\n(defn cubic [a b c]\n  (fn [x] (+ (cube x) (* a (square x)) (* b x) c)))\n```"))) (data/exercise {} (md {} "Define a procedure `dubs` <<we could have named it `double` as in the\noriginal *SICP*, but `double` is already a thing in Clojure. Since\n`double` is not a special form, you can redefine it within your\nenvironment, but you should just get a warning about it. Either way,\nit was not very instructive to do so at this time, so I renamed it\n`dubs`>> that takes a procedure of one argument as argument and\nreturns a procedure that applies the original procedure twice. For\nexample, if `inc` is a procedure that adds 1 to its argument, then\n`(dubs inc)` should be a procedure that adds 2. What value is\nreturned by\n\n```clj\n(((dubs (dubs dubs)) inc) 5)\n```") "" (data/q-a {} (md {} "```clj\n(defn dubs [f]\n  (fn [x] (f (f x))))\n```\n\n```clj\n(((dubs (dubs dubs)) inc) 5)\n(((dubs (fn [x] (dubs (dubs x)))) inc) 5)\n(((fn [x] (dubs (dubs (dubs x)))) inc) 5)\n((dubs (dubs (dubs #(+ % 2)))) 5)\n((dubs (dubs #(+ % 4))) 5)\n((dubs #(+ % 8)) 5)\n(#(+ % 16) 5)\n(+ 5 16)\n21\n```"))) "" (data/exercise {} (md {} "Let \\\\(f\\\\) and \\\\(g\\\\) be two one-argument functions. The\ncomposition \\\\(f\\\\) after \\\\(g\\\\) is defined to be the function\n\\\\(x\\to f(g(x))\\\\). Define a procedure `compose` that implements\ncomposition. For example, if `inc` is a procedure that adds 1 to its\nargument,\n\n```clj\n((compose square inc) 6)\n49\n```") "" (data/q-a {} (md {} "```clj\n(defn compose [f g]\n  (fn [x] (f (g x))))\n```"))) "" (data/exercise {} (md {} "If \\\\(f\\\\) is a numerical function and \\\\(n\\\\) is a positive integer,\nthen we can form the \\\\(n\\\\)th repeated application of \\\\(f\\\\), which\nis defined to be the function whose value at \\\\(x\\\\) is\n\\\\(f(f(...(f(x))...))\\\\). For example, if \\\\(f\\\\) is the function\n\\\\(x\\to x + 1\\\\), then the \\\\(n\\\\)th repeated application of \\\\(f\\\\)\nis the function \\\\(x\\to x + n\\\\). If \\\\(f\\\\) is the operation of\nsquaring a number, then the \\\\(n\\\\)th repeated application of \\\\(f\\\\)\nis the function that raises its argument to the \\\\(2^n\\\\)th power.\nWrite a procedure that takes as inputs a procedure that computes\n\\\\(f\\\\) and a positive integer \\\\(n\\\\) and returns the procedure that\ncomputes the \\\\(n\\\\)th repeated application of \\\\(f\\\\). Your\nprocedure should be able to be used as follows:\n\n```clj\n((repeated square 2) 5)\n625\n```\n\nHint: You may find it convenient to use `compose` from [exercise\n1.42](#!/sicp/ch/1/ex/42/)") "" (data/q-a {} (md {} "```clj\n(defn repeated [f n]\n  (loop [accu   identity\n         number n]\n    (if (= number 0)\n        accu\n        (recur (compose f accu) (dec number)))))\n```"))) "" (data/exercise {} (md {} "The idea of *smoothing* a function is an important concept in signal\nprocessing. If \\\\(f\\\\) is a function and \\\\(dx\\\\) is some small\nnumber, then the smoothed version of \\\\(f\\\\) is the function whose\nvalue at a point \\\\(x\\\\) is the average of \\\\(f(x - dx)\\\\),\n\\\\(f(x)\\\\), and \\\\(f(x + dx)\\\\). Write a procedure `smooth` that\ntakes as input a procedure that computes \\\\(f\\\\) and returns a\nprocedure that computes the smoothed \\\\(f\\\\). It is sometimes\nvaluable to repeatedly smooth a function (that is, smooth the\nsmoothed function, and so on) to obtained the *n-fold smoothed\nfunction*. Show how to generate the \\\\(n\\\\)-fold smoothed function of\nany given function using `smooth` and `repeated` from [exercise\n1.43](#!/sicp/ch/1/ex/43/).") "" (data/q-a {} (md {} "```clj\n(defn average-of-3 [a b c]\n  (/ (+ a b c) 3))\n```\n\n```clj\n(defn smooth [f]\n  (let [dx 0.00001]\n    (fn [x] (average-of-3 (f (- x dx)) (f x) (f (+ x dx))))))\n```\n\n```clj\n(defn n-fold-smooth [f n]\n  ((repeated smooth n) f))\n```"))) "" (data/exercise {} (md {} "We saw in [section 1.3.3](#!/sicp/ch/1/sect/3/sub/3/) that attempting\nto compute square roots by naively finding a fixed point of \\\\(y\\to\nx/y\\\\) does not converge, and that this can be fixed by average\ndamping. The same method works for finding cube roots as fixed points\nof the average-damped \\\\(y\\to x/y^2\\\\). Unfortunately, the process\ndoes not work for fourth roots -- a single average damp is not enough\nto make a fixed-point search for \\\\(y\\to x/y^3\\\\) converge. On the\nother hand, if we average damp twice (i.e., use the average damp of\nthe average damp of \\((y\\to x/y^3\\\\)) the fixed-point search does\nconverge. Do some experiments to determine how many average damps are\nrequired to compute \\\\(n\\\\)th roots as a fixed-point search based\nupon repeated average damping of \\\\(y\\to x/y^{n-1}\\\\). Use this to\nimplement a simple procedure for computing \\\\(n\\\\)th roots using\nfixed-point, average-damp, and the repeated procedure of [exercise\n1.43](#!/sicp/ch/1/ex/43/). Assume that any arithmetic operations you\nneed are available as primitives (you can see which ones are\navailable at [clojure.org](http://www.clojure.org/)).") "" (data/q-a {} (md {} "By trial and error, we can deduce that every time we double the\nargument (the exponent), the number of dampings increases by one\n(give or take). That would suggest that the number of dampings\nneeded is \\\\(\\log_2(n)\\\\). I will find a proof of this later and\nput it here for those of you who are interested. In the mean time,\nhere is the procedure (we're using the identity\n\\\\(\\log_b(x)=\\log_a(x)\\cdot\\log_b(a)\\\\))\n\n```clj\n(defn log-base-2 [x] (/ (Math/log x) (Math/log 2)))\n(defn nth-root [x n]\n  (fixed-point ((repeated average-damp (Math/floor (log-base-2 n)))\n                #(/ x (expt y (- n 1))))\n               1.0))\n```"))) "" (data/exercise {} (md {} "Several of the numerical methods described in this chapter are\ninstances of an extremely general computational strategy known as\n*iterative improvement*. Iterative improvement says that, to compute\nsomething, we start with an initial guess for the answer, test if the\nguess is good enough, and otherwise improve the guess and continue\nthe process using the improved guess as the new guess. Write a\nprocedure `iterative-improve` that takes two procedures as arguments:\na method for telling whether a guess is good enough and a method for\nimproving a guess. `Iterative-improve` should return as its value a\nprocedure that takes a guess as argument and keeps improving the\nguess until it is good enough. Rewrite the sqrt procedure of section\n1.1.7 and the fixed-point procedure of section 1.3.3 in terms of\niterative-improve.") "" (data/q-a {} (md {} "```clj\n(defn iterative-improve [good-enough? improve]\n  (fn [initial] \n    (loop [guess initial]\n      (if (good-enough? guess)\n          guess\n          (recur (improve guess))))))\n```\n\n```clj\n(defn sqrt [x]\n  ((iterative-improve #(< (Math/abs (- (square %) x)) tolerance)\n                      #(average % (/ x %))) \n    1.0))\n```\n\n```clj\n(defn fixed-point [f]\n  ((iterative-improve \n    #(< (Math/abs (- (f %) %)) tolerance)\n    f)\n   1.0))\n```"))))))
